{
  "best_global_step": 4642,
  "best_metric": 0.44598889350891113,
  "best_model_checkpoint": "./results/checkpoint-4642",
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 11605,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00043084877208099956,
      "grad_norm": 5.294051170349121,
      "learning_rate": 5e-05,
      "loss": 1.9822,
      "step": 1
    },
    {
      "epoch": 0.004308487720809996,
      "grad_norm": 5.510874271392822,
      "learning_rate": 4.9961223610512713e-05,
      "loss": 1.7966,
      "step": 10
    },
    {
      "epoch": 0.008616975441619991,
      "grad_norm": 5.419978141784668,
      "learning_rate": 4.9918138733304615e-05,
      "loss": 1.5562,
      "step": 20
    },
    {
      "epoch": 0.012925463162429988,
      "grad_norm": 7.0500054359436035,
      "learning_rate": 4.9875053856096516e-05,
      "loss": 1.3368,
      "step": 30
    },
    {
      "epoch": 0.017233950883239983,
      "grad_norm": 6.071752071380615,
      "learning_rate": 4.983196897888841e-05,
      "loss": 1.3607,
      "step": 40
    },
    {
      "epoch": 0.021542438604049977,
      "grad_norm": 4.963291645050049,
      "learning_rate": 4.978888410168031e-05,
      "loss": 1.179,
      "step": 50
    },
    {
      "epoch": 0.025850926324859975,
      "grad_norm": 7.149969100952148,
      "learning_rate": 4.974579922447221e-05,
      "loss": 1.1236,
      "step": 60
    },
    {
      "epoch": 0.03015941404566997,
      "grad_norm": 5.012447834014893,
      "learning_rate": 4.9702714347264114e-05,
      "loss": 0.9838,
      "step": 70
    },
    {
      "epoch": 0.034467901766479965,
      "grad_norm": 7.398519039154053,
      "learning_rate": 4.9659629470056015e-05,
      "loss": 0.8959,
      "step": 80
    },
    {
      "epoch": 0.03877638948728996,
      "grad_norm": 8.819184303283691,
      "learning_rate": 4.9616544592847916e-05,
      "loss": 1.0545,
      "step": 90
    },
    {
      "epoch": 0.043084877208099955,
      "grad_norm": 8.742959022521973,
      "learning_rate": 4.957345971563981e-05,
      "loss": 1.0567,
      "step": 100
    },
    {
      "epoch": 0.04739336492890995,
      "grad_norm": 5.570676803588867,
      "learning_rate": 4.953037483843171e-05,
      "loss": 0.7928,
      "step": 110
    },
    {
      "epoch": 0.05170185264971995,
      "grad_norm": 4.912286758422852,
      "learning_rate": 4.948728996122361e-05,
      "loss": 0.799,
      "step": 120
    },
    {
      "epoch": 0.056010340370529946,
      "grad_norm": 9.095301628112793,
      "learning_rate": 4.944420508401551e-05,
      "loss": 0.9041,
      "step": 130
    },
    {
      "epoch": 0.06031882809133994,
      "grad_norm": 6.5924391746521,
      "learning_rate": 4.940112020680741e-05,
      "loss": 0.7588,
      "step": 140
    },
    {
      "epoch": 0.06462731581214994,
      "grad_norm": 6.964405536651611,
      "learning_rate": 4.935803532959931e-05,
      "loss": 0.8354,
      "step": 150
    },
    {
      "epoch": 0.06893580353295993,
      "grad_norm": 7.014651775360107,
      "learning_rate": 4.931495045239121e-05,
      "loss": 0.7997,
      "step": 160
    },
    {
      "epoch": 0.07324429125376992,
      "grad_norm": 5.817525863647461,
      "learning_rate": 4.927186557518311e-05,
      "loss": 0.7931,
      "step": 170
    },
    {
      "epoch": 0.07755277897457992,
      "grad_norm": 6.140594005584717,
      "learning_rate": 4.9228780697975014e-05,
      "loss": 0.6971,
      "step": 180
    },
    {
      "epoch": 0.08186126669538991,
      "grad_norm": 5.774064064025879,
      "learning_rate": 4.9185695820766915e-05,
      "loss": 0.6128,
      "step": 190
    },
    {
      "epoch": 0.08616975441619991,
      "grad_norm": 9.674849510192871,
      "learning_rate": 4.9142610943558816e-05,
      "loss": 0.7007,
      "step": 200
    },
    {
      "epoch": 0.0904782421370099,
      "grad_norm": 8.082931518554688,
      "learning_rate": 4.909952606635072e-05,
      "loss": 0.9726,
      "step": 210
    },
    {
      "epoch": 0.0947867298578199,
      "grad_norm": 6.938453197479248,
      "learning_rate": 4.905644118914262e-05,
      "loss": 0.6638,
      "step": 220
    },
    {
      "epoch": 0.09909521757862991,
      "grad_norm": 16.418853759765625,
      "learning_rate": 4.901335631193451e-05,
      "loss": 0.7771,
      "step": 230
    },
    {
      "epoch": 0.1034037052994399,
      "grad_norm": 4.866405010223389,
      "learning_rate": 4.8970271434726414e-05,
      "loss": 0.643,
      "step": 240
    },
    {
      "epoch": 0.1077121930202499,
      "grad_norm": 7.944871425628662,
      "learning_rate": 4.892718655751831e-05,
      "loss": 0.7393,
      "step": 250
    },
    {
      "epoch": 0.11202068074105989,
      "grad_norm": 9.858027458190918,
      "learning_rate": 4.888410168031021e-05,
      "loss": 0.7135,
      "step": 260
    },
    {
      "epoch": 0.11632916846186989,
      "grad_norm": 4.243436813354492,
      "learning_rate": 4.884101680310211e-05,
      "loss": 0.7192,
      "step": 270
    },
    {
      "epoch": 0.12063765618267988,
      "grad_norm": 4.949830532073975,
      "learning_rate": 4.879793192589401e-05,
      "loss": 0.6959,
      "step": 280
    },
    {
      "epoch": 0.12494614390348988,
      "grad_norm": 5.98270320892334,
      "learning_rate": 4.8754847048685914e-05,
      "loss": 0.7758,
      "step": 290
    },
    {
      "epoch": 0.12925463162429987,
      "grad_norm": 7.222840785980225,
      "learning_rate": 4.8711762171477815e-05,
      "loss": 0.8345,
      "step": 300
    },
    {
      "epoch": 0.13356311934510987,
      "grad_norm": 4.627902507781982,
      "learning_rate": 4.8668677294269716e-05,
      "loss": 0.6235,
      "step": 310
    },
    {
      "epoch": 0.13787160706591986,
      "grad_norm": 8.83741569519043,
      "learning_rate": 4.862559241706162e-05,
      "loss": 0.7491,
      "step": 320
    },
    {
      "epoch": 0.14218009478672985,
      "grad_norm": 10.413594245910645,
      "learning_rate": 4.858250753985351e-05,
      "loss": 0.7433,
      "step": 330
    },
    {
      "epoch": 0.14648858250753985,
      "grad_norm": 6.305183410644531,
      "learning_rate": 4.853942266264541e-05,
      "loss": 0.736,
      "step": 340
    },
    {
      "epoch": 0.15079707022834984,
      "grad_norm": 5.8295488357543945,
      "learning_rate": 4.8496337785437314e-05,
      "loss": 0.6097,
      "step": 350
    },
    {
      "epoch": 0.15510555794915984,
      "grad_norm": 15.449037551879883,
      "learning_rate": 4.8453252908229215e-05,
      "loss": 0.6675,
      "step": 360
    },
    {
      "epoch": 0.15941404566996983,
      "grad_norm": 6.663893699645996,
      "learning_rate": 4.8410168031021117e-05,
      "loss": 0.7169,
      "step": 370
    },
    {
      "epoch": 0.16372253339077983,
      "grad_norm": 8.715707778930664,
      "learning_rate": 4.836708315381301e-05,
      "loss": 0.6701,
      "step": 380
    },
    {
      "epoch": 0.16803102111158982,
      "grad_norm": 6.049393653869629,
      "learning_rate": 4.832399827660491e-05,
      "loss": 0.5916,
      "step": 390
    },
    {
      "epoch": 0.17233950883239982,
      "grad_norm": 6.031497478485107,
      "learning_rate": 4.8280913399396813e-05,
      "loss": 0.6265,
      "step": 400
    },
    {
      "epoch": 0.1766479965532098,
      "grad_norm": 5.704559326171875,
      "learning_rate": 4.8237828522188715e-05,
      "loss": 0.5755,
      "step": 410
    },
    {
      "epoch": 0.1809564842740198,
      "grad_norm": 4.799853324890137,
      "learning_rate": 4.8194743644980616e-05,
      "loss": 0.6863,
      "step": 420
    },
    {
      "epoch": 0.1852649719948298,
      "grad_norm": 10.044988632202148,
      "learning_rate": 4.815165876777251e-05,
      "loss": 0.681,
      "step": 430
    },
    {
      "epoch": 0.1895734597156398,
      "grad_norm": 3.4133872985839844,
      "learning_rate": 4.810857389056441e-05,
      "loss": 0.637,
      "step": 440
    },
    {
      "epoch": 0.19388194743644982,
      "grad_norm": 6.905567646026611,
      "learning_rate": 4.806548901335631e-05,
      "loss": 0.4908,
      "step": 450
    },
    {
      "epoch": 0.19819043515725981,
      "grad_norm": 8.543020248413086,
      "learning_rate": 4.8022404136148214e-05,
      "loss": 0.6662,
      "step": 460
    },
    {
      "epoch": 0.2024989228780698,
      "grad_norm": 3.678361654281616,
      "learning_rate": 4.7979319258940115e-05,
      "loss": 0.5878,
      "step": 470
    },
    {
      "epoch": 0.2068074105988798,
      "grad_norm": 3.91329288482666,
      "learning_rate": 4.7936234381732016e-05,
      "loss": 0.6055,
      "step": 480
    },
    {
      "epoch": 0.2111158983196898,
      "grad_norm": 7.848910808563232,
      "learning_rate": 4.789314950452392e-05,
      "loss": 0.5134,
      "step": 490
    },
    {
      "epoch": 0.2154243860404998,
      "grad_norm": 3.918935537338257,
      "learning_rate": 4.785006462731582e-05,
      "loss": 0.684,
      "step": 500
    },
    {
      "epoch": 0.2197328737613098,
      "grad_norm": 9.703276634216309,
      "learning_rate": 4.780697975010771e-05,
      "loss": 0.6446,
      "step": 510
    },
    {
      "epoch": 0.22404136148211978,
      "grad_norm": 6.430994510650635,
      "learning_rate": 4.7763894872899614e-05,
      "loss": 0.6204,
      "step": 520
    },
    {
      "epoch": 0.22834984920292978,
      "grad_norm": 5.249555587768555,
      "learning_rate": 4.772080999569151e-05,
      "loss": 0.4842,
      "step": 530
    },
    {
      "epoch": 0.23265833692373977,
      "grad_norm": 7.423232555389404,
      "learning_rate": 4.767772511848341e-05,
      "loss": 0.5904,
      "step": 540
    },
    {
      "epoch": 0.23696682464454977,
      "grad_norm": 4.705328941345215,
      "learning_rate": 4.763464024127531e-05,
      "loss": 0.6121,
      "step": 550
    },
    {
      "epoch": 0.24127531236535976,
      "grad_norm": 4.052763938903809,
      "learning_rate": 4.759155536406721e-05,
      "loss": 0.6619,
      "step": 560
    },
    {
      "epoch": 0.24558380008616976,
      "grad_norm": 5.656164169311523,
      "learning_rate": 4.7548470486859114e-05,
      "loss": 0.4935,
      "step": 570
    },
    {
      "epoch": 0.24989228780697975,
      "grad_norm": 5.289011478424072,
      "learning_rate": 4.7505385609651015e-05,
      "loss": 0.6657,
      "step": 580
    },
    {
      "epoch": 0.25420077552778975,
      "grad_norm": 8.090758323669434,
      "learning_rate": 4.7462300732442916e-05,
      "loss": 0.7541,
      "step": 590
    },
    {
      "epoch": 0.25850926324859974,
      "grad_norm": 7.915714263916016,
      "learning_rate": 4.741921585523482e-05,
      "loss": 0.6718,
      "step": 600
    },
    {
      "epoch": 0.26281775096940974,
      "grad_norm": 3.3638668060302734,
      "learning_rate": 4.737613097802672e-05,
      "loss": 0.5758,
      "step": 610
    },
    {
      "epoch": 0.26712623869021973,
      "grad_norm": 9.440357208251953,
      "learning_rate": 4.733304610081862e-05,
      "loss": 0.6421,
      "step": 620
    },
    {
      "epoch": 0.2714347264110297,
      "grad_norm": 6.901145935058594,
      "learning_rate": 4.7289961223610514e-05,
      "loss": 0.5776,
      "step": 630
    },
    {
      "epoch": 0.2757432141318397,
      "grad_norm": 3.208530902862549,
      "learning_rate": 4.7246876346402415e-05,
      "loss": 0.4781,
      "step": 640
    },
    {
      "epoch": 0.2800517018526497,
      "grad_norm": 7.336590766906738,
      "learning_rate": 4.720379146919432e-05,
      "loss": 0.5877,
      "step": 650
    },
    {
      "epoch": 0.2843601895734597,
      "grad_norm": 7.278299808502197,
      "learning_rate": 4.716070659198622e-05,
      "loss": 0.5691,
      "step": 660
    },
    {
      "epoch": 0.2886686772942697,
      "grad_norm": 5.597586631774902,
      "learning_rate": 4.711762171477811e-05,
      "loss": 0.626,
      "step": 670
    },
    {
      "epoch": 0.2929771650150797,
      "grad_norm": 8.697712898254395,
      "learning_rate": 4.7074536837570014e-05,
      "loss": 0.5861,
      "step": 680
    },
    {
      "epoch": 0.2972856527358897,
      "grad_norm": 7.913462162017822,
      "learning_rate": 4.7031451960361915e-05,
      "loss": 0.4899,
      "step": 690
    },
    {
      "epoch": 0.3015941404566997,
      "grad_norm": 11.34586238861084,
      "learning_rate": 4.6988367083153816e-05,
      "loss": 0.5693,
      "step": 700
    },
    {
      "epoch": 0.3059026281775097,
      "grad_norm": 3.8883795738220215,
      "learning_rate": 4.694528220594572e-05,
      "loss": 0.6345,
      "step": 710
    },
    {
      "epoch": 0.3102111158983197,
      "grad_norm": 5.2936248779296875,
      "learning_rate": 4.690219732873761e-05,
      "loss": 0.5912,
      "step": 720
    },
    {
      "epoch": 0.3145196036191297,
      "grad_norm": 3.2322421073913574,
      "learning_rate": 4.685911245152951e-05,
      "loss": 0.543,
      "step": 730
    },
    {
      "epoch": 0.31882809133993967,
      "grad_norm": 11.775153160095215,
      "learning_rate": 4.6816027574321414e-05,
      "loss": 0.5106,
      "step": 740
    },
    {
      "epoch": 0.32313657906074966,
      "grad_norm": 4.635697364807129,
      "learning_rate": 4.6772942697113315e-05,
      "loss": 0.4653,
      "step": 750
    },
    {
      "epoch": 0.32744506678155966,
      "grad_norm": 5.854623794555664,
      "learning_rate": 4.6729857819905216e-05,
      "loss": 0.6981,
      "step": 760
    },
    {
      "epoch": 0.33175355450236965,
      "grad_norm": 5.592535972595215,
      "learning_rate": 4.668677294269712e-05,
      "loss": 0.556,
      "step": 770
    },
    {
      "epoch": 0.33606204222317965,
      "grad_norm": 13.304792404174805,
      "learning_rate": 4.664368806548902e-05,
      "loss": 0.445,
      "step": 780
    },
    {
      "epoch": 0.34037052994398964,
      "grad_norm": 7.952719211578369,
      "learning_rate": 4.660060318828092e-05,
      "loss": 0.6838,
      "step": 790
    },
    {
      "epoch": 0.34467901766479964,
      "grad_norm": 7.355303764343262,
      "learning_rate": 4.6557518311072815e-05,
      "loss": 0.5647,
      "step": 800
    },
    {
      "epoch": 0.34898750538560963,
      "grad_norm": 6.545389175415039,
      "learning_rate": 4.6514433433864716e-05,
      "loss": 0.6114,
      "step": 810
    },
    {
      "epoch": 0.3532959931064196,
      "grad_norm": 8.147128105163574,
      "learning_rate": 4.647134855665661e-05,
      "loss": 0.5596,
      "step": 820
    },
    {
      "epoch": 0.3576044808272296,
      "grad_norm": 5.872011661529541,
      "learning_rate": 4.642826367944851e-05,
      "loss": 0.5707,
      "step": 830
    },
    {
      "epoch": 0.3619129685480396,
      "grad_norm": 4.234875679016113,
      "learning_rate": 4.638517880224041e-05,
      "loss": 0.5963,
      "step": 840
    },
    {
      "epoch": 0.3662214562688496,
      "grad_norm": 7.013054847717285,
      "learning_rate": 4.6342093925032314e-05,
      "loss": 0.5388,
      "step": 850
    },
    {
      "epoch": 0.3705299439896596,
      "grad_norm": 9.554668426513672,
      "learning_rate": 4.6299009047824215e-05,
      "loss": 0.5662,
      "step": 860
    },
    {
      "epoch": 0.3748384317104696,
      "grad_norm": 4.030694007873535,
      "learning_rate": 4.6255924170616116e-05,
      "loss": 0.5447,
      "step": 870
    },
    {
      "epoch": 0.3791469194312796,
      "grad_norm": 3.2828238010406494,
      "learning_rate": 4.621283929340802e-05,
      "loss": 0.5781,
      "step": 880
    },
    {
      "epoch": 0.3834554071520896,
      "grad_norm": 8.358835220336914,
      "learning_rate": 4.616975441619992e-05,
      "loss": 0.5413,
      "step": 890
    },
    {
      "epoch": 0.38776389487289964,
      "grad_norm": 4.384496212005615,
      "learning_rate": 4.612666953899182e-05,
      "loss": 0.6781,
      "step": 900
    },
    {
      "epoch": 0.39207238259370963,
      "grad_norm": 6.872919082641602,
      "learning_rate": 4.608358466178372e-05,
      "loss": 0.6049,
      "step": 910
    },
    {
      "epoch": 0.39638087031451963,
      "grad_norm": 7.400866985321045,
      "learning_rate": 4.6040499784575616e-05,
      "loss": 0.5398,
      "step": 920
    },
    {
      "epoch": 0.4006893580353296,
      "grad_norm": 15.920406341552734,
      "learning_rate": 4.599741490736752e-05,
      "loss": 0.6272,
      "step": 930
    },
    {
      "epoch": 0.4049978457561396,
      "grad_norm": 6.002612590789795,
      "learning_rate": 4.595433003015942e-05,
      "loss": 0.4806,
      "step": 940
    },
    {
      "epoch": 0.4093063334769496,
      "grad_norm": 9.722614288330078,
      "learning_rate": 4.591124515295131e-05,
      "loss": 0.5409,
      "step": 950
    },
    {
      "epoch": 0.4136148211977596,
      "grad_norm": 7.253836154937744,
      "learning_rate": 4.5868160275743214e-05,
      "loss": 0.5181,
      "step": 960
    },
    {
      "epoch": 0.4179233089185696,
      "grad_norm": 10.294853210449219,
      "learning_rate": 4.5825075398535115e-05,
      "loss": 0.5307,
      "step": 970
    },
    {
      "epoch": 0.4222317966393796,
      "grad_norm": 6.106749534606934,
      "learning_rate": 4.5781990521327016e-05,
      "loss": 0.6346,
      "step": 980
    },
    {
      "epoch": 0.4265402843601896,
      "grad_norm": 8.110475540161133,
      "learning_rate": 4.573890564411892e-05,
      "loss": 0.4755,
      "step": 990
    },
    {
      "epoch": 0.4308487720809996,
      "grad_norm": 7.054041385650635,
      "learning_rate": 4.569582076691082e-05,
      "loss": 0.5477,
      "step": 1000
    },
    {
      "epoch": 0.4351572598018096,
      "grad_norm": 3.555905818939209,
      "learning_rate": 4.565273588970272e-05,
      "loss": 0.5407,
      "step": 1010
    },
    {
      "epoch": 0.4394657475226196,
      "grad_norm": 8.43257999420166,
      "learning_rate": 4.5609651012494614e-05,
      "loss": 0.5629,
      "step": 1020
    },
    {
      "epoch": 0.44377423524342957,
      "grad_norm": 7.181661605834961,
      "learning_rate": 4.5566566135286515e-05,
      "loss": 0.445,
      "step": 1030
    },
    {
      "epoch": 0.44808272296423957,
      "grad_norm": 3.9746572971343994,
      "learning_rate": 4.552348125807842e-05,
      "loss": 0.6146,
      "step": 1040
    },
    {
      "epoch": 0.45239121068504956,
      "grad_norm": 8.689151763916016,
      "learning_rate": 4.548039638087032e-05,
      "loss": 0.4975,
      "step": 1050
    },
    {
      "epoch": 0.45669969840585956,
      "grad_norm": 5.563642501831055,
      "learning_rate": 4.543731150366222e-05,
      "loss": 0.5382,
      "step": 1060
    },
    {
      "epoch": 0.46100818612666955,
      "grad_norm": 3.1053550243377686,
      "learning_rate": 4.539422662645412e-05,
      "loss": 0.538,
      "step": 1070
    },
    {
      "epoch": 0.46531667384747954,
      "grad_norm": 4.812693119049072,
      "learning_rate": 4.5351141749246015e-05,
      "loss": 0.482,
      "step": 1080
    },
    {
      "epoch": 0.46962516156828954,
      "grad_norm": 9.196337699890137,
      "learning_rate": 4.5308056872037916e-05,
      "loss": 0.5802,
      "step": 1090
    },
    {
      "epoch": 0.47393364928909953,
      "grad_norm": 5.507308006286621,
      "learning_rate": 4.526497199482982e-05,
      "loss": 0.5439,
      "step": 1100
    },
    {
      "epoch": 0.47824213700990953,
      "grad_norm": 3.658364772796631,
      "learning_rate": 4.522188711762172e-05,
      "loss": 0.6062,
      "step": 1110
    },
    {
      "epoch": 0.4825506247307195,
      "grad_norm": 8.793002128601074,
      "learning_rate": 4.517880224041361e-05,
      "loss": 0.6115,
      "step": 1120
    },
    {
      "epoch": 0.4868591124515295,
      "grad_norm": 4.934069633483887,
      "learning_rate": 4.5135717363205514e-05,
      "loss": 0.4632,
      "step": 1130
    },
    {
      "epoch": 0.4911676001723395,
      "grad_norm": 5.230056285858154,
      "learning_rate": 4.5092632485997415e-05,
      "loss": 0.6099,
      "step": 1140
    },
    {
      "epoch": 0.4954760878931495,
      "grad_norm": 8.574434280395508,
      "learning_rate": 4.5049547608789316e-05,
      "loss": 0.5757,
      "step": 1150
    },
    {
      "epoch": 0.4997845756139595,
      "grad_norm": 4.333014488220215,
      "learning_rate": 4.500646273158122e-05,
      "loss": 0.5471,
      "step": 1160
    },
    {
      "epoch": 0.5040930633347694,
      "grad_norm": 6.1693291664123535,
      "learning_rate": 4.496337785437312e-05,
      "loss": 0.5645,
      "step": 1170
    },
    {
      "epoch": 0.5084015510555795,
      "grad_norm": 10.953474998474121,
      "learning_rate": 4.492029297716502e-05,
      "loss": 0.4854,
      "step": 1180
    },
    {
      "epoch": 0.5127100387763894,
      "grad_norm": 6.9988627433776855,
      "learning_rate": 4.487720809995692e-05,
      "loss": 0.4766,
      "step": 1190
    },
    {
      "epoch": 0.5170185264971995,
      "grad_norm": 7.006561279296875,
      "learning_rate": 4.483412322274882e-05,
      "loss": 0.5928,
      "step": 1200
    },
    {
      "epoch": 0.5213270142180095,
      "grad_norm": 4.7996039390563965,
      "learning_rate": 4.479103834554072e-05,
      "loss": 0.4757,
      "step": 1210
    },
    {
      "epoch": 0.5256355019388195,
      "grad_norm": 5.886119842529297,
      "learning_rate": 4.474795346833262e-05,
      "loss": 0.508,
      "step": 1220
    },
    {
      "epoch": 0.5299439896596295,
      "grad_norm": 7.91379976272583,
      "learning_rate": 4.470486859112451e-05,
      "loss": 0.6152,
      "step": 1230
    },
    {
      "epoch": 0.5342524773804395,
      "grad_norm": 4.923563003540039,
      "learning_rate": 4.4661783713916414e-05,
      "loss": 0.6022,
      "step": 1240
    },
    {
      "epoch": 0.5385609651012495,
      "grad_norm": 5.1128997802734375,
      "learning_rate": 4.4618698836708315e-05,
      "loss": 0.4495,
      "step": 1250
    },
    {
      "epoch": 0.5428694528220595,
      "grad_norm": 7.744036674499512,
      "learning_rate": 4.4575613959500216e-05,
      "loss": 0.4415,
      "step": 1260
    },
    {
      "epoch": 0.5471779405428695,
      "grad_norm": 8.049659729003906,
      "learning_rate": 4.453252908229212e-05,
      "loss": 0.6425,
      "step": 1270
    },
    {
      "epoch": 0.5514864282636794,
      "grad_norm": 9.364435195922852,
      "learning_rate": 4.448944420508402e-05,
      "loss": 0.5702,
      "step": 1280
    },
    {
      "epoch": 0.5557949159844895,
      "grad_norm": 2.8378918170928955,
      "learning_rate": 4.444635932787592e-05,
      "loss": 0.5971,
      "step": 1290
    },
    {
      "epoch": 0.5601034037052994,
      "grad_norm": 5.883237361907959,
      "learning_rate": 4.440327445066782e-05,
      "loss": 0.5557,
      "step": 1300
    },
    {
      "epoch": 0.5644118914261095,
      "grad_norm": 7.662144660949707,
      "learning_rate": 4.4360189573459716e-05,
      "loss": 0.4831,
      "step": 1310
    },
    {
      "epoch": 0.5687203791469194,
      "grad_norm": 4.548491477966309,
      "learning_rate": 4.431710469625162e-05,
      "loss": 0.5379,
      "step": 1320
    },
    {
      "epoch": 0.5730288668677295,
      "grad_norm": 2.3554790019989014,
      "learning_rate": 4.427401981904352e-05,
      "loss": 0.414,
      "step": 1330
    },
    {
      "epoch": 0.5773373545885394,
      "grad_norm": 4.871617794036865,
      "learning_rate": 4.423093494183542e-05,
      "loss": 0.5514,
      "step": 1340
    },
    {
      "epoch": 0.5816458423093495,
      "grad_norm": 3.392866849899292,
      "learning_rate": 4.418785006462732e-05,
      "loss": 0.495,
      "step": 1350
    },
    {
      "epoch": 0.5859543300301594,
      "grad_norm": 6.208298206329346,
      "learning_rate": 4.4144765187419215e-05,
      "loss": 0.4265,
      "step": 1360
    },
    {
      "epoch": 0.5902628177509694,
      "grad_norm": 6.165576457977295,
      "learning_rate": 4.4101680310211116e-05,
      "loss": 0.5412,
      "step": 1370
    },
    {
      "epoch": 0.5945713054717794,
      "grad_norm": 9.817645072937012,
      "learning_rate": 4.405859543300302e-05,
      "loss": 0.5451,
      "step": 1380
    },
    {
      "epoch": 0.5988797931925894,
      "grad_norm": 11.984471321105957,
      "learning_rate": 4.401551055579492e-05,
      "loss": 0.4883,
      "step": 1390
    },
    {
      "epoch": 0.6031882809133994,
      "grad_norm": 9.165369033813477,
      "learning_rate": 4.397242567858682e-05,
      "loss": 0.6603,
      "step": 1400
    },
    {
      "epoch": 0.6074967686342094,
      "grad_norm": 7.584064483642578,
      "learning_rate": 4.3929340801378714e-05,
      "loss": 0.524,
      "step": 1410
    },
    {
      "epoch": 0.6118052563550194,
      "grad_norm": 3.058974504470825,
      "learning_rate": 4.3886255924170615e-05,
      "loss": 0.4915,
      "step": 1420
    },
    {
      "epoch": 0.6161137440758294,
      "grad_norm": 5.989039421081543,
      "learning_rate": 4.3843171046962517e-05,
      "loss": 0.6082,
      "step": 1430
    },
    {
      "epoch": 0.6204222317966394,
      "grad_norm": 5.057097434997559,
      "learning_rate": 4.380008616975442e-05,
      "loss": 0.5348,
      "step": 1440
    },
    {
      "epoch": 0.6247307195174494,
      "grad_norm": 5.169602394104004,
      "learning_rate": 4.375700129254632e-05,
      "loss": 0.4756,
      "step": 1450
    },
    {
      "epoch": 0.6290392072382593,
      "grad_norm": 3.645259380340576,
      "learning_rate": 4.371391641533822e-05,
      "loss": 0.4939,
      "step": 1460
    },
    {
      "epoch": 0.6333476949590694,
      "grad_norm": 4.197673797607422,
      "learning_rate": 4.367083153813012e-05,
      "loss": 0.4918,
      "step": 1470
    },
    {
      "epoch": 0.6376561826798793,
      "grad_norm": 12.374217987060547,
      "learning_rate": 4.362774666092202e-05,
      "loss": 0.5206,
      "step": 1480
    },
    {
      "epoch": 0.6419646704006894,
      "grad_norm": 4.9568095207214355,
      "learning_rate": 4.358466178371392e-05,
      "loss": 0.5797,
      "step": 1490
    },
    {
      "epoch": 0.6462731581214993,
      "grad_norm": 3.7884790897369385,
      "learning_rate": 4.354157690650582e-05,
      "loss": 0.502,
      "step": 1500
    },
    {
      "epoch": 0.6505816458423094,
      "grad_norm": 2.8625271320343018,
      "learning_rate": 4.349849202929771e-05,
      "loss": 0.4629,
      "step": 1510
    },
    {
      "epoch": 0.6548901335631193,
      "grad_norm": 7.628900051116943,
      "learning_rate": 4.3455407152089614e-05,
      "loss": 0.5383,
      "step": 1520
    },
    {
      "epoch": 0.6591986212839294,
      "grad_norm": 5.027743816375732,
      "learning_rate": 4.3412322274881515e-05,
      "loss": 0.4321,
      "step": 1530
    },
    {
      "epoch": 0.6635071090047393,
      "grad_norm": 7.800188064575195,
      "learning_rate": 4.3369237397673416e-05,
      "loss": 0.5554,
      "step": 1540
    },
    {
      "epoch": 0.6678155967255494,
      "grad_norm": 9.20002555847168,
      "learning_rate": 4.332615252046532e-05,
      "loss": 0.5558,
      "step": 1550
    },
    {
      "epoch": 0.6721240844463593,
      "grad_norm": 4.9868998527526855,
      "learning_rate": 4.328306764325722e-05,
      "loss": 0.5926,
      "step": 1560
    },
    {
      "epoch": 0.6764325721671693,
      "grad_norm": 5.081386089324951,
      "learning_rate": 4.323998276604912e-05,
      "loss": 0.3763,
      "step": 1570
    },
    {
      "epoch": 0.6807410598879793,
      "grad_norm": 6.720835208892822,
      "learning_rate": 4.319689788884102e-05,
      "loss": 0.4548,
      "step": 1580
    },
    {
      "epoch": 0.6850495476087893,
      "grad_norm": 4.407772064208984,
      "learning_rate": 4.315381301163292e-05,
      "loss": 0.6115,
      "step": 1590
    },
    {
      "epoch": 0.6893580353295993,
      "grad_norm": 4.213388919830322,
      "learning_rate": 4.3110728134424824e-05,
      "loss": 0.6319,
      "step": 1600
    },
    {
      "epoch": 0.6936665230504093,
      "grad_norm": 1.800727128982544,
      "learning_rate": 4.306764325721672e-05,
      "loss": 0.435,
      "step": 1610
    },
    {
      "epoch": 0.6979750107712193,
      "grad_norm": 9.734642028808594,
      "learning_rate": 4.302455838000862e-05,
      "loss": 0.5335,
      "step": 1620
    },
    {
      "epoch": 0.7022834984920293,
      "grad_norm": 5.033514022827148,
      "learning_rate": 4.298147350280052e-05,
      "loss": 0.4004,
      "step": 1630
    },
    {
      "epoch": 0.7065919862128393,
      "grad_norm": 2.605792999267578,
      "learning_rate": 4.293838862559242e-05,
      "loss": 0.5169,
      "step": 1640
    },
    {
      "epoch": 0.7109004739336493,
      "grad_norm": 12.471551895141602,
      "learning_rate": 4.2895303748384316e-05,
      "loss": 0.7198,
      "step": 1650
    },
    {
      "epoch": 0.7152089616544592,
      "grad_norm": 4.9688005447387695,
      "learning_rate": 4.285221887117622e-05,
      "loss": 0.6024,
      "step": 1660
    },
    {
      "epoch": 0.7195174493752693,
      "grad_norm": 4.5978779792785645,
      "learning_rate": 4.280913399396812e-05,
      "loss": 0.5608,
      "step": 1670
    },
    {
      "epoch": 0.7238259370960792,
      "grad_norm": 8.037457466125488,
      "learning_rate": 4.276604911676002e-05,
      "loss": 0.4359,
      "step": 1680
    },
    {
      "epoch": 0.7281344248168893,
      "grad_norm": 5.689809322357178,
      "learning_rate": 4.272296423955192e-05,
      "loss": 0.5829,
      "step": 1690
    },
    {
      "epoch": 0.7324429125376992,
      "grad_norm": 11.282492637634277,
      "learning_rate": 4.267987936234382e-05,
      "loss": 0.5465,
      "step": 1700
    },
    {
      "epoch": 0.7367514002585093,
      "grad_norm": 5.262845993041992,
      "learning_rate": 4.263679448513572e-05,
      "loss": 0.5264,
      "step": 1710
    },
    {
      "epoch": 0.7410598879793192,
      "grad_norm": 4.9345784187316895,
      "learning_rate": 4.259370960792762e-05,
      "loss": 0.4383,
      "step": 1720
    },
    {
      "epoch": 0.7453683757001293,
      "grad_norm": 9.00161075592041,
      "learning_rate": 4.255062473071952e-05,
      "loss": 0.5842,
      "step": 1730
    },
    {
      "epoch": 0.7496768634209392,
      "grad_norm": 6.159489154815674,
      "learning_rate": 4.250753985351142e-05,
      "loss": 0.5094,
      "step": 1740
    },
    {
      "epoch": 0.7539853511417492,
      "grad_norm": 4.776455879211426,
      "learning_rate": 4.246445497630332e-05,
      "loss": 0.4935,
      "step": 1750
    },
    {
      "epoch": 0.7582938388625592,
      "grad_norm": 6.877500534057617,
      "learning_rate": 4.242137009909522e-05,
      "loss": 0.5149,
      "step": 1760
    },
    {
      "epoch": 0.7626023265833692,
      "grad_norm": 9.990538597106934,
      "learning_rate": 4.2378285221887124e-05,
      "loss": 0.5726,
      "step": 1770
    },
    {
      "epoch": 0.7669108143041792,
      "grad_norm": 3.8846168518066406,
      "learning_rate": 4.233520034467902e-05,
      "loss": 0.4989,
      "step": 1780
    },
    {
      "epoch": 0.7712193020249892,
      "grad_norm": 11.77083683013916,
      "learning_rate": 4.229211546747092e-05,
      "loss": 0.5982,
      "step": 1790
    },
    {
      "epoch": 0.7755277897457993,
      "grad_norm": 6.157454013824463,
      "learning_rate": 4.224903059026282e-05,
      "loss": 0.5253,
      "step": 1800
    },
    {
      "epoch": 0.7798362774666092,
      "grad_norm": 6.4419145584106445,
      "learning_rate": 4.2205945713054715e-05,
      "loss": 0.4646,
      "step": 1810
    },
    {
      "epoch": 0.7841447651874193,
      "grad_norm": 3.0198826789855957,
      "learning_rate": 4.2162860835846617e-05,
      "loss": 0.6185,
      "step": 1820
    },
    {
      "epoch": 0.7884532529082292,
      "grad_norm": 5.749161243438721,
      "learning_rate": 4.211977595863852e-05,
      "loss": 0.4988,
      "step": 1830
    },
    {
      "epoch": 0.7927617406290393,
      "grad_norm": 6.631546974182129,
      "learning_rate": 4.207669108143042e-05,
      "loss": 0.5028,
      "step": 1840
    },
    {
      "epoch": 0.7970702283498492,
      "grad_norm": 9.872796058654785,
      "learning_rate": 4.203360620422232e-05,
      "loss": 0.5085,
      "step": 1850
    },
    {
      "epoch": 0.8013787160706592,
      "grad_norm": 4.669212341308594,
      "learning_rate": 4.199052132701422e-05,
      "loss": 0.3984,
      "step": 1860
    },
    {
      "epoch": 0.8056872037914692,
      "grad_norm": 8.90999698638916,
      "learning_rate": 4.194743644980612e-05,
      "loss": 0.4251,
      "step": 1870
    },
    {
      "epoch": 0.8099956915122792,
      "grad_norm": 7.183155536651611,
      "learning_rate": 4.1904351572598024e-05,
      "loss": 0.5072,
      "step": 1880
    },
    {
      "epoch": 0.8143041792330892,
      "grad_norm": 11.93134593963623,
      "learning_rate": 4.1861266695389925e-05,
      "loss": 0.6579,
      "step": 1890
    },
    {
      "epoch": 0.8186126669538992,
      "grad_norm": 6.837702751159668,
      "learning_rate": 4.181818181818182e-05,
      "loss": 0.5712,
      "step": 1900
    },
    {
      "epoch": 0.8229211546747092,
      "grad_norm": 4.668255805969238,
      "learning_rate": 4.177509694097372e-05,
      "loss": 0.5386,
      "step": 1910
    },
    {
      "epoch": 0.8272296423955192,
      "grad_norm": 7.819020748138428,
      "learning_rate": 4.173201206376562e-05,
      "loss": 0.6157,
      "step": 1920
    },
    {
      "epoch": 0.8315381301163292,
      "grad_norm": 5.891416072845459,
      "learning_rate": 4.1688927186557516e-05,
      "loss": 0.3923,
      "step": 1930
    },
    {
      "epoch": 0.8358466178371392,
      "grad_norm": 11.701703071594238,
      "learning_rate": 4.164584230934942e-05,
      "loss": 0.4785,
      "step": 1940
    },
    {
      "epoch": 0.8401551055579491,
      "grad_norm": 2.491105794906616,
      "learning_rate": 4.160275743214132e-05,
      "loss": 0.59,
      "step": 1950
    },
    {
      "epoch": 0.8444635932787592,
      "grad_norm": 2.884230136871338,
      "learning_rate": 4.155967255493322e-05,
      "loss": 0.4496,
      "step": 1960
    },
    {
      "epoch": 0.8487720809995691,
      "grad_norm": 2.506580352783203,
      "learning_rate": 4.151658767772512e-05,
      "loss": 0.3739,
      "step": 1970
    },
    {
      "epoch": 0.8530805687203792,
      "grad_norm": 8.841599464416504,
      "learning_rate": 4.147350280051702e-05,
      "loss": 0.4274,
      "step": 1980
    },
    {
      "epoch": 0.8573890564411891,
      "grad_norm": 10.326571464538574,
      "learning_rate": 4.1430417923308924e-05,
      "loss": 0.5067,
      "step": 1990
    },
    {
      "epoch": 0.8616975441619992,
      "grad_norm": 4.384904384613037,
      "learning_rate": 4.138733304610082e-05,
      "loss": 0.5044,
      "step": 2000
    },
    {
      "epoch": 0.8660060318828091,
      "grad_norm": 7.468048095703125,
      "learning_rate": 4.134424816889272e-05,
      "loss": 0.5481,
      "step": 2010
    },
    {
      "epoch": 0.8703145196036192,
      "grad_norm": 3.796863555908203,
      "learning_rate": 4.130116329168462e-05,
      "loss": 0.4131,
      "step": 2020
    },
    {
      "epoch": 0.8746230073244291,
      "grad_norm": 6.331583023071289,
      "learning_rate": 4.125807841447652e-05,
      "loss": 0.5422,
      "step": 2030
    },
    {
      "epoch": 0.8789314950452392,
      "grad_norm": 10.263750076293945,
      "learning_rate": 4.121499353726842e-05,
      "loss": 0.5083,
      "step": 2040
    },
    {
      "epoch": 0.8832399827660491,
      "grad_norm": 3.8343210220336914,
      "learning_rate": 4.1171908660060324e-05,
      "loss": 0.488,
      "step": 2050
    },
    {
      "epoch": 0.8875484704868591,
      "grad_norm": 5.732907772064209,
      "learning_rate": 4.112882378285222e-05,
      "loss": 0.4499,
      "step": 2060
    },
    {
      "epoch": 0.8918569582076691,
      "grad_norm": 8.22469711303711,
      "learning_rate": 4.108573890564412e-05,
      "loss": 0.6236,
      "step": 2070
    },
    {
      "epoch": 0.8961654459284791,
      "grad_norm": 2.6207592487335205,
      "learning_rate": 4.104265402843602e-05,
      "loss": 0.3388,
      "step": 2080
    },
    {
      "epoch": 0.9004739336492891,
      "grad_norm": 4.649816989898682,
      "learning_rate": 4.099956915122792e-05,
      "loss": 0.4644,
      "step": 2090
    },
    {
      "epoch": 0.9047824213700991,
      "grad_norm": 7.403257369995117,
      "learning_rate": 4.095648427401982e-05,
      "loss": 0.4726,
      "step": 2100
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 2.667357921600342,
      "learning_rate": 4.091339939681172e-05,
      "loss": 0.5561,
      "step": 2110
    },
    {
      "epoch": 0.9133993968117191,
      "grad_norm": 5.171706199645996,
      "learning_rate": 4.087031451960362e-05,
      "loss": 0.4461,
      "step": 2120
    },
    {
      "epoch": 0.917707884532529,
      "grad_norm": 8.215530395507812,
      "learning_rate": 4.082722964239552e-05,
      "loss": 0.4799,
      "step": 2130
    },
    {
      "epoch": 0.9220163722533391,
      "grad_norm": 3.3789572715759277,
      "learning_rate": 4.078414476518742e-05,
      "loss": 0.4907,
      "step": 2140
    },
    {
      "epoch": 0.926324859974149,
      "grad_norm": 7.9554829597473145,
      "learning_rate": 4.074105988797932e-05,
      "loss": 0.5397,
      "step": 2150
    },
    {
      "epoch": 0.9306333476949591,
      "grad_norm": 3.9524431228637695,
      "learning_rate": 4.0697975010771224e-05,
      "loss": 0.5624,
      "step": 2160
    },
    {
      "epoch": 0.934941835415769,
      "grad_norm": 6.050136089324951,
      "learning_rate": 4.0654890133563125e-05,
      "loss": 0.5614,
      "step": 2170
    },
    {
      "epoch": 0.9392503231365791,
      "grad_norm": 4.2427849769592285,
      "learning_rate": 4.0611805256355026e-05,
      "loss": 0.4907,
      "step": 2180
    },
    {
      "epoch": 0.943558810857389,
      "grad_norm": 4.302005290985107,
      "learning_rate": 4.056872037914692e-05,
      "loss": 0.506,
      "step": 2190
    },
    {
      "epoch": 0.9478672985781991,
      "grad_norm": 4.8727946281433105,
      "learning_rate": 4.052563550193882e-05,
      "loss": 0.5648,
      "step": 2200
    },
    {
      "epoch": 0.952175786299009,
      "grad_norm": 5.077223300933838,
      "learning_rate": 4.0482550624730716e-05,
      "loss": 0.5046,
      "step": 2210
    },
    {
      "epoch": 0.9564842740198191,
      "grad_norm": 5.482575416564941,
      "learning_rate": 4.043946574752262e-05,
      "loss": 0.5036,
      "step": 2220
    },
    {
      "epoch": 0.960792761740629,
      "grad_norm": 3.4120349884033203,
      "learning_rate": 4.039638087031452e-05,
      "loss": 0.3886,
      "step": 2230
    },
    {
      "epoch": 0.965101249461439,
      "grad_norm": 12.105819702148438,
      "learning_rate": 4.035329599310642e-05,
      "loss": 0.5352,
      "step": 2240
    },
    {
      "epoch": 0.969409737182249,
      "grad_norm": 4.720788955688477,
      "learning_rate": 4.031021111589832e-05,
      "loss": 0.4641,
      "step": 2250
    },
    {
      "epoch": 0.973718224903059,
      "grad_norm": 5.935970783233643,
      "learning_rate": 4.026712623869022e-05,
      "loss": 0.4109,
      "step": 2260
    },
    {
      "epoch": 0.978026712623869,
      "grad_norm": 3.6637301445007324,
      "learning_rate": 4.0224041361482124e-05,
      "loss": 0.4492,
      "step": 2270
    },
    {
      "epoch": 0.982335200344679,
      "grad_norm": 2.117865562438965,
      "learning_rate": 4.0180956484274025e-05,
      "loss": 0.432,
      "step": 2280
    },
    {
      "epoch": 0.986643688065489,
      "grad_norm": 9.336099624633789,
      "learning_rate": 4.0137871607065926e-05,
      "loss": 0.5161,
      "step": 2290
    },
    {
      "epoch": 0.990952175786299,
      "grad_norm": 6.746401786804199,
      "learning_rate": 4.009478672985782e-05,
      "loss": 0.4332,
      "step": 2300
    },
    {
      "epoch": 0.995260663507109,
      "grad_norm": 2.8112220764160156,
      "learning_rate": 4.005170185264972e-05,
      "loss": 0.415,
      "step": 2310
    },
    {
      "epoch": 0.999569151227919,
      "grad_norm": 7.850575923919678,
      "learning_rate": 4.000861697544162e-05,
      "loss": 0.4831,
      "step": 2320
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.5121205449104309,
      "eval_runtime": 26.5886,
      "eval_samples_per_second": 598.489,
      "eval_steps_per_second": 37.422,
      "step": 2321
    },
    {
      "epoch": 1.003877638948729,
      "grad_norm": 3.590897560119629,
      "learning_rate": 3.9965532098233524e-05,
      "loss": 0.4013,
      "step": 2330
    },
    {
      "epoch": 1.0081861266695389,
      "grad_norm": 5.675052165985107,
      "learning_rate": 3.992244722102542e-05,
      "loss": 0.3745,
      "step": 2340
    },
    {
      "epoch": 1.012494614390349,
      "grad_norm": 7.889562606811523,
      "learning_rate": 3.987936234381732e-05,
      "loss": 0.4262,
      "step": 2350
    },
    {
      "epoch": 1.016803102111159,
      "grad_norm": 2.5647552013397217,
      "learning_rate": 3.983627746660922e-05,
      "loss": 0.3824,
      "step": 2360
    },
    {
      "epoch": 1.021111589831969,
      "grad_norm": 8.13225269317627,
      "learning_rate": 3.979319258940112e-05,
      "loss": 0.359,
      "step": 2370
    },
    {
      "epoch": 1.0254200775527789,
      "grad_norm": 10.322821617126465,
      "learning_rate": 3.9750107712193024e-05,
      "loss": 0.437,
      "step": 2380
    },
    {
      "epoch": 1.029728565273589,
      "grad_norm": 7.900618553161621,
      "learning_rate": 3.9707022834984925e-05,
      "loss": 0.4265,
      "step": 2390
    },
    {
      "epoch": 1.034037052994399,
      "grad_norm": 7.103431224822998,
      "learning_rate": 3.966393795777682e-05,
      "loss": 0.4348,
      "step": 2400
    },
    {
      "epoch": 1.038345540715209,
      "grad_norm": 6.28530740737915,
      "learning_rate": 3.962085308056872e-05,
      "loss": 0.4967,
      "step": 2410
    },
    {
      "epoch": 1.042654028436019,
      "grad_norm": 4.171532154083252,
      "learning_rate": 3.957776820336062e-05,
      "loss": 0.3537,
      "step": 2420
    },
    {
      "epoch": 1.046962516156829,
      "grad_norm": 4.412185192108154,
      "learning_rate": 3.953468332615252e-05,
      "loss": 0.3191,
      "step": 2430
    },
    {
      "epoch": 1.051271003877639,
      "grad_norm": 10.719310760498047,
      "learning_rate": 3.9491598448944424e-05,
      "loss": 0.3395,
      "step": 2440
    },
    {
      "epoch": 1.0555794915984489,
      "grad_norm": 4.498292922973633,
      "learning_rate": 3.9448513571736325e-05,
      "loss": 0.3738,
      "step": 2450
    },
    {
      "epoch": 1.059887979319259,
      "grad_norm": 4.202781677246094,
      "learning_rate": 3.9405428694528226e-05,
      "loss": 0.3898,
      "step": 2460
    },
    {
      "epoch": 1.064196467040069,
      "grad_norm": 5.694620609283447,
      "learning_rate": 3.936234381732012e-05,
      "loss": 0.531,
      "step": 2470
    },
    {
      "epoch": 1.068504954760879,
      "grad_norm": 13.147635459899902,
      "learning_rate": 3.931925894011202e-05,
      "loss": 0.4425,
      "step": 2480
    },
    {
      "epoch": 1.0728134424816889,
      "grad_norm": 6.125572204589844,
      "learning_rate": 3.9276174062903917e-05,
      "loss": 0.258,
      "step": 2490
    },
    {
      "epoch": 1.077121930202499,
      "grad_norm": 3.823010206222534,
      "learning_rate": 3.923308918569582e-05,
      "loss": 0.3197,
      "step": 2500
    },
    {
      "epoch": 1.081430417923309,
      "grad_norm": 4.211146831512451,
      "learning_rate": 3.919000430848772e-05,
      "loss": 0.3074,
      "step": 2510
    },
    {
      "epoch": 1.085738905644119,
      "grad_norm": 5.083492279052734,
      "learning_rate": 3.914691943127962e-05,
      "loss": 0.3119,
      "step": 2520
    },
    {
      "epoch": 1.0900473933649288,
      "grad_norm": 5.5972676277160645,
      "learning_rate": 3.910383455407152e-05,
      "loss": 0.4341,
      "step": 2530
    },
    {
      "epoch": 1.094355881085739,
      "grad_norm": 5.191241264343262,
      "learning_rate": 3.906074967686342e-05,
      "loss": 0.4288,
      "step": 2540
    },
    {
      "epoch": 1.098664368806549,
      "grad_norm": 5.28058385848999,
      "learning_rate": 3.9017664799655324e-05,
      "loss": 0.3357,
      "step": 2550
    },
    {
      "epoch": 1.1029728565273589,
      "grad_norm": 3.457998275756836,
      "learning_rate": 3.8974579922447225e-05,
      "loss": 0.506,
      "step": 2560
    },
    {
      "epoch": 1.1072813442481688,
      "grad_norm": 9.727873802185059,
      "learning_rate": 3.8931495045239126e-05,
      "loss": 0.3886,
      "step": 2570
    },
    {
      "epoch": 1.111589831968979,
      "grad_norm": 9.315020561218262,
      "learning_rate": 3.888841016803103e-05,
      "loss": 0.3304,
      "step": 2580
    },
    {
      "epoch": 1.115898319689789,
      "grad_norm": 3.339148759841919,
      "learning_rate": 3.884532529082292e-05,
      "loss": 0.3537,
      "step": 2590
    },
    {
      "epoch": 1.1202068074105989,
      "grad_norm": 6.557057857513428,
      "learning_rate": 3.880224041361482e-05,
      "loss": 0.3201,
      "step": 2600
    },
    {
      "epoch": 1.1245152951314088,
      "grad_norm": 7.360129356384277,
      "learning_rate": 3.8759155536406724e-05,
      "loss": 0.3276,
      "step": 2610
    },
    {
      "epoch": 1.128823782852219,
      "grad_norm": 12.392404556274414,
      "learning_rate": 3.871607065919862e-05,
      "loss": 0.3571,
      "step": 2620
    },
    {
      "epoch": 1.133132270573029,
      "grad_norm": 11.78181266784668,
      "learning_rate": 3.867298578199052e-05,
      "loss": 0.336,
      "step": 2630
    },
    {
      "epoch": 1.1374407582938388,
      "grad_norm": 9.637672424316406,
      "learning_rate": 3.862990090478242e-05,
      "loss": 0.377,
      "step": 2640
    },
    {
      "epoch": 1.1417492460146488,
      "grad_norm": 4.089710712432861,
      "learning_rate": 3.858681602757432e-05,
      "loss": 0.4218,
      "step": 2650
    },
    {
      "epoch": 1.146057733735459,
      "grad_norm": 5.981358528137207,
      "learning_rate": 3.8543731150366224e-05,
      "loss": 0.2806,
      "step": 2660
    },
    {
      "epoch": 1.1503662214562689,
      "grad_norm": 2.088326930999756,
      "learning_rate": 3.8500646273158125e-05,
      "loss": 0.3504,
      "step": 2670
    },
    {
      "epoch": 1.1546747091770788,
      "grad_norm": 5.3387041091918945,
      "learning_rate": 3.8457561395950026e-05,
      "loss": 0.3132,
      "step": 2680
    },
    {
      "epoch": 1.1589831968978888,
      "grad_norm": 2.8282718658447266,
      "learning_rate": 3.841447651874192e-05,
      "loss": 0.4528,
      "step": 2690
    },
    {
      "epoch": 1.163291684618699,
      "grad_norm": 5.619887351989746,
      "learning_rate": 3.837139164153382e-05,
      "loss": 0.3727,
      "step": 2700
    },
    {
      "epoch": 1.1676001723395089,
      "grad_norm": 11.454253196716309,
      "learning_rate": 3.832830676432572e-05,
      "loss": 0.4651,
      "step": 2710
    },
    {
      "epoch": 1.1719086600603188,
      "grad_norm": 12.063057899475098,
      "learning_rate": 3.8285221887117624e-05,
      "loss": 0.4125,
      "step": 2720
    },
    {
      "epoch": 1.1762171477811287,
      "grad_norm": 6.342136859893799,
      "learning_rate": 3.8242137009909525e-05,
      "loss": 0.4177,
      "step": 2730
    },
    {
      "epoch": 1.180525635501939,
      "grad_norm": 2.2959327697753906,
      "learning_rate": 3.8199052132701427e-05,
      "loss": 0.3334,
      "step": 2740
    },
    {
      "epoch": 1.1848341232227488,
      "grad_norm": 4.721611976623535,
      "learning_rate": 3.815596725549333e-05,
      "loss": 0.4173,
      "step": 2750
    },
    {
      "epoch": 1.1891426109435588,
      "grad_norm": 8.547126770019531,
      "learning_rate": 3.811288237828522e-05,
      "loss": 0.4862,
      "step": 2760
    },
    {
      "epoch": 1.1934510986643687,
      "grad_norm": 6.098475933074951,
      "learning_rate": 3.8069797501077123e-05,
      "loss": 0.3804,
      "step": 2770
    },
    {
      "epoch": 1.1977595863851789,
      "grad_norm": 12.813690185546875,
      "learning_rate": 3.8026712623869025e-05,
      "loss": 0.3483,
      "step": 2780
    },
    {
      "epoch": 1.2020680741059888,
      "grad_norm": 4.839543342590332,
      "learning_rate": 3.798362774666092e-05,
      "loss": 0.3352,
      "step": 2790
    },
    {
      "epoch": 1.2063765618267988,
      "grad_norm": 7.472893238067627,
      "learning_rate": 3.794054286945282e-05,
      "loss": 0.3879,
      "step": 2800
    },
    {
      "epoch": 1.2106850495476087,
      "grad_norm": 7.931920528411865,
      "learning_rate": 3.789745799224472e-05,
      "loss": 0.3459,
      "step": 2810
    },
    {
      "epoch": 1.2149935372684189,
      "grad_norm": 9.938498497009277,
      "learning_rate": 3.785437311503662e-05,
      "loss": 0.3627,
      "step": 2820
    },
    {
      "epoch": 1.2193020249892288,
      "grad_norm": 2.9624059200286865,
      "learning_rate": 3.7811288237828524e-05,
      "loss": 0.3512,
      "step": 2830
    },
    {
      "epoch": 1.2236105127100387,
      "grad_norm": 6.105066299438477,
      "learning_rate": 3.7768203360620425e-05,
      "loss": 0.4599,
      "step": 2840
    },
    {
      "epoch": 1.2279190004308487,
      "grad_norm": 4.175017356872559,
      "learning_rate": 3.7725118483412326e-05,
      "loss": 0.4565,
      "step": 2850
    },
    {
      "epoch": 1.2322274881516588,
      "grad_norm": 3.667379856109619,
      "learning_rate": 3.768203360620423e-05,
      "loss": 0.3671,
      "step": 2860
    },
    {
      "epoch": 1.2365359758724688,
      "grad_norm": 2.6347105503082275,
      "learning_rate": 3.763894872899613e-05,
      "loss": 0.329,
      "step": 2870
    },
    {
      "epoch": 1.2408444635932787,
      "grad_norm": 6.771756649017334,
      "learning_rate": 3.759586385178803e-05,
      "loss": 0.4114,
      "step": 2880
    },
    {
      "epoch": 1.2451529513140889,
      "grad_norm": 3.4247117042541504,
      "learning_rate": 3.7552778974579925e-05,
      "loss": 0.315,
      "step": 2890
    },
    {
      "epoch": 1.2494614390348988,
      "grad_norm": 8.205143928527832,
      "learning_rate": 3.7509694097371826e-05,
      "loss": 0.4432,
      "step": 2900
    },
    {
      "epoch": 1.2537699267557088,
      "grad_norm": 6.780346393585205,
      "learning_rate": 3.746660922016372e-05,
      "loss": 0.4346,
      "step": 2910
    },
    {
      "epoch": 1.2580784144765187,
      "grad_norm": 2.7430267333984375,
      "learning_rate": 3.742352434295562e-05,
      "loss": 0.4308,
      "step": 2920
    },
    {
      "epoch": 1.2623869021973286,
      "grad_norm": 6.904043674468994,
      "learning_rate": 3.738043946574752e-05,
      "loss": 0.4005,
      "step": 2930
    },
    {
      "epoch": 1.2666953899181388,
      "grad_norm": 6.762728691101074,
      "learning_rate": 3.7337354588539424e-05,
      "loss": 0.3909,
      "step": 2940
    },
    {
      "epoch": 1.2710038776389487,
      "grad_norm": 1.5036568641662598,
      "learning_rate": 3.7294269711331325e-05,
      "loss": 0.3256,
      "step": 2950
    },
    {
      "epoch": 1.2753123653597587,
      "grad_norm": 7.24104642868042,
      "learning_rate": 3.7251184834123226e-05,
      "loss": 0.4506,
      "step": 2960
    },
    {
      "epoch": 1.2796208530805688,
      "grad_norm": 5.093919277191162,
      "learning_rate": 3.720809995691513e-05,
      "loss": 0.4075,
      "step": 2970
    },
    {
      "epoch": 1.2839293408013788,
      "grad_norm": 5.1535797119140625,
      "learning_rate": 3.716501507970703e-05,
      "loss": 0.4299,
      "step": 2980
    },
    {
      "epoch": 1.2882378285221887,
      "grad_norm": 7.26384162902832,
      "learning_rate": 3.712193020249892e-05,
      "loss": 0.5448,
      "step": 2990
    },
    {
      "epoch": 1.2925463162429986,
      "grad_norm": 3.9906084537506104,
      "learning_rate": 3.7078845325290824e-05,
      "loss": 0.3885,
      "step": 3000
    },
    {
      "epoch": 1.2968548039638086,
      "grad_norm": 2.9181888103485107,
      "learning_rate": 3.7035760448082726e-05,
      "loss": 0.3243,
      "step": 3010
    },
    {
      "epoch": 1.3011632916846188,
      "grad_norm": 3.734663724899292,
      "learning_rate": 3.699267557087463e-05,
      "loss": 0.3515,
      "step": 3020
    },
    {
      "epoch": 1.3054717794054287,
      "grad_norm": 4.04498291015625,
      "learning_rate": 3.694959069366653e-05,
      "loss": 0.3746,
      "step": 3030
    },
    {
      "epoch": 1.3097802671262386,
      "grad_norm": 10.068821907043457,
      "learning_rate": 3.690650581645842e-05,
      "loss": 0.481,
      "step": 3040
    },
    {
      "epoch": 1.3140887548470488,
      "grad_norm": 6.867266654968262,
      "learning_rate": 3.6863420939250324e-05,
      "loss": 0.3873,
      "step": 3050
    },
    {
      "epoch": 1.3183972425678587,
      "grad_norm": 3.8415045738220215,
      "learning_rate": 3.6820336062042225e-05,
      "loss": 0.3756,
      "step": 3060
    },
    {
      "epoch": 1.3227057302886687,
      "grad_norm": 2.747082233428955,
      "learning_rate": 3.6777251184834126e-05,
      "loss": 0.3956,
      "step": 3070
    },
    {
      "epoch": 1.3270142180094786,
      "grad_norm": 3.592060089111328,
      "learning_rate": 3.673416630762602e-05,
      "loss": 0.3424,
      "step": 3080
    },
    {
      "epoch": 1.3313227057302885,
      "grad_norm": 4.507553577423096,
      "learning_rate": 3.669108143041792e-05,
      "loss": 0.3719,
      "step": 3090
    },
    {
      "epoch": 1.3356311934510987,
      "grad_norm": 3.8923749923706055,
      "learning_rate": 3.664799655320982e-05,
      "loss": 0.3386,
      "step": 3100
    },
    {
      "epoch": 1.3399396811719086,
      "grad_norm": 5.306473255157471,
      "learning_rate": 3.6604911676001724e-05,
      "loss": 0.3895,
      "step": 3110
    },
    {
      "epoch": 1.3442481688927186,
      "grad_norm": 6.9235711097717285,
      "learning_rate": 3.6561826798793625e-05,
      "loss": 0.212,
      "step": 3120
    },
    {
      "epoch": 1.3485566566135287,
      "grad_norm": 11.011899948120117,
      "learning_rate": 3.6518741921585527e-05,
      "loss": 0.3894,
      "step": 3130
    },
    {
      "epoch": 1.3528651443343387,
      "grad_norm": 14.221458435058594,
      "learning_rate": 3.647565704437743e-05,
      "loss": 0.3363,
      "step": 3140
    },
    {
      "epoch": 1.3571736320551486,
      "grad_norm": 5.309578895568848,
      "learning_rate": 3.643257216716933e-05,
      "loss": 0.4432,
      "step": 3150
    },
    {
      "epoch": 1.3614821197759586,
      "grad_norm": 6.673636436462402,
      "learning_rate": 3.638948728996123e-05,
      "loss": 0.3362,
      "step": 3160
    },
    {
      "epoch": 1.3657906074967685,
      "grad_norm": 5.481452941894531,
      "learning_rate": 3.6346402412753125e-05,
      "loss": 0.4165,
      "step": 3170
    },
    {
      "epoch": 1.3700990952175787,
      "grad_norm": 4.282834053039551,
      "learning_rate": 3.6303317535545026e-05,
      "loss": 0.3162,
      "step": 3180
    },
    {
      "epoch": 1.3744075829383886,
      "grad_norm": 7.127572059631348,
      "learning_rate": 3.626023265833692e-05,
      "loss": 0.4881,
      "step": 3190
    },
    {
      "epoch": 1.3787160706591985,
      "grad_norm": 5.439055442810059,
      "learning_rate": 3.621714778112882e-05,
      "loss": 0.422,
      "step": 3200
    },
    {
      "epoch": 1.3830245583800087,
      "grad_norm": 5.162664413452148,
      "learning_rate": 3.617406290392072e-05,
      "loss": 0.3567,
      "step": 3210
    },
    {
      "epoch": 1.3873330461008186,
      "grad_norm": 5.15122652053833,
      "learning_rate": 3.6130978026712624e-05,
      "loss": 0.5034,
      "step": 3220
    },
    {
      "epoch": 1.3916415338216286,
      "grad_norm": 3.135503053665161,
      "learning_rate": 3.6087893149504525e-05,
      "loss": 0.3894,
      "step": 3230
    },
    {
      "epoch": 1.3959500215424385,
      "grad_norm": 4.602709770202637,
      "learning_rate": 3.6044808272296426e-05,
      "loss": 0.3038,
      "step": 3240
    },
    {
      "epoch": 1.4002585092632485,
      "grad_norm": 8.103524208068848,
      "learning_rate": 3.600172339508833e-05,
      "loss": 0.4132,
      "step": 3250
    },
    {
      "epoch": 1.4045669969840586,
      "grad_norm": 12.448689460754395,
      "learning_rate": 3.595863851788023e-05,
      "loss": 0.3774,
      "step": 3260
    },
    {
      "epoch": 1.4088754847048686,
      "grad_norm": 3.22906494140625,
      "learning_rate": 3.591555364067213e-05,
      "loss": 0.3966,
      "step": 3270
    },
    {
      "epoch": 1.4131839724256787,
      "grad_norm": 6.741346836090088,
      "learning_rate": 3.5872468763464024e-05,
      "loss": 0.4468,
      "step": 3280
    },
    {
      "epoch": 1.4174924601464887,
      "grad_norm": 5.266461372375488,
      "learning_rate": 3.5829383886255926e-05,
      "loss": 0.4011,
      "step": 3290
    },
    {
      "epoch": 1.4218009478672986,
      "grad_norm": 3.758918523788452,
      "learning_rate": 3.578629900904783e-05,
      "loss": 0.4172,
      "step": 3300
    },
    {
      "epoch": 1.4261094355881085,
      "grad_norm": 9.83901596069336,
      "learning_rate": 3.574321413183973e-05,
      "loss": 0.3724,
      "step": 3310
    },
    {
      "epoch": 1.4304179233089185,
      "grad_norm": 7.488256454467773,
      "learning_rate": 3.570012925463162e-05,
      "loss": 0.3816,
      "step": 3320
    },
    {
      "epoch": 1.4347264110297286,
      "grad_norm": 5.643843173980713,
      "learning_rate": 3.5657044377423524e-05,
      "loss": 0.3958,
      "step": 3330
    },
    {
      "epoch": 1.4390348987505386,
      "grad_norm": 1.4038904905319214,
      "learning_rate": 3.5613959500215425e-05,
      "loss": 0.3383,
      "step": 3340
    },
    {
      "epoch": 1.4433433864713485,
      "grad_norm": 7.81384801864624,
      "learning_rate": 3.5570874623007326e-05,
      "loss": 0.3152,
      "step": 3350
    },
    {
      "epoch": 1.4476518741921587,
      "grad_norm": 2.6408941745758057,
      "learning_rate": 3.552778974579923e-05,
      "loss": 0.2925,
      "step": 3360
    },
    {
      "epoch": 1.4519603619129686,
      "grad_norm": 2.4843995571136475,
      "learning_rate": 3.548470486859113e-05,
      "loss": 0.3852,
      "step": 3370
    },
    {
      "epoch": 1.4562688496337786,
      "grad_norm": 19.516124725341797,
      "learning_rate": 3.544161999138302e-05,
      "loss": 0.3319,
      "step": 3380
    },
    {
      "epoch": 1.4605773373545885,
      "grad_norm": 6.006778240203857,
      "learning_rate": 3.5398535114174924e-05,
      "loss": 0.3548,
      "step": 3390
    },
    {
      "epoch": 1.4648858250753984,
      "grad_norm": 5.596940517425537,
      "learning_rate": 3.5355450236966825e-05,
      "loss": 0.3773,
      "step": 3400
    },
    {
      "epoch": 1.4691943127962086,
      "grad_norm": 5.61509370803833,
      "learning_rate": 3.531236535975873e-05,
      "loss": 0.3552,
      "step": 3410
    },
    {
      "epoch": 1.4735028005170185,
      "grad_norm": 4.9271626472473145,
      "learning_rate": 3.526928048255063e-05,
      "loss": 0.2705,
      "step": 3420
    },
    {
      "epoch": 1.4778112882378285,
      "grad_norm": 4.889643669128418,
      "learning_rate": 3.522619560534253e-05,
      "loss": 0.3649,
      "step": 3430
    },
    {
      "epoch": 1.4821197759586386,
      "grad_norm": 4.521627426147461,
      "learning_rate": 3.518311072813443e-05,
      "loss": 0.4459,
      "step": 3440
    },
    {
      "epoch": 1.4864282636794486,
      "grad_norm": 8.345513343811035,
      "learning_rate": 3.5140025850926325e-05,
      "loss": 0.2991,
      "step": 3450
    },
    {
      "epoch": 1.4907367514002585,
      "grad_norm": 10.06977653503418,
      "learning_rate": 3.5096940973718226e-05,
      "loss": 0.3356,
      "step": 3460
    },
    {
      "epoch": 1.4950452391210685,
      "grad_norm": 6.089879035949707,
      "learning_rate": 3.505385609651013e-05,
      "loss": 0.3466,
      "step": 3470
    },
    {
      "epoch": 1.4993537268418784,
      "grad_norm": 14.126886367797852,
      "learning_rate": 3.501077121930202e-05,
      "loss": 0.3428,
      "step": 3480
    },
    {
      "epoch": 1.5036622145626883,
      "grad_norm": 3.5428171157836914,
      "learning_rate": 3.496768634209392e-05,
      "loss": 0.3549,
      "step": 3490
    },
    {
      "epoch": 1.5079707022834985,
      "grad_norm": 13.688278198242188,
      "learning_rate": 3.4924601464885824e-05,
      "loss": 0.2979,
      "step": 3500
    },
    {
      "epoch": 1.5122791900043084,
      "grad_norm": 10.240434646606445,
      "learning_rate": 3.4881516587677725e-05,
      "loss": 0.4014,
      "step": 3510
    },
    {
      "epoch": 1.5165876777251186,
      "grad_norm": 10.629980087280273,
      "learning_rate": 3.4838431710469626e-05,
      "loss": 0.5758,
      "step": 3520
    },
    {
      "epoch": 1.5208961654459285,
      "grad_norm": 2.48677921295166,
      "learning_rate": 3.479534683326153e-05,
      "loss": 0.3391,
      "step": 3530
    },
    {
      "epoch": 1.5252046531667385,
      "grad_norm": 7.115779876708984,
      "learning_rate": 3.475226195605343e-05,
      "loss": 0.4854,
      "step": 3540
    },
    {
      "epoch": 1.5295131408875484,
      "grad_norm": 2.428730010986328,
      "learning_rate": 3.470917707884533e-05,
      "loss": 0.3509,
      "step": 3550
    },
    {
      "epoch": 1.5338216286083584,
      "grad_norm": 12.15073013305664,
      "learning_rate": 3.466609220163723e-05,
      "loss": 0.4811,
      "step": 3560
    },
    {
      "epoch": 1.5381301163291683,
      "grad_norm": 9.884544372558594,
      "learning_rate": 3.462300732442913e-05,
      "loss": 0.3005,
      "step": 3570
    },
    {
      "epoch": 1.5424386040499785,
      "grad_norm": 9.661035537719727,
      "learning_rate": 3.457992244722103e-05,
      "loss": 0.425,
      "step": 3580
    },
    {
      "epoch": 1.5467470917707886,
      "grad_norm": 7.527974605560303,
      "learning_rate": 3.453683757001293e-05,
      "loss": 0.3634,
      "step": 3590
    },
    {
      "epoch": 1.5510555794915986,
      "grad_norm": 8.534478187561035,
      "learning_rate": 3.449375269280482e-05,
      "loss": 0.4686,
      "step": 3600
    },
    {
      "epoch": 1.5553640672124085,
      "grad_norm": 16.75236701965332,
      "learning_rate": 3.4450667815596724e-05,
      "loss": 0.3311,
      "step": 3610
    },
    {
      "epoch": 1.5596725549332184,
      "grad_norm": 8.447901725769043,
      "learning_rate": 3.4407582938388625e-05,
      "loss": 0.3838,
      "step": 3620
    },
    {
      "epoch": 1.5639810426540284,
      "grad_norm": 8.983346939086914,
      "learning_rate": 3.4364498061180526e-05,
      "loss": 0.3608,
      "step": 3630
    },
    {
      "epoch": 1.5682895303748383,
      "grad_norm": 6.849398136138916,
      "learning_rate": 3.432141318397243e-05,
      "loss": 0.2881,
      "step": 3640
    },
    {
      "epoch": 1.5725980180956485,
      "grad_norm": 7.510157585144043,
      "learning_rate": 3.427832830676433e-05,
      "loss": 0.3606,
      "step": 3650
    },
    {
      "epoch": 1.5769065058164584,
      "grad_norm": 2.530433416366577,
      "learning_rate": 3.423524342955623e-05,
      "loss": 0.445,
      "step": 3660
    },
    {
      "epoch": 1.5812149935372686,
      "grad_norm": 5.244054317474365,
      "learning_rate": 3.4192158552348124e-05,
      "loss": 0.2669,
      "step": 3670
    },
    {
      "epoch": 1.5855234812580785,
      "grad_norm": 6.965127468109131,
      "learning_rate": 3.4149073675140026e-05,
      "loss": 0.3372,
      "step": 3680
    },
    {
      "epoch": 1.5898319689788885,
      "grad_norm": 3.4233384132385254,
      "learning_rate": 3.410598879793193e-05,
      "loss": 0.3048,
      "step": 3690
    },
    {
      "epoch": 1.5941404566996984,
      "grad_norm": 4.359930038452148,
      "learning_rate": 3.406290392072383e-05,
      "loss": 0.432,
      "step": 3700
    },
    {
      "epoch": 1.5984489444205083,
      "grad_norm": 7.616671085357666,
      "learning_rate": 3.401981904351573e-05,
      "loss": 0.4207,
      "step": 3710
    },
    {
      "epoch": 1.6027574321413183,
      "grad_norm": 6.349983215332031,
      "learning_rate": 3.397673416630763e-05,
      "loss": 0.3314,
      "step": 3720
    },
    {
      "epoch": 1.6070659198621284,
      "grad_norm": 9.576778411865234,
      "learning_rate": 3.393364928909953e-05,
      "loss": 0.4189,
      "step": 3730
    },
    {
      "epoch": 1.6113744075829384,
      "grad_norm": 9.03040599822998,
      "learning_rate": 3.3890564411891426e-05,
      "loss": 0.3768,
      "step": 3740
    },
    {
      "epoch": 1.6156828953037485,
      "grad_norm": 6.9331135749816895,
      "learning_rate": 3.384747953468333e-05,
      "loss": 0.4433,
      "step": 3750
    },
    {
      "epoch": 1.6199913830245585,
      "grad_norm": 6.818536281585693,
      "learning_rate": 3.380439465747523e-05,
      "loss": 0.4943,
      "step": 3760
    },
    {
      "epoch": 1.6242998707453684,
      "grad_norm": 6.165338516235352,
      "learning_rate": 3.376130978026712e-05,
      "loss": 0.3843,
      "step": 3770
    },
    {
      "epoch": 1.6286083584661784,
      "grad_norm": 6.079308986663818,
      "learning_rate": 3.3718224903059024e-05,
      "loss": 0.3717,
      "step": 3780
    },
    {
      "epoch": 1.6329168461869883,
      "grad_norm": 7.205755710601807,
      "learning_rate": 3.3675140025850925e-05,
      "loss": 0.4084,
      "step": 3790
    },
    {
      "epoch": 1.6372253339077982,
      "grad_norm": 5.425198078155518,
      "learning_rate": 3.363205514864283e-05,
      "loss": 0.3952,
      "step": 3800
    },
    {
      "epoch": 1.6415338216286084,
      "grad_norm": 11.768514633178711,
      "learning_rate": 3.358897027143473e-05,
      "loss": 0.4017,
      "step": 3810
    },
    {
      "epoch": 1.6458423093494183,
      "grad_norm": 15.425503730773926,
      "learning_rate": 3.354588539422663e-05,
      "loss": 0.4419,
      "step": 3820
    },
    {
      "epoch": 1.6501507970702285,
      "grad_norm": 4.496914863586426,
      "learning_rate": 3.350280051701853e-05,
      "loss": 0.341,
      "step": 3830
    },
    {
      "epoch": 1.6544592847910384,
      "grad_norm": 3.0322201251983643,
      "learning_rate": 3.345971563981043e-05,
      "loss": 0.3488,
      "step": 3840
    },
    {
      "epoch": 1.6587677725118484,
      "grad_norm": 9.09678840637207,
      "learning_rate": 3.341663076260233e-05,
      "loss": 0.3441,
      "step": 3850
    },
    {
      "epoch": 1.6630762602326583,
      "grad_norm": 5.679242134094238,
      "learning_rate": 3.3373545885394234e-05,
      "loss": 0.4253,
      "step": 3860
    },
    {
      "epoch": 1.6673847479534682,
      "grad_norm": 1.8214055299758911,
      "learning_rate": 3.333046100818613e-05,
      "loss": 0.3123,
      "step": 3870
    },
    {
      "epoch": 1.6716932356742782,
      "grad_norm": 3.1642379760742188,
      "learning_rate": 3.328737613097803e-05,
      "loss": 0.3723,
      "step": 3880
    },
    {
      "epoch": 1.6760017233950883,
      "grad_norm": 3.7424330711364746,
      "learning_rate": 3.3244291253769924e-05,
      "loss": 0.2762,
      "step": 3890
    },
    {
      "epoch": 1.6803102111158983,
      "grad_norm": 2.551206588745117,
      "learning_rate": 3.3201206376561825e-05,
      "loss": 0.3775,
      "step": 3900
    },
    {
      "epoch": 1.6846186988367085,
      "grad_norm": 10.914793968200684,
      "learning_rate": 3.3158121499353726e-05,
      "loss": 0.4682,
      "step": 3910
    },
    {
      "epoch": 1.6889271865575184,
      "grad_norm": 4.370045185089111,
      "learning_rate": 3.311503662214563e-05,
      "loss": 0.4541,
      "step": 3920
    },
    {
      "epoch": 1.6932356742783283,
      "grad_norm": 1.8149935007095337,
      "learning_rate": 3.307195174493753e-05,
      "loss": 0.3433,
      "step": 3930
    },
    {
      "epoch": 1.6975441619991383,
      "grad_norm": 4.07486629486084,
      "learning_rate": 3.302886686772943e-05,
      "loss": 0.2762,
      "step": 3940
    },
    {
      "epoch": 1.7018526497199482,
      "grad_norm": 4.021484851837158,
      "learning_rate": 3.298578199052133e-05,
      "loss": 0.4105,
      "step": 3950
    },
    {
      "epoch": 1.7061611374407581,
      "grad_norm": 1.9495896100997925,
      "learning_rate": 3.294269711331323e-05,
      "loss": 0.2666,
      "step": 3960
    },
    {
      "epoch": 1.7104696251615683,
      "grad_norm": 5.023964881896973,
      "learning_rate": 3.289961223610513e-05,
      "loss": 0.361,
      "step": 3970
    },
    {
      "epoch": 1.7147781128823782,
      "grad_norm": 16.29005241394043,
      "learning_rate": 3.285652735889703e-05,
      "loss": 0.4205,
      "step": 3980
    },
    {
      "epoch": 1.7190866006031884,
      "grad_norm": 5.354408264160156,
      "learning_rate": 3.281344248168893e-05,
      "loss": 0.4283,
      "step": 3990
    },
    {
      "epoch": 1.7233950883239983,
      "grad_norm": 7.037089824676514,
      "learning_rate": 3.277035760448083e-05,
      "loss": 0.4787,
      "step": 4000
    },
    {
      "epoch": 1.7277035760448083,
      "grad_norm": 18.508028030395508,
      "learning_rate": 3.272727272727273e-05,
      "loss": 0.3744,
      "step": 4010
    },
    {
      "epoch": 1.7320120637656182,
      "grad_norm": 3.11612868309021,
      "learning_rate": 3.2684187850064626e-05,
      "loss": 0.309,
      "step": 4020
    },
    {
      "epoch": 1.7363205514864282,
      "grad_norm": 37.35432052612305,
      "learning_rate": 3.264110297285653e-05,
      "loss": 0.3647,
      "step": 4030
    },
    {
      "epoch": 1.740629039207238,
      "grad_norm": 3.8663196563720703,
      "learning_rate": 3.259801809564843e-05,
      "loss": 0.387,
      "step": 4040
    },
    {
      "epoch": 1.7449375269280483,
      "grad_norm": 7.666943550109863,
      "learning_rate": 3.255493321844033e-05,
      "loss": 0.3722,
      "step": 4050
    },
    {
      "epoch": 1.7492460146488582,
      "grad_norm": 3.079416513442993,
      "learning_rate": 3.251184834123223e-05,
      "loss": 0.3762,
      "step": 4060
    },
    {
      "epoch": 1.7535545023696684,
      "grad_norm": 2.5078752040863037,
      "learning_rate": 3.2468763464024126e-05,
      "loss": 0.3588,
      "step": 4070
    },
    {
      "epoch": 1.7578629900904783,
      "grad_norm": 2.7657480239868164,
      "learning_rate": 3.242567858681603e-05,
      "loss": 0.304,
      "step": 4080
    },
    {
      "epoch": 1.7621714778112882,
      "grad_norm": 6.091010093688965,
      "learning_rate": 3.238259370960793e-05,
      "loss": 0.3206,
      "step": 4090
    },
    {
      "epoch": 1.7664799655320982,
      "grad_norm": 5.9209771156311035,
      "learning_rate": 3.233950883239983e-05,
      "loss": 0.3861,
      "step": 4100
    },
    {
      "epoch": 1.7707884532529081,
      "grad_norm": 2.7699999809265137,
      "learning_rate": 3.229642395519173e-05,
      "loss": 0.4478,
      "step": 4110
    },
    {
      "epoch": 1.775096940973718,
      "grad_norm": 4.073580265045166,
      "learning_rate": 3.225333907798363e-05,
      "loss": 0.3697,
      "step": 4120
    },
    {
      "epoch": 1.7794054286945282,
      "grad_norm": 7.178559303283691,
      "learning_rate": 3.221025420077553e-05,
      "loss": 0.3667,
      "step": 4130
    },
    {
      "epoch": 1.7837139164153382,
      "grad_norm": 3.8908724784851074,
      "learning_rate": 3.2167169323567434e-05,
      "loss": 0.3151,
      "step": 4140
    },
    {
      "epoch": 1.7880224041361483,
      "grad_norm": 3.5278687477111816,
      "learning_rate": 3.212408444635933e-05,
      "loss": 0.4229,
      "step": 4150
    },
    {
      "epoch": 1.7923308918569583,
      "grad_norm": 1.7239576578140259,
      "learning_rate": 3.208099956915123e-05,
      "loss": 0.3156,
      "step": 4160
    },
    {
      "epoch": 1.7966393795777682,
      "grad_norm": 5.449984073638916,
      "learning_rate": 3.2037914691943124e-05,
      "loss": 0.3054,
      "step": 4170
    },
    {
      "epoch": 1.8009478672985781,
      "grad_norm": 5.621598720550537,
      "learning_rate": 3.1994829814735025e-05,
      "loss": 0.3027,
      "step": 4180
    },
    {
      "epoch": 1.805256355019388,
      "grad_norm": 8.264619827270508,
      "learning_rate": 3.1951744937526927e-05,
      "loss": 0.2963,
      "step": 4190
    },
    {
      "epoch": 1.8095648427401982,
      "grad_norm": 3.748918056488037,
      "learning_rate": 3.190866006031883e-05,
      "loss": 0.3417,
      "step": 4200
    },
    {
      "epoch": 1.8138733304610082,
      "grad_norm": 5.134657859802246,
      "learning_rate": 3.186557518311073e-05,
      "loss": 0.3949,
      "step": 4210
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 2.7649173736572266,
      "learning_rate": 3.182249030590263e-05,
      "loss": 0.3337,
      "step": 4220
    },
    {
      "epoch": 1.8224903059026283,
      "grad_norm": 5.963736057281494,
      "learning_rate": 3.177940542869453e-05,
      "loss": 0.4432,
      "step": 4230
    },
    {
      "epoch": 1.8267987936234382,
      "grad_norm": 8.156063079833984,
      "learning_rate": 3.173632055148643e-05,
      "loss": 0.4654,
      "step": 4240
    },
    {
      "epoch": 1.8311072813442482,
      "grad_norm": 2.8575539588928223,
      "learning_rate": 3.1693235674278334e-05,
      "loss": 0.4529,
      "step": 4250
    },
    {
      "epoch": 1.835415769065058,
      "grad_norm": 9.159215927124023,
      "learning_rate": 3.165015079707023e-05,
      "loss": 0.3625,
      "step": 4260
    },
    {
      "epoch": 1.839724256785868,
      "grad_norm": 5.238006114959717,
      "learning_rate": 3.160706591986213e-05,
      "loss": 0.4622,
      "step": 4270
    },
    {
      "epoch": 1.8440327445066782,
      "grad_norm": 3.1744251251220703,
      "learning_rate": 3.156398104265403e-05,
      "loss": 0.3257,
      "step": 4280
    },
    {
      "epoch": 1.8483412322274881,
      "grad_norm": 2.339188575744629,
      "learning_rate": 3.152089616544593e-05,
      "loss": 0.3272,
      "step": 4290
    },
    {
      "epoch": 1.8526497199482983,
      "grad_norm": 3.8408145904541016,
      "learning_rate": 3.1477811288237826e-05,
      "loss": 0.3514,
      "step": 4300
    },
    {
      "epoch": 1.8569582076691082,
      "grad_norm": 5.428679466247559,
      "learning_rate": 3.143472641102973e-05,
      "loss": 0.4144,
      "step": 4310
    },
    {
      "epoch": 1.8612666953899182,
      "grad_norm": 6.362871170043945,
      "learning_rate": 3.139164153382163e-05,
      "loss": 0.4396,
      "step": 4320
    },
    {
      "epoch": 1.8655751831107281,
      "grad_norm": 5.9084625244140625,
      "learning_rate": 3.134855665661353e-05,
      "loss": 0.3935,
      "step": 4330
    },
    {
      "epoch": 1.869883670831538,
      "grad_norm": 2.3944857120513916,
      "learning_rate": 3.130547177940543e-05,
      "loss": 0.4319,
      "step": 4340
    },
    {
      "epoch": 1.874192158552348,
      "grad_norm": 8.931401252746582,
      "learning_rate": 3.126238690219733e-05,
      "loss": 0.402,
      "step": 4350
    },
    {
      "epoch": 1.8785006462731582,
      "grad_norm": 4.175596237182617,
      "learning_rate": 3.121930202498923e-05,
      "loss": 0.3999,
      "step": 4360
    },
    {
      "epoch": 1.882809133993968,
      "grad_norm": 9.931584358215332,
      "learning_rate": 3.117621714778113e-05,
      "loss": 0.3129,
      "step": 4370
    },
    {
      "epoch": 1.8871176217147783,
      "grad_norm": 5.073201656341553,
      "learning_rate": 3.113313227057303e-05,
      "loss": 0.4125,
      "step": 4380
    },
    {
      "epoch": 1.8914261094355882,
      "grad_norm": 6.516151428222656,
      "learning_rate": 3.109004739336493e-05,
      "loss": 0.3798,
      "step": 4390
    },
    {
      "epoch": 1.8957345971563981,
      "grad_norm": 1.5509713888168335,
      "learning_rate": 3.104696251615683e-05,
      "loss": 0.2832,
      "step": 4400
    },
    {
      "epoch": 1.900043084877208,
      "grad_norm": 4.086947917938232,
      "learning_rate": 3.100387763894873e-05,
      "loss": 0.3254,
      "step": 4410
    },
    {
      "epoch": 1.904351572598018,
      "grad_norm": 7.893184185028076,
      "learning_rate": 3.0960792761740634e-05,
      "loss": 0.3737,
      "step": 4420
    },
    {
      "epoch": 1.908660060318828,
      "grad_norm": 5.986332893371582,
      "learning_rate": 3.091770788453253e-05,
      "loss": 0.3841,
      "step": 4430
    },
    {
      "epoch": 1.9129685480396381,
      "grad_norm": 10.986656188964844,
      "learning_rate": 3.087462300732443e-05,
      "loss": 0.3667,
      "step": 4440
    },
    {
      "epoch": 1.917277035760448,
      "grad_norm": 10.506738662719727,
      "learning_rate": 3.083153813011633e-05,
      "loss": 0.4085,
      "step": 4450
    },
    {
      "epoch": 1.9215855234812582,
      "grad_norm": 4.980945587158203,
      "learning_rate": 3.0788453252908225e-05,
      "loss": 0.3656,
      "step": 4460
    },
    {
      "epoch": 1.9258940112020682,
      "grad_norm": 8.127358436584473,
      "learning_rate": 3.074536837570013e-05,
      "loss": 0.374,
      "step": 4470
    },
    {
      "epoch": 1.930202498922878,
      "grad_norm": 5.165857315063477,
      "learning_rate": 3.070228349849203e-05,
      "loss": 0.3961,
      "step": 4480
    },
    {
      "epoch": 1.934510986643688,
      "grad_norm": 3.642347812652588,
      "learning_rate": 3.065919862128393e-05,
      "loss": 0.3526,
      "step": 4490
    },
    {
      "epoch": 1.938819474364498,
      "grad_norm": 4.933537483215332,
      "learning_rate": 3.061611374407583e-05,
      "loss": 0.3481,
      "step": 4500
    },
    {
      "epoch": 1.943127962085308,
      "grad_norm": 6.637113571166992,
      "learning_rate": 3.057302886686773e-05,
      "loss": 0.4299,
      "step": 4510
    },
    {
      "epoch": 1.947436449806118,
      "grad_norm": 4.862458229064941,
      "learning_rate": 3.052994398965963e-05,
      "loss": 0.4159,
      "step": 4520
    },
    {
      "epoch": 1.951744937526928,
      "grad_norm": 9.072687149047852,
      "learning_rate": 3.0486859112451534e-05,
      "loss": 0.302,
      "step": 4530
    },
    {
      "epoch": 1.9560534252477382,
      "grad_norm": 4.028695106506348,
      "learning_rate": 3.0443774235243432e-05,
      "loss": 0.3844,
      "step": 4540
    },
    {
      "epoch": 1.9603619129685481,
      "grad_norm": 4.811106204986572,
      "learning_rate": 3.0400689358035333e-05,
      "loss": 0.4062,
      "step": 4550
    },
    {
      "epoch": 1.964670400689358,
      "grad_norm": 5.5779523849487305,
      "learning_rate": 3.0357604480827227e-05,
      "loss": 0.4415,
      "step": 4560
    },
    {
      "epoch": 1.968978888410168,
      "grad_norm": 10.044821739196777,
      "learning_rate": 3.031451960361913e-05,
      "loss": 0.3131,
      "step": 4570
    },
    {
      "epoch": 1.973287376130978,
      "grad_norm": 4.737741470336914,
      "learning_rate": 3.027143472641103e-05,
      "loss": 0.3227,
      "step": 4580
    },
    {
      "epoch": 1.9775958638517879,
      "grad_norm": 8.264359474182129,
      "learning_rate": 3.022834984920293e-05,
      "loss": 0.4296,
      "step": 4590
    },
    {
      "epoch": 1.981904351572598,
      "grad_norm": 3.778519630432129,
      "learning_rate": 3.0185264971994832e-05,
      "loss": 0.4194,
      "step": 4600
    },
    {
      "epoch": 1.986212839293408,
      "grad_norm": 7.45163631439209,
      "learning_rate": 3.014218009478673e-05,
      "loss": 0.3325,
      "step": 4610
    },
    {
      "epoch": 1.9905213270142181,
      "grad_norm": 2.3223724365234375,
      "learning_rate": 3.009909521757863e-05,
      "loss": 0.3917,
      "step": 4620
    },
    {
      "epoch": 1.994829814735028,
      "grad_norm": 3.028817892074585,
      "learning_rate": 3.0056010340370533e-05,
      "loss": 0.3444,
      "step": 4630
    },
    {
      "epoch": 1.999138302455838,
      "grad_norm": 7.731974124908447,
      "learning_rate": 3.0012925463162434e-05,
      "loss": 0.2678,
      "step": 4640
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.44598889350891113,
      "eval_runtime": 26.6093,
      "eval_samples_per_second": 598.024,
      "eval_steps_per_second": 37.393,
      "step": 4642
    },
    {
      "epoch": 2.003446790176648,
      "grad_norm": 5.663721561431885,
      "learning_rate": 2.9969840585954335e-05,
      "loss": 0.2476,
      "step": 4650
    },
    {
      "epoch": 2.007755277897458,
      "grad_norm": 5.057522296905518,
      "learning_rate": 2.992675570874623e-05,
      "loss": 0.2244,
      "step": 4660
    },
    {
      "epoch": 2.012063765618268,
      "grad_norm": 9.540754318237305,
      "learning_rate": 2.988367083153813e-05,
      "loss": 0.2588,
      "step": 4670
    },
    {
      "epoch": 2.0163722533390778,
      "grad_norm": 3.1715328693389893,
      "learning_rate": 2.9840585954330032e-05,
      "loss": 0.2492,
      "step": 4680
    },
    {
      "epoch": 2.020680741059888,
      "grad_norm": 5.751262187957764,
      "learning_rate": 2.979750107712193e-05,
      "loss": 0.2535,
      "step": 4690
    },
    {
      "epoch": 2.024989228780698,
      "grad_norm": 5.07501745223999,
      "learning_rate": 2.975441619991383e-05,
      "loss": 0.1988,
      "step": 4700
    },
    {
      "epoch": 2.029297716501508,
      "grad_norm": 8.310789108276367,
      "learning_rate": 2.9711331322705732e-05,
      "loss": 0.2864,
      "step": 4710
    },
    {
      "epoch": 2.033606204222318,
      "grad_norm": 6.01857328414917,
      "learning_rate": 2.9668246445497633e-05,
      "loss": 0.1786,
      "step": 4720
    },
    {
      "epoch": 2.037914691943128,
      "grad_norm": 14.23697566986084,
      "learning_rate": 2.9625161568289535e-05,
      "loss": 0.2879,
      "step": 4730
    },
    {
      "epoch": 2.042223179663938,
      "grad_norm": 6.018524646759033,
      "learning_rate": 2.9582076691081432e-05,
      "loss": 0.2856,
      "step": 4740
    },
    {
      "epoch": 2.046531667384748,
      "grad_norm": 5.342257976531982,
      "learning_rate": 2.9538991813873334e-05,
      "loss": 0.203,
      "step": 4750
    },
    {
      "epoch": 2.0508401551055577,
      "grad_norm": 7.344825267791748,
      "learning_rate": 2.9495906936665228e-05,
      "loss": 0.2366,
      "step": 4760
    },
    {
      "epoch": 2.055148642826368,
      "grad_norm": 5.63657808303833,
      "learning_rate": 2.945282205945713e-05,
      "loss": 0.2739,
      "step": 4770
    },
    {
      "epoch": 2.059457130547178,
      "grad_norm": 7.527071475982666,
      "learning_rate": 2.940973718224903e-05,
      "loss": 0.2589,
      "step": 4780
    },
    {
      "epoch": 2.063765618267988,
      "grad_norm": 6.2369842529296875,
      "learning_rate": 2.936665230504093e-05,
      "loss": 0.1915,
      "step": 4790
    },
    {
      "epoch": 2.068074105988798,
      "grad_norm": 3.0855307579040527,
      "learning_rate": 2.9323567427832833e-05,
      "loss": 0.2348,
      "step": 4800
    },
    {
      "epoch": 2.072382593709608,
      "grad_norm": 4.390134334564209,
      "learning_rate": 2.9280482550624734e-05,
      "loss": 0.2143,
      "step": 4810
    },
    {
      "epoch": 2.076691081430418,
      "grad_norm": 2.5195071697235107,
      "learning_rate": 2.9237397673416632e-05,
      "loss": 0.2345,
      "step": 4820
    },
    {
      "epoch": 2.0809995691512277,
      "grad_norm": 11.887733459472656,
      "learning_rate": 2.9194312796208533e-05,
      "loss": 0.2311,
      "step": 4830
    },
    {
      "epoch": 2.085308056872038,
      "grad_norm": 11.020423889160156,
      "learning_rate": 2.9151227919000434e-05,
      "loss": 0.2508,
      "step": 4840
    },
    {
      "epoch": 2.089616544592848,
      "grad_norm": 9.664212226867676,
      "learning_rate": 2.910814304179233e-05,
      "loss": 0.202,
      "step": 4850
    },
    {
      "epoch": 2.093925032313658,
      "grad_norm": 6.080756187438965,
      "learning_rate": 2.906505816458423e-05,
      "loss": 0.256,
      "step": 4860
    },
    {
      "epoch": 2.098233520034468,
      "grad_norm": 7.207979202270508,
      "learning_rate": 2.902197328737613e-05,
      "loss": 0.3345,
      "step": 4870
    },
    {
      "epoch": 2.102542007755278,
      "grad_norm": 10.348382949829102,
      "learning_rate": 2.8978888410168032e-05,
      "loss": 0.3884,
      "step": 4880
    },
    {
      "epoch": 2.106850495476088,
      "grad_norm": 7.629287242889404,
      "learning_rate": 2.893580353295993e-05,
      "loss": 0.2368,
      "step": 4890
    },
    {
      "epoch": 2.1111589831968978,
      "grad_norm": 5.017970085144043,
      "learning_rate": 2.889271865575183e-05,
      "loss": 0.2317,
      "step": 4900
    },
    {
      "epoch": 2.1154674709177077,
      "grad_norm": 11.437073707580566,
      "learning_rate": 2.8849633778543733e-05,
      "loss": 0.1696,
      "step": 4910
    },
    {
      "epoch": 2.119775958638518,
      "grad_norm": 20.419391632080078,
      "learning_rate": 2.8806548901335634e-05,
      "loss": 0.2434,
      "step": 4920
    },
    {
      "epoch": 2.124084446359328,
      "grad_norm": 6.846683979034424,
      "learning_rate": 2.8763464024127535e-05,
      "loss": 0.2291,
      "step": 4930
    },
    {
      "epoch": 2.128392934080138,
      "grad_norm": 6.369823455810547,
      "learning_rate": 2.8720379146919436e-05,
      "loss": 0.2074,
      "step": 4940
    },
    {
      "epoch": 2.132701421800948,
      "grad_norm": 8.611660957336426,
      "learning_rate": 2.867729426971133e-05,
      "loss": 0.2066,
      "step": 4950
    },
    {
      "epoch": 2.137009909521758,
      "grad_norm": 5.771997928619385,
      "learning_rate": 2.8634209392503232e-05,
      "loss": 0.2899,
      "step": 4960
    },
    {
      "epoch": 2.141318397242568,
      "grad_norm": 8.78939437866211,
      "learning_rate": 2.859112451529513e-05,
      "loss": 0.2077,
      "step": 4970
    },
    {
      "epoch": 2.1456268849633777,
      "grad_norm": 3.1571879386901855,
      "learning_rate": 2.854803963808703e-05,
      "loss": 0.1349,
      "step": 4980
    },
    {
      "epoch": 2.1499353726841877,
      "grad_norm": 2.8545796871185303,
      "learning_rate": 2.8504954760878932e-05,
      "loss": 0.2178,
      "step": 4990
    },
    {
      "epoch": 2.154243860404998,
      "grad_norm": 7.513122081756592,
      "learning_rate": 2.8461869883670833e-05,
      "loss": 0.3032,
      "step": 5000
    },
    {
      "epoch": 2.158552348125808,
      "grad_norm": 3.0454506874084473,
      "learning_rate": 2.8418785006462735e-05,
      "loss": 0.2798,
      "step": 5010
    },
    {
      "epoch": 2.162860835846618,
      "grad_norm": 3.789659023284912,
      "learning_rate": 2.8375700129254636e-05,
      "loss": 0.2717,
      "step": 5020
    },
    {
      "epoch": 2.167169323567428,
      "grad_norm": 4.668327808380127,
      "learning_rate": 2.8332615252046534e-05,
      "loss": 0.2437,
      "step": 5030
    },
    {
      "epoch": 2.171477811288238,
      "grad_norm": 1.781722068786621,
      "learning_rate": 2.8289530374838435e-05,
      "loss": 0.223,
      "step": 5040
    },
    {
      "epoch": 2.1757862990090477,
      "grad_norm": 8.288018226623535,
      "learning_rate": 2.824644549763033e-05,
      "loss": 0.3091,
      "step": 5050
    },
    {
      "epoch": 2.1800947867298577,
      "grad_norm": 8.151077270507812,
      "learning_rate": 2.820336062042223e-05,
      "loss": 0.2447,
      "step": 5060
    },
    {
      "epoch": 2.1844032744506676,
      "grad_norm": 4.128024578094482,
      "learning_rate": 2.8160275743214132e-05,
      "loss": 0.2749,
      "step": 5070
    },
    {
      "epoch": 2.188711762171478,
      "grad_norm": 2.798234462738037,
      "learning_rate": 2.8117190866006033e-05,
      "loss": 0.2307,
      "step": 5080
    },
    {
      "epoch": 2.193020249892288,
      "grad_norm": 4.202315807342529,
      "learning_rate": 2.8074105988797934e-05,
      "loss": 0.2447,
      "step": 5090
    },
    {
      "epoch": 2.197328737613098,
      "grad_norm": 7.14230489730835,
      "learning_rate": 2.8031021111589832e-05,
      "loss": 0.2721,
      "step": 5100
    },
    {
      "epoch": 2.201637225333908,
      "grad_norm": 5.663987636566162,
      "learning_rate": 2.7987936234381733e-05,
      "loss": 0.3037,
      "step": 5110
    },
    {
      "epoch": 2.2059457130547178,
      "grad_norm": 8.160236358642578,
      "learning_rate": 2.7944851357173634e-05,
      "loss": 0.169,
      "step": 5120
    },
    {
      "epoch": 2.2102542007755277,
      "grad_norm": 7.212368488311768,
      "learning_rate": 2.7901766479965536e-05,
      "loss": 0.2272,
      "step": 5130
    },
    {
      "epoch": 2.2145626884963376,
      "grad_norm": 11.522238731384277,
      "learning_rate": 2.7858681602757437e-05,
      "loss": 0.2403,
      "step": 5140
    },
    {
      "epoch": 2.2188711762171476,
      "grad_norm": 11.660818099975586,
      "learning_rate": 2.781559672554933e-05,
      "loss": 0.1644,
      "step": 5150
    },
    {
      "epoch": 2.223179663937958,
      "grad_norm": 5.358041286468506,
      "learning_rate": 2.7772511848341233e-05,
      "loss": 0.1829,
      "step": 5160
    },
    {
      "epoch": 2.227488151658768,
      "grad_norm": 5.813822269439697,
      "learning_rate": 2.7729426971133134e-05,
      "loss": 0.2007,
      "step": 5170
    },
    {
      "epoch": 2.231796639379578,
      "grad_norm": 5.025450229644775,
      "learning_rate": 2.768634209392503e-05,
      "loss": 0.2523,
      "step": 5180
    },
    {
      "epoch": 2.236105127100388,
      "grad_norm": 4.855681419372559,
      "learning_rate": 2.7643257216716933e-05,
      "loss": 0.2258,
      "step": 5190
    },
    {
      "epoch": 2.2404136148211977,
      "grad_norm": 5.708663463592529,
      "learning_rate": 2.7600172339508834e-05,
      "loss": 0.2894,
      "step": 5200
    },
    {
      "epoch": 2.2447221025420077,
      "grad_norm": 5.579139709472656,
      "learning_rate": 2.7557087462300735e-05,
      "loss": 0.2466,
      "step": 5210
    },
    {
      "epoch": 2.2490305902628176,
      "grad_norm": 1.3169687986373901,
      "learning_rate": 2.7514002585092636e-05,
      "loss": 0.1534,
      "step": 5220
    },
    {
      "epoch": 2.253339077983628,
      "grad_norm": 6.346175193786621,
      "learning_rate": 2.7470917707884534e-05,
      "loss": 0.2034,
      "step": 5230
    },
    {
      "epoch": 2.257647565704438,
      "grad_norm": 1.0806399583816528,
      "learning_rate": 2.7427832830676436e-05,
      "loss": 0.2194,
      "step": 5240
    },
    {
      "epoch": 2.261956053425248,
      "grad_norm": 8.077699661254883,
      "learning_rate": 2.738474795346833e-05,
      "loss": 0.4577,
      "step": 5250
    },
    {
      "epoch": 2.266264541146058,
      "grad_norm": 3.146411657333374,
      "learning_rate": 2.734166307626023e-05,
      "loss": 0.1951,
      "step": 5260
    },
    {
      "epoch": 2.2705730288668677,
      "grad_norm": 5.261524200439453,
      "learning_rate": 2.7298578199052132e-05,
      "loss": 0.3042,
      "step": 5270
    },
    {
      "epoch": 2.2748815165876777,
      "grad_norm": 6.4938764572143555,
      "learning_rate": 2.7255493321844034e-05,
      "loss": 0.2025,
      "step": 5280
    },
    {
      "epoch": 2.2791900043084876,
      "grad_norm": 2.1064391136169434,
      "learning_rate": 2.7212408444635935e-05,
      "loss": 0.2401,
      "step": 5290
    },
    {
      "epoch": 2.2834984920292976,
      "grad_norm": 5.842591285705566,
      "learning_rate": 2.7169323567427836e-05,
      "loss": 0.1543,
      "step": 5300
    },
    {
      "epoch": 2.2878069797501075,
      "grad_norm": 2.0600287914276123,
      "learning_rate": 2.7126238690219734e-05,
      "loss": 0.2113,
      "step": 5310
    },
    {
      "epoch": 2.292115467470918,
      "grad_norm": 15.322525978088379,
      "learning_rate": 2.7083153813011635e-05,
      "loss": 0.2729,
      "step": 5320
    },
    {
      "epoch": 2.296423955191728,
      "grad_norm": 4.327635765075684,
      "learning_rate": 2.7040068935803536e-05,
      "loss": 0.2072,
      "step": 5330
    },
    {
      "epoch": 2.3007324429125378,
      "grad_norm": 5.861257076263428,
      "learning_rate": 2.6996984058595437e-05,
      "loss": 0.2055,
      "step": 5340
    },
    {
      "epoch": 2.3050409306333477,
      "grad_norm": 3.4098544120788574,
      "learning_rate": 2.6953899181387332e-05,
      "loss": 0.3315,
      "step": 5350
    },
    {
      "epoch": 2.3093494183541576,
      "grad_norm": 8.613633155822754,
      "learning_rate": 2.6910814304179233e-05,
      "loss": 0.2764,
      "step": 5360
    },
    {
      "epoch": 2.3136579060749676,
      "grad_norm": 4.542110443115234,
      "learning_rate": 2.6867729426971134e-05,
      "loss": 0.2424,
      "step": 5370
    },
    {
      "epoch": 2.3179663937957775,
      "grad_norm": 3.5528955459594727,
      "learning_rate": 2.6824644549763032e-05,
      "loss": 0.2145,
      "step": 5380
    },
    {
      "epoch": 2.322274881516588,
      "grad_norm": 4.444680690765381,
      "learning_rate": 2.6781559672554933e-05,
      "loss": 0.2873,
      "step": 5390
    },
    {
      "epoch": 2.326583369237398,
      "grad_norm": 14.490579605102539,
      "learning_rate": 2.6738474795346835e-05,
      "loss": 0.285,
      "step": 5400
    },
    {
      "epoch": 2.3308918569582078,
      "grad_norm": 7.170324325561523,
      "learning_rate": 2.6695389918138736e-05,
      "loss": 0.2038,
      "step": 5410
    },
    {
      "epoch": 2.3352003446790177,
      "grad_norm": 3.8617188930511475,
      "learning_rate": 2.6652305040930637e-05,
      "loss": 0.1605,
      "step": 5420
    },
    {
      "epoch": 2.3395088323998277,
      "grad_norm": 8.04809856414795,
      "learning_rate": 2.6609220163722538e-05,
      "loss": 0.3017,
      "step": 5430
    },
    {
      "epoch": 2.3438173201206376,
      "grad_norm": 4.794151782989502,
      "learning_rate": 2.6566135286514433e-05,
      "loss": 0.2484,
      "step": 5440
    },
    {
      "epoch": 2.3481258078414475,
      "grad_norm": 11.85686206817627,
      "learning_rate": 2.6523050409306334e-05,
      "loss": 0.2394,
      "step": 5450
    },
    {
      "epoch": 2.3524342955622575,
      "grad_norm": 5.319192409515381,
      "learning_rate": 2.6479965532098232e-05,
      "loss": 0.291,
      "step": 5460
    },
    {
      "epoch": 2.3567427832830674,
      "grad_norm": 6.456291198730469,
      "learning_rate": 2.6436880654890133e-05,
      "loss": 0.2343,
      "step": 5470
    },
    {
      "epoch": 2.361051271003878,
      "grad_norm": 21.043607711791992,
      "learning_rate": 2.6393795777682034e-05,
      "loss": 0.1867,
      "step": 5480
    },
    {
      "epoch": 2.3653597587246877,
      "grad_norm": 20.861509323120117,
      "learning_rate": 2.6350710900473935e-05,
      "loss": 0.2421,
      "step": 5490
    },
    {
      "epoch": 2.3696682464454977,
      "grad_norm": 12.18315601348877,
      "learning_rate": 2.6307626023265837e-05,
      "loss": 0.3367,
      "step": 5500
    },
    {
      "epoch": 2.3739767341663076,
      "grad_norm": 2.0400068759918213,
      "learning_rate": 2.6264541146057738e-05,
      "loss": 0.2297,
      "step": 5510
    },
    {
      "epoch": 2.3782852218871176,
      "grad_norm": 7.251345634460449,
      "learning_rate": 2.6221456268849636e-05,
      "loss": 0.2979,
      "step": 5520
    },
    {
      "epoch": 2.3825937096079275,
      "grad_norm": 6.749761581420898,
      "learning_rate": 2.6178371391641537e-05,
      "loss": 0.2731,
      "step": 5530
    },
    {
      "epoch": 2.3869021973287374,
      "grad_norm": 10.5274658203125,
      "learning_rate": 2.613528651443343e-05,
      "loss": 0.2418,
      "step": 5540
    },
    {
      "epoch": 2.391210685049548,
      "grad_norm": 8.542313575744629,
      "learning_rate": 2.6092201637225333e-05,
      "loss": 0.2121,
      "step": 5550
    },
    {
      "epoch": 2.3955191727703578,
      "grad_norm": 6.197847843170166,
      "learning_rate": 2.6049116760017234e-05,
      "loss": 0.2541,
      "step": 5560
    },
    {
      "epoch": 2.3998276604911677,
      "grad_norm": 17.490745544433594,
      "learning_rate": 2.6006031882809135e-05,
      "loss": 0.1848,
      "step": 5570
    },
    {
      "epoch": 2.4041361482119776,
      "grad_norm": 4.402955055236816,
      "learning_rate": 2.5962947005601036e-05,
      "loss": 0.209,
      "step": 5580
    },
    {
      "epoch": 2.4084446359327876,
      "grad_norm": 13.739377975463867,
      "learning_rate": 2.5919862128392934e-05,
      "loss": 0.4146,
      "step": 5590
    },
    {
      "epoch": 2.4127531236535975,
      "grad_norm": 12.760643005371094,
      "learning_rate": 2.5876777251184835e-05,
      "loss": 0.2446,
      "step": 5600
    },
    {
      "epoch": 2.4170616113744074,
      "grad_norm": 10.506277084350586,
      "learning_rate": 2.5833692373976736e-05,
      "loss": 0.3001,
      "step": 5610
    },
    {
      "epoch": 2.4213700990952174,
      "grad_norm": 5.338688373565674,
      "learning_rate": 2.5790607496768638e-05,
      "loss": 0.1643,
      "step": 5620
    },
    {
      "epoch": 2.4256785868160273,
      "grad_norm": 6.253190040588379,
      "learning_rate": 2.574752261956054e-05,
      "loss": 0.2383,
      "step": 5630
    },
    {
      "epoch": 2.4299870745368377,
      "grad_norm": 10.29806137084961,
      "learning_rate": 2.5704437742352433e-05,
      "loss": 0.2064,
      "step": 5640
    },
    {
      "epoch": 2.4342955622576476,
      "grad_norm": 7.41417121887207,
      "learning_rate": 2.5661352865144334e-05,
      "loss": 0.2395,
      "step": 5650
    },
    {
      "epoch": 2.4386040499784576,
      "grad_norm": 11.1129789352417,
      "learning_rate": 2.5618267987936236e-05,
      "loss": 0.1535,
      "step": 5660
    },
    {
      "epoch": 2.4429125376992675,
      "grad_norm": 23.76299476623535,
      "learning_rate": 2.5575183110728134e-05,
      "loss": 0.2413,
      "step": 5670
    },
    {
      "epoch": 2.4472210254200775,
      "grad_norm": 18.673419952392578,
      "learning_rate": 2.5532098233520035e-05,
      "loss": 0.3272,
      "step": 5680
    },
    {
      "epoch": 2.4515295131408874,
      "grad_norm": 6.517416000366211,
      "learning_rate": 2.5489013356311936e-05,
      "loss": 0.1904,
      "step": 5690
    },
    {
      "epoch": 2.4558380008616973,
      "grad_norm": 4.268484115600586,
      "learning_rate": 2.5445928479103837e-05,
      "loss": 0.2805,
      "step": 5700
    },
    {
      "epoch": 2.4601464885825077,
      "grad_norm": 8.129560470581055,
      "learning_rate": 2.540284360189574e-05,
      "loss": 0.3273,
      "step": 5710
    },
    {
      "epoch": 2.4644549763033177,
      "grad_norm": 5.580802917480469,
      "learning_rate": 2.5359758724687636e-05,
      "loss": 0.2282,
      "step": 5720
    },
    {
      "epoch": 2.4687634640241276,
      "grad_norm": 0.7145545482635498,
      "learning_rate": 2.5316673847479537e-05,
      "loss": 0.1615,
      "step": 5730
    },
    {
      "epoch": 2.4730719517449375,
      "grad_norm": 6.382878303527832,
      "learning_rate": 2.5273588970271432e-05,
      "loss": 0.1773,
      "step": 5740
    },
    {
      "epoch": 2.4773804394657475,
      "grad_norm": 14.435805320739746,
      "learning_rate": 2.5230504093063333e-05,
      "loss": 0.2207,
      "step": 5750
    },
    {
      "epoch": 2.4816889271865574,
      "grad_norm": 1.180963397026062,
      "learning_rate": 2.5187419215855234e-05,
      "loss": 0.1952,
      "step": 5760
    },
    {
      "epoch": 2.4859974149073674,
      "grad_norm": 1.5933985710144043,
      "learning_rate": 2.5144334338647136e-05,
      "loss": 0.2282,
      "step": 5770
    },
    {
      "epoch": 2.4903059026281777,
      "grad_norm": 2.8071393966674805,
      "learning_rate": 2.5101249461439037e-05,
      "loss": 0.194,
      "step": 5780
    },
    {
      "epoch": 2.4946143903489877,
      "grad_norm": 9.113646507263184,
      "learning_rate": 2.5058164584230938e-05,
      "loss": 0.2355,
      "step": 5790
    },
    {
      "epoch": 2.4989228780697976,
      "grad_norm": 6.937984943389893,
      "learning_rate": 2.5015079707022836e-05,
      "loss": 0.3119,
      "step": 5800
    },
    {
      "epoch": 2.5032313657906076,
      "grad_norm": 7.8061604499816895,
      "learning_rate": 2.4971994829814734e-05,
      "loss": 0.2072,
      "step": 5810
    },
    {
      "epoch": 2.5075398535114175,
      "grad_norm": 5.689671516418457,
      "learning_rate": 2.4928909952606635e-05,
      "loss": 0.191,
      "step": 5820
    },
    {
      "epoch": 2.5118483412322274,
      "grad_norm": 5.2391157150268555,
      "learning_rate": 2.4885825075398536e-05,
      "loss": 0.2533,
      "step": 5830
    },
    {
      "epoch": 2.5161568289530374,
      "grad_norm": 14.38219928741455,
      "learning_rate": 2.4842740198190437e-05,
      "loss": 0.1527,
      "step": 5840
    },
    {
      "epoch": 2.5204653166738473,
      "grad_norm": 4.894649028778076,
      "learning_rate": 2.479965532098234e-05,
      "loss": 0.2501,
      "step": 5850
    },
    {
      "epoch": 2.5247738043946573,
      "grad_norm": 6.194145679473877,
      "learning_rate": 2.4756570443774236e-05,
      "loss": 0.2459,
      "step": 5860
    },
    {
      "epoch": 2.5290822921154676,
      "grad_norm": 22.99433708190918,
      "learning_rate": 2.4713485566566134e-05,
      "loss": 0.2509,
      "step": 5870
    },
    {
      "epoch": 2.5333907798362776,
      "grad_norm": 10.587127685546875,
      "learning_rate": 2.4670400689358035e-05,
      "loss": 0.2362,
      "step": 5880
    },
    {
      "epoch": 2.5376992675570875,
      "grad_norm": 3.08711576461792,
      "learning_rate": 2.4627315812149937e-05,
      "loss": 0.2465,
      "step": 5890
    },
    {
      "epoch": 2.5420077552778975,
      "grad_norm": 4.130971431732178,
      "learning_rate": 2.4584230934941838e-05,
      "loss": 0.3361,
      "step": 5900
    },
    {
      "epoch": 2.5463162429987074,
      "grad_norm": 6.097258567810059,
      "learning_rate": 2.4541146057733736e-05,
      "loss": 0.2484,
      "step": 5910
    },
    {
      "epoch": 2.5506247307195173,
      "grad_norm": 8.814661979675293,
      "learning_rate": 2.4498061180525637e-05,
      "loss": 0.2606,
      "step": 5920
    },
    {
      "epoch": 2.5549332184403273,
      "grad_norm": 1.818427324295044,
      "learning_rate": 2.4454976303317538e-05,
      "loss": 0.1686,
      "step": 5930
    },
    {
      "epoch": 2.5592417061611377,
      "grad_norm": 5.172046184539795,
      "learning_rate": 2.4411891426109436e-05,
      "loss": 0.2224,
      "step": 5940
    },
    {
      "epoch": 2.563550193881947,
      "grad_norm": 8.557270050048828,
      "learning_rate": 2.4368806548901337e-05,
      "loss": 0.2047,
      "step": 5950
    },
    {
      "epoch": 2.5678586816027575,
      "grad_norm": 0.41093969345092773,
      "learning_rate": 2.4325721671693235e-05,
      "loss": 0.0769,
      "step": 5960
    },
    {
      "epoch": 2.5721671693235675,
      "grad_norm": 4.117542266845703,
      "learning_rate": 2.4282636794485136e-05,
      "loss": 0.3163,
      "step": 5970
    },
    {
      "epoch": 2.5764756570443774,
      "grad_norm": 11.577107429504395,
      "learning_rate": 2.4239551917277037e-05,
      "loss": 0.2494,
      "step": 5980
    },
    {
      "epoch": 2.5807841447651874,
      "grad_norm": 24.808874130249023,
      "learning_rate": 2.419646704006894e-05,
      "loss": 0.3908,
      "step": 5990
    },
    {
      "epoch": 2.5850926324859973,
      "grad_norm": 13.951473236083984,
      "learning_rate": 2.415338216286084e-05,
      "loss": 0.2817,
      "step": 6000
    },
    {
      "epoch": 2.5894011202068077,
      "grad_norm": 4.344727993011475,
      "learning_rate": 2.4110297285652738e-05,
      "loss": 0.2227,
      "step": 6010
    },
    {
      "epoch": 2.593709607927617,
      "grad_norm": 7.081716537475586,
      "learning_rate": 2.4067212408444635e-05,
      "loss": 0.2364,
      "step": 6020
    },
    {
      "epoch": 2.5980180956484276,
      "grad_norm": 4.938223361968994,
      "learning_rate": 2.4024127531236537e-05,
      "loss": 0.2845,
      "step": 6030
    },
    {
      "epoch": 2.6023265833692375,
      "grad_norm": 2.1201791763305664,
      "learning_rate": 2.3981042654028438e-05,
      "loss": 0.2087,
      "step": 6040
    },
    {
      "epoch": 2.6066350710900474,
      "grad_norm": 5.081819534301758,
      "learning_rate": 2.393795777682034e-05,
      "loss": 0.4262,
      "step": 6050
    },
    {
      "epoch": 2.6109435588108574,
      "grad_norm": 6.29404878616333,
      "learning_rate": 2.3894872899612237e-05,
      "loss": 0.373,
      "step": 6060
    },
    {
      "epoch": 2.6152520465316673,
      "grad_norm": 30.312053680419922,
      "learning_rate": 2.3851788022404138e-05,
      "loss": 0.2759,
      "step": 6070
    },
    {
      "epoch": 2.6195605342524773,
      "grad_norm": 12.130681037902832,
      "learning_rate": 2.3808703145196036e-05,
      "loss": 0.276,
      "step": 6080
    },
    {
      "epoch": 2.623869021973287,
      "grad_norm": 1.6159446239471436,
      "learning_rate": 2.3765618267987937e-05,
      "loss": 0.1925,
      "step": 6090
    },
    {
      "epoch": 2.6281775096940976,
      "grad_norm": 10.396000862121582,
      "learning_rate": 2.372253339077984e-05,
      "loss": 0.2834,
      "step": 6100
    },
    {
      "epoch": 2.6324859974149075,
      "grad_norm": 8.841039657592773,
      "learning_rate": 2.3679448513571736e-05,
      "loss": 0.2956,
      "step": 6110
    },
    {
      "epoch": 2.6367944851357175,
      "grad_norm": 6.480522632598877,
      "learning_rate": 2.3636363636363637e-05,
      "loss": 0.3234,
      "step": 6120
    },
    {
      "epoch": 2.6411029728565274,
      "grad_norm": 10.502700805664062,
      "learning_rate": 2.359327875915554e-05,
      "loss": 0.221,
      "step": 6130
    },
    {
      "epoch": 2.6454114605773373,
      "grad_norm": 7.761032581329346,
      "learning_rate": 2.355019388194744e-05,
      "loss": 0.3052,
      "step": 6140
    },
    {
      "epoch": 2.6497199482981473,
      "grad_norm": 16.339017868041992,
      "learning_rate": 2.3507109004739338e-05,
      "loss": 0.2237,
      "step": 6150
    },
    {
      "epoch": 2.654028436018957,
      "grad_norm": 6.195872783660889,
      "learning_rate": 2.3464024127531235e-05,
      "loss": 0.2842,
      "step": 6160
    },
    {
      "epoch": 2.6583369237397676,
      "grad_norm": 9.6454439163208,
      "learning_rate": 2.3420939250323137e-05,
      "loss": 0.2058,
      "step": 6170
    },
    {
      "epoch": 2.662645411460577,
      "grad_norm": 6.938799858093262,
      "learning_rate": 2.3377854373115038e-05,
      "loss": 0.1737,
      "step": 6180
    },
    {
      "epoch": 2.6669538991813875,
      "grad_norm": 8.06167221069336,
      "learning_rate": 2.333476949590694e-05,
      "loss": 0.1707,
      "step": 6190
    },
    {
      "epoch": 2.6712623869021974,
      "grad_norm": 7.574416637420654,
      "learning_rate": 2.329168461869884e-05,
      "loss": 0.199,
      "step": 6200
    },
    {
      "epoch": 2.6755708746230074,
      "grad_norm": 3.2021164894104004,
      "learning_rate": 2.3248599741490738e-05,
      "loss": 0.1927,
      "step": 6210
    },
    {
      "epoch": 2.6798793623438173,
      "grad_norm": 17.78826141357422,
      "learning_rate": 2.3205514864282636e-05,
      "loss": 0.2362,
      "step": 6220
    },
    {
      "epoch": 2.6841878500646272,
      "grad_norm": 15.15188980102539,
      "learning_rate": 2.3162429987074537e-05,
      "loss": 0.1909,
      "step": 6230
    },
    {
      "epoch": 2.688496337785437,
      "grad_norm": 6.994384765625,
      "learning_rate": 2.311934510986644e-05,
      "loss": 0.1497,
      "step": 6240
    },
    {
      "epoch": 2.692804825506247,
      "grad_norm": 40.32963562011719,
      "learning_rate": 2.307626023265834e-05,
      "loss": 0.2891,
      "step": 6250
    },
    {
      "epoch": 2.6971133132270575,
      "grad_norm": 16.35993194580078,
      "learning_rate": 2.3033175355450237e-05,
      "loss": 0.4252,
      "step": 6260
    },
    {
      "epoch": 2.7014218009478674,
      "grad_norm": 13.88422966003418,
      "learning_rate": 2.299009047824214e-05,
      "loss": 0.2229,
      "step": 6270
    },
    {
      "epoch": 2.7057302886686774,
      "grad_norm": 7.3828887939453125,
      "learning_rate": 2.294700560103404e-05,
      "loss": 0.2828,
      "step": 6280
    },
    {
      "epoch": 2.7100387763894873,
      "grad_norm": 11.909412384033203,
      "learning_rate": 2.2903920723825938e-05,
      "loss": 0.217,
      "step": 6290
    },
    {
      "epoch": 2.7143472641102973,
      "grad_norm": 13.38373851776123,
      "learning_rate": 2.286083584661784e-05,
      "loss": 0.2195,
      "step": 6300
    },
    {
      "epoch": 2.718655751831107,
      "grad_norm": 4.392201900482178,
      "learning_rate": 2.2817750969409737e-05,
      "loss": 0.1754,
      "step": 6310
    },
    {
      "epoch": 2.722964239551917,
      "grad_norm": 6.656230926513672,
      "learning_rate": 2.2774666092201638e-05,
      "loss": 0.2685,
      "step": 6320
    },
    {
      "epoch": 2.7272727272727275,
      "grad_norm": 1.1181700229644775,
      "learning_rate": 2.273158121499354e-05,
      "loss": 0.2663,
      "step": 6330
    },
    {
      "epoch": 2.731581214993537,
      "grad_norm": 6.957266807556152,
      "learning_rate": 2.268849633778544e-05,
      "loss": 0.2439,
      "step": 6340
    },
    {
      "epoch": 2.7358897027143474,
      "grad_norm": 14.535552024841309,
      "learning_rate": 2.2645411460577338e-05,
      "loss": 0.2093,
      "step": 6350
    },
    {
      "epoch": 2.7401981904351573,
      "grad_norm": 6.1620659828186035,
      "learning_rate": 2.2602326583369236e-05,
      "loss": 0.271,
      "step": 6360
    },
    {
      "epoch": 2.7445066781559673,
      "grad_norm": 6.035202503204346,
      "learning_rate": 2.2559241706161137e-05,
      "loss": 0.1569,
      "step": 6370
    },
    {
      "epoch": 2.748815165876777,
      "grad_norm": 1.4461227655410767,
      "learning_rate": 2.251615682895304e-05,
      "loss": 0.284,
      "step": 6380
    },
    {
      "epoch": 2.753123653597587,
      "grad_norm": 4.986525535583496,
      "learning_rate": 2.247307195174494e-05,
      "loss": 0.2871,
      "step": 6390
    },
    {
      "epoch": 2.757432141318397,
      "grad_norm": 8.919815063476562,
      "learning_rate": 2.2429987074536838e-05,
      "loss": 0.3057,
      "step": 6400
    },
    {
      "epoch": 2.761740629039207,
      "grad_norm": 10.165839195251465,
      "learning_rate": 2.238690219732874e-05,
      "loss": 0.188,
      "step": 6410
    },
    {
      "epoch": 2.7660491167600174,
      "grad_norm": 2.597360849380493,
      "learning_rate": 2.234381732012064e-05,
      "loss": 0.2424,
      "step": 6420
    },
    {
      "epoch": 2.7703576044808274,
      "grad_norm": 4.6253228187561035,
      "learning_rate": 2.2300732442912538e-05,
      "loss": 0.1594,
      "step": 6430
    },
    {
      "epoch": 2.7746660922016373,
      "grad_norm": 20.40221405029297,
      "learning_rate": 2.225764756570444e-05,
      "loss": 0.1812,
      "step": 6440
    },
    {
      "epoch": 2.7789745799224472,
      "grad_norm": 16.58099937438965,
      "learning_rate": 2.2214562688496337e-05,
      "loss": 0.3084,
      "step": 6450
    },
    {
      "epoch": 2.783283067643257,
      "grad_norm": 8.481927871704102,
      "learning_rate": 2.2171477811288238e-05,
      "loss": 0.2356,
      "step": 6460
    },
    {
      "epoch": 2.787591555364067,
      "grad_norm": 12.90028190612793,
      "learning_rate": 2.212839293408014e-05,
      "loss": 0.3649,
      "step": 6470
    },
    {
      "epoch": 2.791900043084877,
      "grad_norm": 7.347188949584961,
      "learning_rate": 2.208530805687204e-05,
      "loss": 0.2708,
      "step": 6480
    },
    {
      "epoch": 2.7962085308056874,
      "grad_norm": 6.169014930725098,
      "learning_rate": 2.204222317966394e-05,
      "loss": 0.2769,
      "step": 6490
    },
    {
      "epoch": 2.800517018526497,
      "grad_norm": 11.33448314666748,
      "learning_rate": 2.199913830245584e-05,
      "loss": 0.184,
      "step": 6500
    },
    {
      "epoch": 2.8048255062473073,
      "grad_norm": 8.960135459899902,
      "learning_rate": 2.1956053425247737e-05,
      "loss": 0.2112,
      "step": 6510
    },
    {
      "epoch": 2.8091339939681172,
      "grad_norm": 13.597526550292969,
      "learning_rate": 2.191296854803964e-05,
      "loss": 0.2861,
      "step": 6520
    },
    {
      "epoch": 2.813442481688927,
      "grad_norm": 8.34113597869873,
      "learning_rate": 2.186988367083154e-05,
      "loss": 0.1966,
      "step": 6530
    },
    {
      "epoch": 2.817750969409737,
      "grad_norm": 4.613450050354004,
      "learning_rate": 2.182679879362344e-05,
      "loss": 0.1761,
      "step": 6540
    },
    {
      "epoch": 2.822059457130547,
      "grad_norm": 8.24013614654541,
      "learning_rate": 2.178371391641534e-05,
      "loss": 0.2664,
      "step": 6550
    },
    {
      "epoch": 2.8263679448513574,
      "grad_norm": 10.142098426818848,
      "learning_rate": 2.174062903920724e-05,
      "loss": 0.3614,
      "step": 6560
    },
    {
      "epoch": 2.830676432572167,
      "grad_norm": 15.039036750793457,
      "learning_rate": 2.1697544161999138e-05,
      "loss": 0.2673,
      "step": 6570
    },
    {
      "epoch": 2.8349849202929773,
      "grad_norm": 10.671823501586914,
      "learning_rate": 2.165445928479104e-05,
      "loss": 0.2858,
      "step": 6580
    },
    {
      "epoch": 2.8392934080137873,
      "grad_norm": 3.1170175075531006,
      "learning_rate": 2.161137440758294e-05,
      "loss": 0.1769,
      "step": 6590
    },
    {
      "epoch": 2.843601895734597,
      "grad_norm": 5.220183849334717,
      "learning_rate": 2.1568289530374838e-05,
      "loss": 0.2562,
      "step": 6600
    },
    {
      "epoch": 2.847910383455407,
      "grad_norm": 9.354273796081543,
      "learning_rate": 2.152520465316674e-05,
      "loss": 0.2333,
      "step": 6610
    },
    {
      "epoch": 2.852218871176217,
      "grad_norm": 5.856535911560059,
      "learning_rate": 2.148211977595864e-05,
      "loss": 0.1927,
      "step": 6620
    },
    {
      "epoch": 2.856527358897027,
      "grad_norm": 25.984392166137695,
      "learning_rate": 2.1439034898750542e-05,
      "loss": 0.331,
      "step": 6630
    },
    {
      "epoch": 2.860835846617837,
      "grad_norm": 4.868743896484375,
      "learning_rate": 2.139595002154244e-05,
      "loss": 0.2344,
      "step": 6640
    },
    {
      "epoch": 2.8651443343386473,
      "grad_norm": 3.598151445388794,
      "learning_rate": 2.1352865144334337e-05,
      "loss": 0.3181,
      "step": 6650
    },
    {
      "epoch": 2.8694528220594573,
      "grad_norm": 6.113214015960693,
      "learning_rate": 2.130978026712624e-05,
      "loss": 0.2201,
      "step": 6660
    },
    {
      "epoch": 2.8737613097802672,
      "grad_norm": 14.119172096252441,
      "learning_rate": 2.126669538991814e-05,
      "loss": 0.2579,
      "step": 6670
    },
    {
      "epoch": 2.878069797501077,
      "grad_norm": 9.813783645629883,
      "learning_rate": 2.122361051271004e-05,
      "loss": 0.1965,
      "step": 6680
    },
    {
      "epoch": 2.882378285221887,
      "grad_norm": 5.88205099105835,
      "learning_rate": 2.1180525635501942e-05,
      "loss": 0.3239,
      "step": 6690
    },
    {
      "epoch": 2.886686772942697,
      "grad_norm": 3.8113036155700684,
      "learning_rate": 2.113744075829384e-05,
      "loss": 0.2352,
      "step": 6700
    },
    {
      "epoch": 2.890995260663507,
      "grad_norm": 4.415079116821289,
      "learning_rate": 2.1094355881085738e-05,
      "loss": 0.2959,
      "step": 6710
    },
    {
      "epoch": 2.8953037483843174,
      "grad_norm": 2.79787278175354,
      "learning_rate": 2.105127100387764e-05,
      "loss": 0.185,
      "step": 6720
    },
    {
      "epoch": 2.899612236105127,
      "grad_norm": 9.075538635253906,
      "learning_rate": 2.100818612666954e-05,
      "loss": 0.2192,
      "step": 6730
    },
    {
      "epoch": 2.9039207238259372,
      "grad_norm": 13.480539321899414,
      "learning_rate": 2.096510124946144e-05,
      "loss": 0.3259,
      "step": 6740
    },
    {
      "epoch": 2.908229211546747,
      "grad_norm": 1.9970167875289917,
      "learning_rate": 2.092201637225334e-05,
      "loss": 0.2535,
      "step": 6750
    },
    {
      "epoch": 2.912537699267557,
      "grad_norm": 3.144469738006592,
      "learning_rate": 2.087893149504524e-05,
      "loss": 0.2098,
      "step": 6760
    },
    {
      "epoch": 2.916846186988367,
      "grad_norm": 4.961772918701172,
      "learning_rate": 2.0835846617837142e-05,
      "loss": 0.2144,
      "step": 6770
    },
    {
      "epoch": 2.921154674709177,
      "grad_norm": 8.889174461364746,
      "learning_rate": 2.079276174062904e-05,
      "loss": 0.1289,
      "step": 6780
    },
    {
      "epoch": 2.925463162429987,
      "grad_norm": 8.404722213745117,
      "learning_rate": 2.074967686342094e-05,
      "loss": 0.1563,
      "step": 6790
    },
    {
      "epoch": 2.929771650150797,
      "grad_norm": 11.743407249450684,
      "learning_rate": 2.070659198621284e-05,
      "loss": 0.1351,
      "step": 6800
    },
    {
      "epoch": 2.9340801378716073,
      "grad_norm": 9.777117729187012,
      "learning_rate": 2.066350710900474e-05,
      "loss": 0.1947,
      "step": 6810
    },
    {
      "epoch": 2.938388625592417,
      "grad_norm": 2.623926877975464,
      "learning_rate": 2.062042223179664e-05,
      "loss": 0.1484,
      "step": 6820
    },
    {
      "epoch": 2.942697113313227,
      "grad_norm": 13.162392616271973,
      "learning_rate": 2.0577337354588542e-05,
      "loss": 0.2279,
      "step": 6830
    },
    {
      "epoch": 2.947005601034037,
      "grad_norm": 3.562103033065796,
      "learning_rate": 2.053425247738044e-05,
      "loss": 0.1968,
      "step": 6840
    },
    {
      "epoch": 2.951314088754847,
      "grad_norm": 7.97245979309082,
      "learning_rate": 2.0491167600172338e-05,
      "loss": 0.1702,
      "step": 6850
    },
    {
      "epoch": 2.955622576475657,
      "grad_norm": 10.906879425048828,
      "learning_rate": 2.044808272296424e-05,
      "loss": 0.224,
      "step": 6860
    },
    {
      "epoch": 2.959931064196467,
      "grad_norm": 3.7092063426971436,
      "learning_rate": 2.040499784575614e-05,
      "loss": 0.2479,
      "step": 6870
    },
    {
      "epoch": 2.9642395519172773,
      "grad_norm": 9.690939903259277,
      "learning_rate": 2.036191296854804e-05,
      "loss": 0.1599,
      "step": 6880
    },
    {
      "epoch": 2.9685480396380868,
      "grad_norm": 15.551129341125488,
      "learning_rate": 2.0318828091339943e-05,
      "loss": 0.2801,
      "step": 6890
    },
    {
      "epoch": 2.972856527358897,
      "grad_norm": 6.547935485839844,
      "learning_rate": 2.027574321413184e-05,
      "loss": 0.2753,
      "step": 6900
    },
    {
      "epoch": 2.977165015079707,
      "grad_norm": 0.7944672703742981,
      "learning_rate": 2.0232658336923742e-05,
      "loss": 0.1716,
      "step": 6910
    },
    {
      "epoch": 2.981473502800517,
      "grad_norm": 9.524309158325195,
      "learning_rate": 2.018957345971564e-05,
      "loss": 0.275,
      "step": 6920
    },
    {
      "epoch": 2.985781990521327,
      "grad_norm": 8.43091869354248,
      "learning_rate": 2.014648858250754e-05,
      "loss": 0.2199,
      "step": 6930
    },
    {
      "epoch": 2.990090478242137,
      "grad_norm": 4.753373622894287,
      "learning_rate": 2.010340370529944e-05,
      "loss": 0.3019,
      "step": 6940
    },
    {
      "epoch": 2.994398965962947,
      "grad_norm": 2.555874824523926,
      "learning_rate": 2.006031882809134e-05,
      "loss": 0.1669,
      "step": 6950
    },
    {
      "epoch": 2.998707453683757,
      "grad_norm": 11.539107322692871,
      "learning_rate": 2.001723395088324e-05,
      "loss": 0.2293,
      "step": 6960
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.5395546555519104,
      "eval_runtime": 26.538,
      "eval_samples_per_second": 599.63,
      "eval_steps_per_second": 37.493,
      "step": 6963
    },
    {
      "epoch": 3.003015941404567,
      "grad_norm": 4.707644462585449,
      "learning_rate": 1.9974149073675142e-05,
      "loss": 0.1717,
      "step": 6970
    },
    {
      "epoch": 3.007324429125377,
      "grad_norm": 3.98152232170105,
      "learning_rate": 1.9931064196467044e-05,
      "loss": 0.1393,
      "step": 6980
    },
    {
      "epoch": 3.011632916846187,
      "grad_norm": 6.672098636627197,
      "learning_rate": 1.988797931925894e-05,
      "loss": 0.1369,
      "step": 6990
    },
    {
      "epoch": 3.015941404566997,
      "grad_norm": 2.6420631408691406,
      "learning_rate": 1.984489444205084e-05,
      "loss": 0.1318,
      "step": 7000
    },
    {
      "epoch": 3.020249892287807,
      "grad_norm": 4.464670658111572,
      "learning_rate": 1.980180956484274e-05,
      "loss": 0.1095,
      "step": 7010
    },
    {
      "epoch": 3.024558380008617,
      "grad_norm": 1.0680351257324219,
      "learning_rate": 1.975872468763464e-05,
      "loss": 0.1144,
      "step": 7020
    },
    {
      "epoch": 3.028866867729427,
      "grad_norm": 7.665433883666992,
      "learning_rate": 1.9715639810426543e-05,
      "loss": 0.0911,
      "step": 7030
    },
    {
      "epoch": 3.0331753554502368,
      "grad_norm": 0.41139790415763855,
      "learning_rate": 1.967255493321844e-05,
      "loss": 0.0852,
      "step": 7040
    },
    {
      "epoch": 3.037483843171047,
      "grad_norm": 8.845863342285156,
      "learning_rate": 1.9629470056010342e-05,
      "loss": 0.0716,
      "step": 7050
    },
    {
      "epoch": 3.041792330891857,
      "grad_norm": 0.8730683326721191,
      "learning_rate": 1.958638517880224e-05,
      "loss": 0.182,
      "step": 7060
    },
    {
      "epoch": 3.046100818612667,
      "grad_norm": 9.195772171020508,
      "learning_rate": 1.954330030159414e-05,
      "loss": 0.0518,
      "step": 7070
    },
    {
      "epoch": 3.050409306333477,
      "grad_norm": 0.05267009511590004,
      "learning_rate": 1.9500215424386042e-05,
      "loss": 0.0994,
      "step": 7080
    },
    {
      "epoch": 3.054717794054287,
      "grad_norm": 0.2739200294017792,
      "learning_rate": 1.945713054717794e-05,
      "loss": 0.0828,
      "step": 7090
    },
    {
      "epoch": 3.059026281775097,
      "grad_norm": 0.27424949407577515,
      "learning_rate": 1.941404566996984e-05,
      "loss": 0.1158,
      "step": 7100
    },
    {
      "epoch": 3.0633347694959068,
      "grad_norm": 4.502109527587891,
      "learning_rate": 1.9370960792761742e-05,
      "loss": 0.0963,
      "step": 7110
    },
    {
      "epoch": 3.0676432572167167,
      "grad_norm": 3.255492687225342,
      "learning_rate": 1.9327875915553644e-05,
      "loss": 0.0789,
      "step": 7120
    },
    {
      "epoch": 3.071951744937527,
      "grad_norm": 20.43402862548828,
      "learning_rate": 1.928479103834554e-05,
      "loss": 0.1951,
      "step": 7130
    },
    {
      "epoch": 3.076260232658337,
      "grad_norm": 2.936091661453247,
      "learning_rate": 1.924170616113744e-05,
      "loss": 0.1359,
      "step": 7140
    },
    {
      "epoch": 3.080568720379147,
      "grad_norm": 10.839210510253906,
      "learning_rate": 1.919862128392934e-05,
      "loss": 0.1077,
      "step": 7150
    },
    {
      "epoch": 3.084877208099957,
      "grad_norm": 13.868298530578613,
      "learning_rate": 1.9155536406721242e-05,
      "loss": 0.1656,
      "step": 7160
    },
    {
      "epoch": 3.089185695820767,
      "grad_norm": 1.9918866157531738,
      "learning_rate": 1.9112451529513143e-05,
      "loss": 0.1382,
      "step": 7170
    },
    {
      "epoch": 3.093494183541577,
      "grad_norm": 10.155720710754395,
      "learning_rate": 1.9069366652305044e-05,
      "loss": 0.1426,
      "step": 7180
    },
    {
      "epoch": 3.0978026712623867,
      "grad_norm": 0.3018784821033478,
      "learning_rate": 1.9026281775096942e-05,
      "loss": 0.0383,
      "step": 7190
    },
    {
      "epoch": 3.102111158983197,
      "grad_norm": 5.2196855545043945,
      "learning_rate": 1.898319689788884e-05,
      "loss": 0.1337,
      "step": 7200
    },
    {
      "epoch": 3.106419646704007,
      "grad_norm": 8.38301944732666,
      "learning_rate": 1.894011202068074e-05,
      "loss": 0.1698,
      "step": 7210
    },
    {
      "epoch": 3.110728134424817,
      "grad_norm": 20.250059127807617,
      "learning_rate": 1.8897027143472642e-05,
      "loss": 0.1679,
      "step": 7220
    },
    {
      "epoch": 3.115036622145627,
      "grad_norm": 14.942142486572266,
      "learning_rate": 1.8853942266264543e-05,
      "loss": 0.1287,
      "step": 7230
    },
    {
      "epoch": 3.119345109866437,
      "grad_norm": 1.1712806224822998,
      "learning_rate": 1.881085738905644e-05,
      "loss": 0.1013,
      "step": 7240
    },
    {
      "epoch": 3.123653597587247,
      "grad_norm": 0.48603224754333496,
      "learning_rate": 1.8767772511848342e-05,
      "loss": 0.0776,
      "step": 7250
    },
    {
      "epoch": 3.1279620853080567,
      "grad_norm": 8.747116088867188,
      "learning_rate": 1.8724687634640244e-05,
      "loss": 0.083,
      "step": 7260
    },
    {
      "epoch": 3.1322705730288667,
      "grad_norm": 20.042131423950195,
      "learning_rate": 1.868160275743214e-05,
      "loss": 0.083,
      "step": 7270
    },
    {
      "epoch": 3.1365790607496766,
      "grad_norm": 13.442291259765625,
      "learning_rate": 1.8638517880224043e-05,
      "loss": 0.1771,
      "step": 7280
    },
    {
      "epoch": 3.140887548470487,
      "grad_norm": 28.881671905517578,
      "learning_rate": 1.859543300301594e-05,
      "loss": 0.2271,
      "step": 7290
    },
    {
      "epoch": 3.145196036191297,
      "grad_norm": 1.6064866781234741,
      "learning_rate": 1.8552348125807842e-05,
      "loss": 0.1075,
      "step": 7300
    },
    {
      "epoch": 3.149504523912107,
      "grad_norm": 8.562591552734375,
      "learning_rate": 1.8509263248599743e-05,
      "loss": 0.1299,
      "step": 7310
    },
    {
      "epoch": 3.153813011632917,
      "grad_norm": 0.6551377177238464,
      "learning_rate": 1.8466178371391644e-05,
      "loss": 0.221,
      "step": 7320
    },
    {
      "epoch": 3.1581214993537268,
      "grad_norm": 8.347148895263672,
      "learning_rate": 1.8423093494183542e-05,
      "loss": 0.1996,
      "step": 7330
    },
    {
      "epoch": 3.1624299870745367,
      "grad_norm": 2.188138246536255,
      "learning_rate": 1.838000861697544e-05,
      "loss": 0.1072,
      "step": 7340
    },
    {
      "epoch": 3.1667384747953466,
      "grad_norm": 0.36479178071022034,
      "learning_rate": 1.833692373976734e-05,
      "loss": 0.0704,
      "step": 7350
    },
    {
      "epoch": 3.171046962516157,
      "grad_norm": 4.473042964935303,
      "learning_rate": 1.8293838862559242e-05,
      "loss": 0.1152,
      "step": 7360
    },
    {
      "epoch": 3.175355450236967,
      "grad_norm": 3.5534725189208984,
      "learning_rate": 1.8250753985351144e-05,
      "loss": 0.3426,
      "step": 7370
    },
    {
      "epoch": 3.179663937957777,
      "grad_norm": 3.128748893737793,
      "learning_rate": 1.8207669108143045e-05,
      "loss": 0.2275,
      "step": 7380
    },
    {
      "epoch": 3.183972425678587,
      "grad_norm": 5.654235363006592,
      "learning_rate": 1.8164584230934943e-05,
      "loss": 0.0348,
      "step": 7390
    },
    {
      "epoch": 3.188280913399397,
      "grad_norm": 4.298528671264648,
      "learning_rate": 1.8121499353726844e-05,
      "loss": 0.1351,
      "step": 7400
    },
    {
      "epoch": 3.1925894011202067,
      "grad_norm": 0.5836689472198486,
      "learning_rate": 1.807841447651874e-05,
      "loss": 0.1986,
      "step": 7410
    },
    {
      "epoch": 3.1968978888410167,
      "grad_norm": 6.091721534729004,
      "learning_rate": 1.8035329599310643e-05,
      "loss": 0.0758,
      "step": 7420
    },
    {
      "epoch": 3.2012063765618266,
      "grad_norm": 6.17554235458374,
      "learning_rate": 1.7992244722102544e-05,
      "loss": 0.1337,
      "step": 7430
    },
    {
      "epoch": 3.205514864282637,
      "grad_norm": 2.5546116828918457,
      "learning_rate": 1.7949159844894442e-05,
      "loss": 0.1438,
      "step": 7440
    },
    {
      "epoch": 3.209823352003447,
      "grad_norm": 4.717696666717529,
      "learning_rate": 1.7906074967686343e-05,
      "loss": 0.116,
      "step": 7450
    },
    {
      "epoch": 3.214131839724257,
      "grad_norm": 9.388664245605469,
      "learning_rate": 1.7862990090478244e-05,
      "loss": 0.1487,
      "step": 7460
    },
    {
      "epoch": 3.218440327445067,
      "grad_norm": 11.33554458618164,
      "learning_rate": 1.7819905213270146e-05,
      "loss": 0.1651,
      "step": 7470
    },
    {
      "epoch": 3.2227488151658767,
      "grad_norm": 19.749692916870117,
      "learning_rate": 1.7776820336062043e-05,
      "loss": 0.1184,
      "step": 7480
    },
    {
      "epoch": 3.2270573028866867,
      "grad_norm": 1.3259118795394897,
      "learning_rate": 1.773373545885394e-05,
      "loss": 0.1786,
      "step": 7490
    },
    {
      "epoch": 3.2313657906074966,
      "grad_norm": 1.5139321088790894,
      "learning_rate": 1.7690650581645842e-05,
      "loss": 0.0685,
      "step": 7500
    },
    {
      "epoch": 3.2356742783283066,
      "grad_norm": 12.972996711730957,
      "learning_rate": 1.7647565704437744e-05,
      "loss": 0.1526,
      "step": 7510
    },
    {
      "epoch": 3.239982766049117,
      "grad_norm": 1.4201347827911377,
      "learning_rate": 1.7604480827229645e-05,
      "loss": 0.1008,
      "step": 7520
    },
    {
      "epoch": 3.244291253769927,
      "grad_norm": 13.119978904724121,
      "learning_rate": 1.7561395950021543e-05,
      "loss": 0.1613,
      "step": 7530
    },
    {
      "epoch": 3.248599741490737,
      "grad_norm": 12.102926254272461,
      "learning_rate": 1.7518311072813444e-05,
      "loss": 0.2582,
      "step": 7540
    },
    {
      "epoch": 3.2529082292115468,
      "grad_norm": 0.8117759227752686,
      "learning_rate": 1.747522619560534e-05,
      "loss": 0.1427,
      "step": 7550
    },
    {
      "epoch": 3.2572167169323567,
      "grad_norm": 20.806297302246094,
      "learning_rate": 1.7432141318397243e-05,
      "loss": 0.1115,
      "step": 7560
    },
    {
      "epoch": 3.2615252046531666,
      "grad_norm": 8.327577590942383,
      "learning_rate": 1.7389056441189144e-05,
      "loss": 0.1573,
      "step": 7570
    },
    {
      "epoch": 3.2658336923739766,
      "grad_norm": 25.978151321411133,
      "learning_rate": 1.7345971563981042e-05,
      "loss": 0.107,
      "step": 7580
    },
    {
      "epoch": 3.270142180094787,
      "grad_norm": 15.259265899658203,
      "learning_rate": 1.7302886686772943e-05,
      "loss": 0.1815,
      "step": 7590
    },
    {
      "epoch": 3.274450667815597,
      "grad_norm": 11.284261703491211,
      "learning_rate": 1.7259801809564844e-05,
      "loss": 0.1915,
      "step": 7600
    },
    {
      "epoch": 3.278759155536407,
      "grad_norm": 6.541170597076416,
      "learning_rate": 1.7216716932356746e-05,
      "loss": 0.0581,
      "step": 7610
    },
    {
      "epoch": 3.283067643257217,
      "grad_norm": 12.656961441040039,
      "learning_rate": 1.7173632055148643e-05,
      "loss": 0.1145,
      "step": 7620
    },
    {
      "epoch": 3.2873761309780267,
      "grad_norm": 8.045828819274902,
      "learning_rate": 1.713054717794054e-05,
      "loss": 0.1395,
      "step": 7630
    },
    {
      "epoch": 3.2916846186988367,
      "grad_norm": 0.6543400287628174,
      "learning_rate": 1.7087462300732442e-05,
      "loss": 0.1143,
      "step": 7640
    },
    {
      "epoch": 3.2959931064196466,
      "grad_norm": 7.556183815002441,
      "learning_rate": 1.7044377423524344e-05,
      "loss": 0.1662,
      "step": 7650
    },
    {
      "epoch": 3.3003015941404565,
      "grad_norm": 1.9986697435379028,
      "learning_rate": 1.7001292546316245e-05,
      "loss": 0.0982,
      "step": 7660
    },
    {
      "epoch": 3.3046100818612665,
      "grad_norm": 16.602947235107422,
      "learning_rate": 1.6958207669108146e-05,
      "loss": 0.1796,
      "step": 7670
    },
    {
      "epoch": 3.308918569582077,
      "grad_norm": 5.520254135131836,
      "learning_rate": 1.6915122791900044e-05,
      "loss": 0.1008,
      "step": 7680
    },
    {
      "epoch": 3.313227057302887,
      "grad_norm": 19.75119400024414,
      "learning_rate": 1.6872037914691942e-05,
      "loss": 0.2263,
      "step": 7690
    },
    {
      "epoch": 3.3175355450236967,
      "grad_norm": 0.7756367921829224,
      "learning_rate": 1.6828953037483843e-05,
      "loss": 0.1892,
      "step": 7700
    },
    {
      "epoch": 3.3218440327445067,
      "grad_norm": 9.263786315917969,
      "learning_rate": 1.6785868160275744e-05,
      "loss": 0.0944,
      "step": 7710
    },
    {
      "epoch": 3.3261525204653166,
      "grad_norm": 5.226397514343262,
      "learning_rate": 1.6742783283067645e-05,
      "loss": 0.0608,
      "step": 7720
    },
    {
      "epoch": 3.3304610081861266,
      "grad_norm": 1.213058590888977,
      "learning_rate": 1.6699698405859543e-05,
      "loss": 0.0723,
      "step": 7730
    },
    {
      "epoch": 3.3347694959069365,
      "grad_norm": 10.743253707885742,
      "learning_rate": 1.6656613528651444e-05,
      "loss": 0.0747,
      "step": 7740
    },
    {
      "epoch": 3.339077983627747,
      "grad_norm": 25.05877685546875,
      "learning_rate": 1.6613528651443346e-05,
      "loss": 0.131,
      "step": 7750
    },
    {
      "epoch": 3.343386471348557,
      "grad_norm": 0.10587143898010254,
      "learning_rate": 1.6570443774235243e-05,
      "loss": 0.1621,
      "step": 7760
    },
    {
      "epoch": 3.3476949590693668,
      "grad_norm": 4.518877983093262,
      "learning_rate": 1.6527358897027145e-05,
      "loss": 0.1296,
      "step": 7770
    },
    {
      "epoch": 3.3520034467901767,
      "grad_norm": 0.5692792534828186,
      "learning_rate": 1.6484274019819042e-05,
      "loss": 0.1137,
      "step": 7780
    },
    {
      "epoch": 3.3563119345109866,
      "grad_norm": 10.437009811401367,
      "learning_rate": 1.6441189142610944e-05,
      "loss": 0.0627,
      "step": 7790
    },
    {
      "epoch": 3.3606204222317966,
      "grad_norm": 1.9927176237106323,
      "learning_rate": 1.6398104265402845e-05,
      "loss": 0.1154,
      "step": 7800
    },
    {
      "epoch": 3.3649289099526065,
      "grad_norm": 1.7022937536239624,
      "learning_rate": 1.6355019388194746e-05,
      "loss": 0.0527,
      "step": 7810
    },
    {
      "epoch": 3.3692373976734165,
      "grad_norm": 0.25845152139663696,
      "learning_rate": 1.6311934510986644e-05,
      "loss": 0.1126,
      "step": 7820
    },
    {
      "epoch": 3.3735458853942264,
      "grad_norm": 13.157682418823242,
      "learning_rate": 1.6268849633778542e-05,
      "loss": 0.1956,
      "step": 7830
    },
    {
      "epoch": 3.377854373115037,
      "grad_norm": 8.413829803466797,
      "learning_rate": 1.6225764756570443e-05,
      "loss": 0.1154,
      "step": 7840
    },
    {
      "epoch": 3.3821628608358467,
      "grad_norm": 4.037868976593018,
      "learning_rate": 1.6182679879362344e-05,
      "loss": 0.2343,
      "step": 7850
    },
    {
      "epoch": 3.3864713485566567,
      "grad_norm": 17.849945068359375,
      "learning_rate": 1.6139595002154245e-05,
      "loss": 0.1918,
      "step": 7860
    },
    {
      "epoch": 3.3907798362774666,
      "grad_norm": 2.7048230171203613,
      "learning_rate": 1.6096510124946147e-05,
      "loss": 0.0826,
      "step": 7870
    },
    {
      "epoch": 3.3950883239982765,
      "grad_norm": 15.307229042053223,
      "learning_rate": 1.6053425247738044e-05,
      "loss": 0.2507,
      "step": 7880
    },
    {
      "epoch": 3.3993968117190865,
      "grad_norm": 12.938673973083496,
      "learning_rate": 1.6010340370529946e-05,
      "loss": 0.2085,
      "step": 7890
    },
    {
      "epoch": 3.4037052994398964,
      "grad_norm": 5.178922176361084,
      "learning_rate": 1.5967255493321844e-05,
      "loss": 0.1779,
      "step": 7900
    },
    {
      "epoch": 3.408013787160707,
      "grad_norm": 11.511265754699707,
      "learning_rate": 1.5924170616113745e-05,
      "loss": 0.1209,
      "step": 7910
    },
    {
      "epoch": 3.4123222748815167,
      "grad_norm": 1.627626895904541,
      "learning_rate": 1.5881085738905646e-05,
      "loss": 0.1986,
      "step": 7920
    },
    {
      "epoch": 3.4166307626023267,
      "grad_norm": 8.87540054321289,
      "learning_rate": 1.5838000861697544e-05,
      "loss": 0.1076,
      "step": 7930
    },
    {
      "epoch": 3.4209392503231366,
      "grad_norm": 12.894648551940918,
      "learning_rate": 1.5794915984489445e-05,
      "loss": 0.1089,
      "step": 7940
    },
    {
      "epoch": 3.4252477380439466,
      "grad_norm": 8.225152015686035,
      "learning_rate": 1.5751831107281346e-05,
      "loss": 0.1878,
      "step": 7950
    },
    {
      "epoch": 3.4295562257647565,
      "grad_norm": 0.1474350094795227,
      "learning_rate": 1.5708746230073247e-05,
      "loss": 0.1252,
      "step": 7960
    },
    {
      "epoch": 3.4338647134855664,
      "grad_norm": 3.6839942932128906,
      "learning_rate": 1.5665661352865145e-05,
      "loss": 0.1286,
      "step": 7970
    },
    {
      "epoch": 3.4381732012063764,
      "grad_norm": 0.3561653196811676,
      "learning_rate": 1.5622576475657043e-05,
      "loss": 0.0723,
      "step": 7980
    },
    {
      "epoch": 3.4424816889271863,
      "grad_norm": 4.630277156829834,
      "learning_rate": 1.5579491598448944e-05,
      "loss": 0.1183,
      "step": 7990
    },
    {
      "epoch": 3.4467901766479967,
      "grad_norm": 2.0984160900115967,
      "learning_rate": 1.5536406721240846e-05,
      "loss": 0.2345,
      "step": 8000
    },
    {
      "epoch": 3.4510986643688066,
      "grad_norm": 4.74329948425293,
      "learning_rate": 1.5493321844032747e-05,
      "loss": 0.1344,
      "step": 8010
    },
    {
      "epoch": 3.4554071520896166,
      "grad_norm": 18.869327545166016,
      "learning_rate": 1.5450236966824648e-05,
      "loss": 0.1355,
      "step": 8020
    },
    {
      "epoch": 3.4597156398104265,
      "grad_norm": 14.602334976196289,
      "learning_rate": 1.5407152089616546e-05,
      "loss": 0.1884,
      "step": 8030
    },
    {
      "epoch": 3.4640241275312365,
      "grad_norm": 0.058773696422576904,
      "learning_rate": 1.5364067212408444e-05,
      "loss": 0.2099,
      "step": 8040
    },
    {
      "epoch": 3.4683326152520464,
      "grad_norm": 0.17821015417575836,
      "learning_rate": 1.5320982335200345e-05,
      "loss": 0.1983,
      "step": 8050
    },
    {
      "epoch": 3.4726411029728563,
      "grad_norm": 9.183401107788086,
      "learning_rate": 1.5277897457992246e-05,
      "loss": 0.1094,
      "step": 8060
    },
    {
      "epoch": 3.4769495906936667,
      "grad_norm": 5.063354969024658,
      "learning_rate": 1.5234812580784147e-05,
      "loss": 0.0697,
      "step": 8070
    },
    {
      "epoch": 3.4812580784144767,
      "grad_norm": 1.0188087224960327,
      "learning_rate": 1.5191727703576045e-05,
      "loss": 0.1579,
      "step": 8080
    },
    {
      "epoch": 3.4855665661352866,
      "grad_norm": 0.33347588777542114,
      "learning_rate": 1.5148642826367945e-05,
      "loss": 0.2662,
      "step": 8090
    },
    {
      "epoch": 3.4898750538560965,
      "grad_norm": 9.90976333618164,
      "learning_rate": 1.5105557949159846e-05,
      "loss": 0.2867,
      "step": 8100
    },
    {
      "epoch": 3.4941835415769065,
      "grad_norm": 29.682321548461914,
      "learning_rate": 1.5062473071951747e-05,
      "loss": 0.1601,
      "step": 8110
    },
    {
      "epoch": 3.4984920292977164,
      "grad_norm": 7.571852684020996,
      "learning_rate": 1.5019388194743645e-05,
      "loss": 0.132,
      "step": 8120
    },
    {
      "epoch": 3.5028005170185263,
      "grad_norm": 11.10373306274414,
      "learning_rate": 1.4976303317535544e-05,
      "loss": 0.1655,
      "step": 8130
    },
    {
      "epoch": 3.5071090047393367,
      "grad_norm": 21.601377487182617,
      "learning_rate": 1.4933218440327446e-05,
      "loss": 0.2359,
      "step": 8140
    },
    {
      "epoch": 3.5114174924601462,
      "grad_norm": 0.3309980630874634,
      "learning_rate": 1.4890133563119347e-05,
      "loss": 0.1193,
      "step": 8150
    },
    {
      "epoch": 3.5157259801809566,
      "grad_norm": 7.436139106750488,
      "learning_rate": 1.4847048685911246e-05,
      "loss": 0.1181,
      "step": 8160
    },
    {
      "epoch": 3.5200344679017666,
      "grad_norm": 0.5549774765968323,
      "learning_rate": 1.4803963808703144e-05,
      "loss": 0.1034,
      "step": 8170
    },
    {
      "epoch": 3.5243429556225765,
      "grad_norm": 8.762384414672852,
      "learning_rate": 1.4760878931495045e-05,
      "loss": 0.176,
      "step": 8180
    },
    {
      "epoch": 3.5286514433433864,
      "grad_norm": 0.2937701940536499,
      "learning_rate": 1.4717794054286947e-05,
      "loss": 0.078,
      "step": 8190
    },
    {
      "epoch": 3.5329599310641964,
      "grad_norm": 6.577700614929199,
      "learning_rate": 1.4674709177078846e-05,
      "loss": 0.1607,
      "step": 8200
    },
    {
      "epoch": 3.5372684187850063,
      "grad_norm": 0.6292824149131775,
      "learning_rate": 1.4631624299870747e-05,
      "loss": 0.2024,
      "step": 8210
    },
    {
      "epoch": 3.5415769065058162,
      "grad_norm": 0.8232462406158447,
      "learning_rate": 1.4588539422662645e-05,
      "loss": 0.1773,
      "step": 8220
    },
    {
      "epoch": 3.5458853942266266,
      "grad_norm": 5.282741546630859,
      "learning_rate": 1.4545454545454545e-05,
      "loss": 0.0836,
      "step": 8230
    },
    {
      "epoch": 3.5501938819474366,
      "grad_norm": 2.649595022201538,
      "learning_rate": 1.4502369668246446e-05,
      "loss": 0.0965,
      "step": 8240
    },
    {
      "epoch": 3.5545023696682465,
      "grad_norm": 22.843198776245117,
      "learning_rate": 1.4459284791038347e-05,
      "loss": 0.1396,
      "step": 8250
    },
    {
      "epoch": 3.5588108573890564,
      "grad_norm": 0.302390992641449,
      "learning_rate": 1.4416199913830247e-05,
      "loss": 0.0771,
      "step": 8260
    },
    {
      "epoch": 3.5631193451098664,
      "grad_norm": 0.27408021688461304,
      "learning_rate": 1.4373115036622144e-05,
      "loss": 0.184,
      "step": 8270
    },
    {
      "epoch": 3.5674278328306763,
      "grad_norm": 21.00216293334961,
      "learning_rate": 1.4330030159414046e-05,
      "loss": 0.1221,
      "step": 8280
    },
    {
      "epoch": 3.5717363205514863,
      "grad_norm": 8.948657989501953,
      "learning_rate": 1.4286945282205947e-05,
      "loss": 0.1829,
      "step": 8290
    },
    {
      "epoch": 3.5760448082722966,
      "grad_norm": 8.062211990356445,
      "learning_rate": 1.4243860404997846e-05,
      "loss": 0.1666,
      "step": 8300
    },
    {
      "epoch": 3.580353295993106,
      "grad_norm": 15.871240615844727,
      "learning_rate": 1.4200775527789748e-05,
      "loss": 0.2374,
      "step": 8310
    },
    {
      "epoch": 3.5846617837139165,
      "grad_norm": 3.7052485942840576,
      "learning_rate": 1.4157690650581645e-05,
      "loss": 0.1679,
      "step": 8320
    },
    {
      "epoch": 3.5889702714347265,
      "grad_norm": 1.9224424362182617,
      "learning_rate": 1.4114605773373547e-05,
      "loss": 0.1147,
      "step": 8330
    },
    {
      "epoch": 3.5932787591555364,
      "grad_norm": 7.2112016677856445,
      "learning_rate": 1.4071520896165446e-05,
      "loss": 0.1085,
      "step": 8340
    },
    {
      "epoch": 3.5975872468763463,
      "grad_norm": 0.4139249622821808,
      "learning_rate": 1.4028436018957347e-05,
      "loss": 0.1598,
      "step": 8350
    },
    {
      "epoch": 3.6018957345971563,
      "grad_norm": 1.2917976379394531,
      "learning_rate": 1.3985351141749249e-05,
      "loss": 0.1553,
      "step": 8360
    },
    {
      "epoch": 3.6062042223179667,
      "grad_norm": 0.6940821409225464,
      "learning_rate": 1.3942266264541146e-05,
      "loss": 0.0285,
      "step": 8370
    },
    {
      "epoch": 3.610512710038776,
      "grad_norm": 25.60297203063965,
      "learning_rate": 1.3899181387333046e-05,
      "loss": 0.1272,
      "step": 8380
    },
    {
      "epoch": 3.6148211977595865,
      "grad_norm": 8.206470489501953,
      "learning_rate": 1.3856096510124947e-05,
      "loss": 0.1502,
      "step": 8390
    },
    {
      "epoch": 3.6191296854803965,
      "grad_norm": 15.616686820983887,
      "learning_rate": 1.3813011632916847e-05,
      "loss": 0.1523,
      "step": 8400
    },
    {
      "epoch": 3.6234381732012064,
      "grad_norm": 0.5385466814041138,
      "learning_rate": 1.3769926755708748e-05,
      "loss": 0.1228,
      "step": 8410
    },
    {
      "epoch": 3.6277466609220164,
      "grad_norm": 11.552902221679688,
      "learning_rate": 1.3726841878500646e-05,
      "loss": 0.1193,
      "step": 8420
    },
    {
      "epoch": 3.6320551486428263,
      "grad_norm": 2.1254684925079346,
      "learning_rate": 1.3683757001292547e-05,
      "loss": 0.0702,
      "step": 8430
    },
    {
      "epoch": 3.6363636363636362,
      "grad_norm": 20.026779174804688,
      "learning_rate": 1.3640672124084446e-05,
      "loss": 0.2333,
      "step": 8440
    },
    {
      "epoch": 3.640672124084446,
      "grad_norm": 2.016732692718506,
      "learning_rate": 1.3597587246876348e-05,
      "loss": 0.1522,
      "step": 8450
    },
    {
      "epoch": 3.6449806118052566,
      "grad_norm": 0.41337141394615173,
      "learning_rate": 1.3554502369668249e-05,
      "loss": 0.1443,
      "step": 8460
    },
    {
      "epoch": 3.6492890995260665,
      "grad_norm": 0.08417998254299164,
      "learning_rate": 1.3511417492460147e-05,
      "loss": 0.0811,
      "step": 8470
    },
    {
      "epoch": 3.6535975872468764,
      "grad_norm": 0.5308675765991211,
      "learning_rate": 1.3468332615252046e-05,
      "loss": 0.1047,
      "step": 8480
    },
    {
      "epoch": 3.6579060749676864,
      "grad_norm": 8.331437110900879,
      "learning_rate": 1.3425247738043947e-05,
      "loss": 0.2557,
      "step": 8490
    },
    {
      "epoch": 3.6622145626884963,
      "grad_norm": 2.4911773204803467,
      "learning_rate": 1.3382162860835849e-05,
      "loss": 0.1099,
      "step": 8500
    },
    {
      "epoch": 3.6665230504093063,
      "grad_norm": 12.14841079711914,
      "learning_rate": 1.3339077983627748e-05,
      "loss": 0.2087,
      "step": 8510
    },
    {
      "epoch": 3.670831538130116,
      "grad_norm": 1.2575583457946777,
      "learning_rate": 1.3295993106419646e-05,
      "loss": 0.129,
      "step": 8520
    },
    {
      "epoch": 3.6751400258509266,
      "grad_norm": 4.092909812927246,
      "learning_rate": 1.3252908229211547e-05,
      "loss": 0.1103,
      "step": 8530
    },
    {
      "epoch": 3.679448513571736,
      "grad_norm": 5.196098804473877,
      "learning_rate": 1.3209823352003447e-05,
      "loss": 0.0945,
      "step": 8540
    },
    {
      "epoch": 3.6837570012925465,
      "grad_norm": 12.541610717773438,
      "learning_rate": 1.3166738474795348e-05,
      "loss": 0.2277,
      "step": 8550
    },
    {
      "epoch": 3.6880654890133564,
      "grad_norm": 14.214539527893066,
      "learning_rate": 1.3123653597587249e-05,
      "loss": 0.1452,
      "step": 8560
    },
    {
      "epoch": 3.6923739767341663,
      "grad_norm": 6.457083225250244,
      "learning_rate": 1.3080568720379147e-05,
      "loss": 0.1037,
      "step": 8570
    },
    {
      "epoch": 3.6966824644549763,
      "grad_norm": 11.41087818145752,
      "learning_rate": 1.3037483843171046e-05,
      "loss": 0.1162,
      "step": 8580
    },
    {
      "epoch": 3.700990952175786,
      "grad_norm": 5.198583126068115,
      "learning_rate": 1.2994398965962948e-05,
      "loss": 0.0895,
      "step": 8590
    },
    {
      "epoch": 3.705299439896596,
      "grad_norm": 1.138890266418457,
      "learning_rate": 1.2951314088754849e-05,
      "loss": 0.0896,
      "step": 8600
    },
    {
      "epoch": 3.709607927617406,
      "grad_norm": 0.7789103984832764,
      "learning_rate": 1.2908229211546748e-05,
      "loss": 0.1838,
      "step": 8610
    },
    {
      "epoch": 3.7139164153382165,
      "grad_norm": 8.937543869018555,
      "learning_rate": 1.2865144334338646e-05,
      "loss": 0.0722,
      "step": 8620
    },
    {
      "epoch": 3.7182249030590264,
      "grad_norm": 2.056204319000244,
      "learning_rate": 1.2822059457130547e-05,
      "loss": 0.1421,
      "step": 8630
    },
    {
      "epoch": 3.7225333907798364,
      "grad_norm": 3.302293062210083,
      "learning_rate": 1.2778974579922449e-05,
      "loss": 0.1335,
      "step": 8640
    },
    {
      "epoch": 3.7268418785006463,
      "grad_norm": 0.9753842353820801,
      "learning_rate": 1.2735889702714348e-05,
      "loss": 0.0802,
      "step": 8650
    },
    {
      "epoch": 3.7311503662214562,
      "grad_norm": 11.385757446289062,
      "learning_rate": 1.269280482550625e-05,
      "loss": 0.1123,
      "step": 8660
    },
    {
      "epoch": 3.735458853942266,
      "grad_norm": 0.4823223352432251,
      "learning_rate": 1.2649719948298147e-05,
      "loss": 0.097,
      "step": 8670
    },
    {
      "epoch": 3.739767341663076,
      "grad_norm": 4.668694496154785,
      "learning_rate": 1.2606635071090048e-05,
      "loss": 0.0439,
      "step": 8680
    },
    {
      "epoch": 3.7440758293838865,
      "grad_norm": 18.650009155273438,
      "learning_rate": 1.2563550193881948e-05,
      "loss": 0.2446,
      "step": 8690
    },
    {
      "epoch": 3.748384317104696,
      "grad_norm": 5.595440864562988,
      "learning_rate": 1.252046531667385e-05,
      "loss": 0.0579,
      "step": 8700
    },
    {
      "epoch": 3.7526928048255064,
      "grad_norm": 9.79195785522461,
      "learning_rate": 1.2477380439465749e-05,
      "loss": 0.1174,
      "step": 8710
    },
    {
      "epoch": 3.7570012925463163,
      "grad_norm": 7.933449745178223,
      "learning_rate": 1.2434295562257648e-05,
      "loss": 0.0707,
      "step": 8720
    },
    {
      "epoch": 3.7613097802671263,
      "grad_norm": 16.287940979003906,
      "learning_rate": 1.2391210685049548e-05,
      "loss": 0.2339,
      "step": 8730
    },
    {
      "epoch": 3.765618267987936,
      "grad_norm": 5.520149230957031,
      "learning_rate": 1.2348125807841449e-05,
      "loss": 0.0717,
      "step": 8740
    },
    {
      "epoch": 3.769926755708746,
      "grad_norm": 13.974228858947754,
      "learning_rate": 1.2305040930633349e-05,
      "loss": 0.1303,
      "step": 8750
    },
    {
      "epoch": 3.774235243429556,
      "grad_norm": 7.210999011993408,
      "learning_rate": 1.2261956053425248e-05,
      "loss": 0.1141,
      "step": 8760
    },
    {
      "epoch": 3.778543731150366,
      "grad_norm": 13.469807624816895,
      "learning_rate": 1.221887117621715e-05,
      "loss": 0.1725,
      "step": 8770
    },
    {
      "epoch": 3.7828522188711764,
      "grad_norm": 3.9858756065368652,
      "learning_rate": 1.2175786299009049e-05,
      "loss": 0.1016,
      "step": 8780
    },
    {
      "epoch": 3.7871607065919863,
      "grad_norm": 0.30414828658103943,
      "learning_rate": 1.2132701421800948e-05,
      "loss": 0.1308,
      "step": 8790
    },
    {
      "epoch": 3.7914691943127963,
      "grad_norm": 16.461523056030273,
      "learning_rate": 1.2089616544592848e-05,
      "loss": 0.2183,
      "step": 8800
    },
    {
      "epoch": 3.795777682033606,
      "grad_norm": 1.6549944877624512,
      "learning_rate": 1.2046531667384749e-05,
      "loss": 0.1114,
      "step": 8810
    },
    {
      "epoch": 3.800086169754416,
      "grad_norm": 14.28042984008789,
      "learning_rate": 1.2003446790176649e-05,
      "loss": 0.0434,
      "step": 8820
    },
    {
      "epoch": 3.804394657475226,
      "grad_norm": 45.3098258972168,
      "learning_rate": 1.1960361912968548e-05,
      "loss": 0.1805,
      "step": 8830
    },
    {
      "epoch": 3.808703145196036,
      "grad_norm": 9.396843910217285,
      "learning_rate": 1.191727703576045e-05,
      "loss": 0.1456,
      "step": 8840
    },
    {
      "epoch": 3.8130116329168464,
      "grad_norm": 14.383102416992188,
      "learning_rate": 1.1874192158552349e-05,
      "loss": 0.1413,
      "step": 8850
    },
    {
      "epoch": 3.817320120637656,
      "grad_norm": 44.79193878173828,
      "learning_rate": 1.1831107281344248e-05,
      "loss": 0.1132,
      "step": 8860
    },
    {
      "epoch": 3.8216286083584663,
      "grad_norm": 25.659669876098633,
      "learning_rate": 1.1788022404136148e-05,
      "loss": 0.2406,
      "step": 8870
    },
    {
      "epoch": 3.8259370960792762,
      "grad_norm": 3.7551400661468506,
      "learning_rate": 1.1744937526928049e-05,
      "loss": 0.0739,
      "step": 8880
    },
    {
      "epoch": 3.830245583800086,
      "grad_norm": 0.43148699402809143,
      "learning_rate": 1.1701852649719949e-05,
      "loss": 0.1263,
      "step": 8890
    },
    {
      "epoch": 3.834554071520896,
      "grad_norm": 26.578414916992188,
      "learning_rate": 1.1658767772511848e-05,
      "loss": 0.1768,
      "step": 8900
    },
    {
      "epoch": 3.838862559241706,
      "grad_norm": 0.7522236704826355,
      "learning_rate": 1.161568289530375e-05,
      "loss": 0.073,
      "step": 8910
    },
    {
      "epoch": 3.843171046962516,
      "grad_norm": 15.358839988708496,
      "learning_rate": 1.1572598018095649e-05,
      "loss": 0.0617,
      "step": 8920
    },
    {
      "epoch": 3.847479534683326,
      "grad_norm": 0.5614939332008362,
      "learning_rate": 1.1529513140887548e-05,
      "loss": 0.1227,
      "step": 8930
    },
    {
      "epoch": 3.8517880224041363,
      "grad_norm": 29.716657638549805,
      "learning_rate": 1.148642826367945e-05,
      "loss": 0.1624,
      "step": 8940
    },
    {
      "epoch": 3.8560965101249463,
      "grad_norm": 1.1671665906906128,
      "learning_rate": 1.1443343386471349e-05,
      "loss": 0.1532,
      "step": 8950
    },
    {
      "epoch": 3.860404997845756,
      "grad_norm": 0.17446723580360413,
      "learning_rate": 1.1400258509263249e-05,
      "loss": 0.097,
      "step": 8960
    },
    {
      "epoch": 3.864713485566566,
      "grad_norm": 2.9568257331848145,
      "learning_rate": 1.1357173632055148e-05,
      "loss": 0.121,
      "step": 8970
    },
    {
      "epoch": 3.869021973287376,
      "grad_norm": 5.7252092361450195,
      "learning_rate": 1.131408875484705e-05,
      "loss": 0.125,
      "step": 8980
    },
    {
      "epoch": 3.873330461008186,
      "grad_norm": 2.355726957321167,
      "learning_rate": 1.127100387763895e-05,
      "loss": 0.1042,
      "step": 8990
    },
    {
      "epoch": 3.877638948728996,
      "grad_norm": 4.556172847747803,
      "learning_rate": 1.1227919000430848e-05,
      "loss": 0.1412,
      "step": 9000
    },
    {
      "epoch": 3.8819474364498063,
      "grad_norm": 8.267448425292969,
      "learning_rate": 1.118483412322275e-05,
      "loss": 0.1087,
      "step": 9010
    },
    {
      "epoch": 3.8862559241706163,
      "grad_norm": 0.13087640702724457,
      "learning_rate": 1.1141749246014649e-05,
      "loss": 0.1718,
      "step": 9020
    },
    {
      "epoch": 3.890564411891426,
      "grad_norm": 1.394288420677185,
      "learning_rate": 1.1098664368806549e-05,
      "loss": 0.1722,
      "step": 9030
    },
    {
      "epoch": 3.894872899612236,
      "grad_norm": 4.137319564819336,
      "learning_rate": 1.105557949159845e-05,
      "loss": 0.1494,
      "step": 9040
    },
    {
      "epoch": 3.899181387333046,
      "grad_norm": 9.679289817810059,
      "learning_rate": 1.101249461439035e-05,
      "loss": 0.2169,
      "step": 9050
    },
    {
      "epoch": 3.903489875053856,
      "grad_norm": 3.6828689575195312,
      "learning_rate": 1.096940973718225e-05,
      "loss": 0.0826,
      "step": 9060
    },
    {
      "epoch": 3.907798362774666,
      "grad_norm": 2.5483670234680176,
      "learning_rate": 1.0926324859974148e-05,
      "loss": 0.0898,
      "step": 9070
    },
    {
      "epoch": 3.9121068504954764,
      "grad_norm": 1.2114441394805908,
      "learning_rate": 1.088323998276605e-05,
      "loss": 0.0692,
      "step": 9080
    },
    {
      "epoch": 3.916415338216286,
      "grad_norm": 0.1775699108839035,
      "learning_rate": 1.0840155105557951e-05,
      "loss": 0.1,
      "step": 9090
    },
    {
      "epoch": 3.9207238259370962,
      "grad_norm": 6.56398344039917,
      "learning_rate": 1.079707022834985e-05,
      "loss": 0.1969,
      "step": 9100
    },
    {
      "epoch": 3.925032313657906,
      "grad_norm": 9.834529876708984,
      "learning_rate": 1.075398535114175e-05,
      "loss": 0.1314,
      "step": 9110
    },
    {
      "epoch": 3.929340801378716,
      "grad_norm": 0.586729109287262,
      "learning_rate": 1.071090047393365e-05,
      "loss": 0.1588,
      "step": 9120
    },
    {
      "epoch": 3.933649289099526,
      "grad_norm": 10.006730079650879,
      "learning_rate": 1.066781559672555e-05,
      "loss": 0.1032,
      "step": 9130
    },
    {
      "epoch": 3.937957776820336,
      "grad_norm": 22.00007438659668,
      "learning_rate": 1.0624730719517448e-05,
      "loss": 0.1687,
      "step": 9140
    },
    {
      "epoch": 3.942266264541146,
      "grad_norm": 1.745311975479126,
      "learning_rate": 1.058164584230935e-05,
      "loss": 0.095,
      "step": 9150
    },
    {
      "epoch": 3.946574752261956,
      "grad_norm": 26.86330795288086,
      "learning_rate": 1.0538560965101251e-05,
      "loss": 0.1566,
      "step": 9160
    },
    {
      "epoch": 3.9508832399827662,
      "grad_norm": 7.262691974639893,
      "learning_rate": 1.049547608789315e-05,
      "loss": 0.1301,
      "step": 9170
    },
    {
      "epoch": 3.955191727703576,
      "grad_norm": 5.518339157104492,
      "learning_rate": 1.045239121068505e-05,
      "loss": 0.0949,
      "step": 9180
    },
    {
      "epoch": 3.959500215424386,
      "grad_norm": 0.8731497526168823,
      "learning_rate": 1.040930633347695e-05,
      "loss": 0.1282,
      "step": 9190
    },
    {
      "epoch": 3.963808703145196,
      "grad_norm": 0.05710858851671219,
      "learning_rate": 1.036622145626885e-05,
      "loss": 0.0695,
      "step": 9200
    },
    {
      "epoch": 3.968117190866006,
      "grad_norm": 7.4671711921691895,
      "learning_rate": 1.032313657906075e-05,
      "loss": 0.1337,
      "step": 9210
    },
    {
      "epoch": 3.972425678586816,
      "grad_norm": 1.8321022987365723,
      "learning_rate": 1.028005170185265e-05,
      "loss": 0.0893,
      "step": 9220
    },
    {
      "epoch": 3.976734166307626,
      "grad_norm": 5.158494472503662,
      "learning_rate": 1.0236966824644551e-05,
      "loss": 0.1012,
      "step": 9230
    },
    {
      "epoch": 3.9810426540284363,
      "grad_norm": 5.609950065612793,
      "learning_rate": 1.019388194743645e-05,
      "loss": 0.0678,
      "step": 9240
    },
    {
      "epoch": 3.9853511417492458,
      "grad_norm": 21.991395950317383,
      "learning_rate": 1.015079707022835e-05,
      "loss": 0.1619,
      "step": 9250
    },
    {
      "epoch": 3.989659629470056,
      "grad_norm": 0.1681545376777649,
      "learning_rate": 1.0107712193020251e-05,
      "loss": 0.0864,
      "step": 9260
    },
    {
      "epoch": 3.993968117190866,
      "grad_norm": 18.20203399658203,
      "learning_rate": 1.006462731581215e-05,
      "loss": 0.1724,
      "step": 9270
    },
    {
      "epoch": 3.998276604911676,
      "grad_norm": 1.016013503074646,
      "learning_rate": 1.002154243860405e-05,
      "loss": 0.107,
      "step": 9280
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.758908748626709,
      "eval_runtime": 26.5315,
      "eval_samples_per_second": 599.777,
      "eval_steps_per_second": 37.503,
      "step": 9284
    },
    {
      "epoch": 4.002585092632486,
      "grad_norm": 19.19277572631836,
      "learning_rate": 9.97845756139595e-06,
      "loss": 0.1966,
      "step": 9290
    },
    {
      "epoch": 4.006893580353296,
      "grad_norm": 0.6220364570617676,
      "learning_rate": 9.935372684187851e-06,
      "loss": 0.0813,
      "step": 9300
    },
    {
      "epoch": 4.011202068074106,
      "grad_norm": 8.93072509765625,
      "learning_rate": 9.89228780697975e-06,
      "loss": 0.0525,
      "step": 9310
    },
    {
      "epoch": 4.015510555794916,
      "grad_norm": 6.381407260894775,
      "learning_rate": 9.84920292977165e-06,
      "loss": 0.0524,
      "step": 9320
    },
    {
      "epoch": 4.019819043515726,
      "grad_norm": 21.96738052368164,
      "learning_rate": 9.806118052563551e-06,
      "loss": 0.0451,
      "step": 9330
    },
    {
      "epoch": 4.024127531236536,
      "grad_norm": 1.2250975370407104,
      "learning_rate": 9.76303317535545e-06,
      "loss": 0.0255,
      "step": 9340
    },
    {
      "epoch": 4.028436018957346,
      "grad_norm": 0.05741589888930321,
      "learning_rate": 9.71994829814735e-06,
      "loss": 0.0726,
      "step": 9350
    },
    {
      "epoch": 4.0327445066781555,
      "grad_norm": 15.381179809570312,
      "learning_rate": 9.676863420939251e-06,
      "loss": 0.128,
      "step": 9360
    },
    {
      "epoch": 4.037052994398966,
      "grad_norm": 33.7090950012207,
      "learning_rate": 9.633778543731151e-06,
      "loss": 0.1218,
      "step": 9370
    },
    {
      "epoch": 4.041361482119776,
      "grad_norm": 0.2855370342731476,
      "learning_rate": 9.59069366652305e-06,
      "loss": 0.069,
      "step": 9380
    },
    {
      "epoch": 4.045669969840586,
      "grad_norm": 9.491228103637695,
      "learning_rate": 9.54760878931495e-06,
      "loss": 0.1355,
      "step": 9390
    },
    {
      "epoch": 4.049978457561396,
      "grad_norm": 10.110684394836426,
      "learning_rate": 9.504523912106851e-06,
      "loss": 0.1309,
      "step": 9400
    },
    {
      "epoch": 4.054286945282206,
      "grad_norm": 0.20225046575069427,
      "learning_rate": 9.461439034898752e-06,
      "loss": 0.1159,
      "step": 9410
    },
    {
      "epoch": 4.058595433003016,
      "grad_norm": 0.26036685705184937,
      "learning_rate": 9.41835415769065e-06,
      "loss": 0.0494,
      "step": 9420
    },
    {
      "epoch": 4.062903920723826,
      "grad_norm": 0.20578207075595856,
      "learning_rate": 9.375269280482551e-06,
      "loss": 0.051,
      "step": 9430
    },
    {
      "epoch": 4.067212408444636,
      "grad_norm": 17.552156448364258,
      "learning_rate": 9.332184403274451e-06,
      "loss": 0.0727,
      "step": 9440
    },
    {
      "epoch": 4.071520896165446,
      "grad_norm": 0.4201139211654663,
      "learning_rate": 9.28909952606635e-06,
      "loss": 0.0042,
      "step": 9450
    },
    {
      "epoch": 4.075829383886256,
      "grad_norm": 44.08575439453125,
      "learning_rate": 9.24601464885825e-06,
      "loss": 0.0609,
      "step": 9460
    },
    {
      "epoch": 4.080137871607066,
      "grad_norm": 0.13301779329776764,
      "learning_rate": 9.202929771650151e-06,
      "loss": 0.0626,
      "step": 9470
    },
    {
      "epoch": 4.084446359327876,
      "grad_norm": 0.9148983359336853,
      "learning_rate": 9.159844894442052e-06,
      "loss": 0.006,
      "step": 9480
    },
    {
      "epoch": 4.088754847048686,
      "grad_norm": 1.8263826370239258,
      "learning_rate": 9.11676001723395e-06,
      "loss": 0.0426,
      "step": 9490
    },
    {
      "epoch": 4.093063334769496,
      "grad_norm": 0.1798064112663269,
      "learning_rate": 9.073675140025852e-06,
      "loss": 0.0295,
      "step": 9500
    },
    {
      "epoch": 4.097371822490306,
      "grad_norm": 0.22078005969524384,
      "learning_rate": 9.030590262817751e-06,
      "loss": 0.1001,
      "step": 9510
    },
    {
      "epoch": 4.1016803102111155,
      "grad_norm": 2.5724692344665527,
      "learning_rate": 8.98750538560965e-06,
      "loss": 0.0398,
      "step": 9520
    },
    {
      "epoch": 4.105988797931926,
      "grad_norm": 1.1597068309783936,
      "learning_rate": 8.944420508401552e-06,
      "loss": 0.0719,
      "step": 9530
    },
    {
      "epoch": 4.110297285652736,
      "grad_norm": 1.516096591949463,
      "learning_rate": 8.901335631193451e-06,
      "loss": 0.0952,
      "step": 9540
    },
    {
      "epoch": 4.114605773373546,
      "grad_norm": 0.5488196611404419,
      "learning_rate": 8.858250753985353e-06,
      "loss": 0.0493,
      "step": 9550
    },
    {
      "epoch": 4.118914261094356,
      "grad_norm": 0.030733440071344376,
      "learning_rate": 8.81516587677725e-06,
      "loss": 0.0455,
      "step": 9560
    },
    {
      "epoch": 4.123222748815166,
      "grad_norm": 1.401014804840088,
      "learning_rate": 8.772080999569152e-06,
      "loss": 0.1139,
      "step": 9570
    },
    {
      "epoch": 4.127531236535976,
      "grad_norm": 23.048643112182617,
      "learning_rate": 8.728996122361053e-06,
      "loss": 0.0643,
      "step": 9580
    },
    {
      "epoch": 4.1318397242567855,
      "grad_norm": 44.99537658691406,
      "learning_rate": 8.685911245152952e-06,
      "loss": 0.039,
      "step": 9590
    },
    {
      "epoch": 4.136148211977596,
      "grad_norm": 13.365920066833496,
      "learning_rate": 8.642826367944852e-06,
      "loss": 0.0431,
      "step": 9600
    },
    {
      "epoch": 4.140456699698406,
      "grad_norm": 6.390340328216553,
      "learning_rate": 8.599741490736751e-06,
      "loss": 0.0055,
      "step": 9610
    },
    {
      "epoch": 4.144765187419216,
      "grad_norm": 4.6821160316467285,
      "learning_rate": 8.556656613528653e-06,
      "loss": 0.0202,
      "step": 9620
    },
    {
      "epoch": 4.149073675140026,
      "grad_norm": 0.022010568529367447,
      "learning_rate": 8.513571736320552e-06,
      "loss": 0.1119,
      "step": 9630
    },
    {
      "epoch": 4.153382162860836,
      "grad_norm": 41.1430549621582,
      "learning_rate": 8.470486859112452e-06,
      "loss": 0.0787,
      "step": 9640
    },
    {
      "epoch": 4.157690650581646,
      "grad_norm": 0.34841614961624146,
      "learning_rate": 8.427401981904353e-06,
      "loss": 0.084,
      "step": 9650
    },
    {
      "epoch": 4.1619991383024555,
      "grad_norm": 0.027384819462895393,
      "learning_rate": 8.384317104696252e-06,
      "loss": 0.0925,
      "step": 9660
    },
    {
      "epoch": 4.166307626023266,
      "grad_norm": 4.298120498657227,
      "learning_rate": 8.341232227488152e-06,
      "loss": 0.1435,
      "step": 9670
    },
    {
      "epoch": 4.170616113744076,
      "grad_norm": 0.05455392971634865,
      "learning_rate": 8.298147350280053e-06,
      "loss": 0.1421,
      "step": 9680
    },
    {
      "epoch": 4.174924601464886,
      "grad_norm": 0.0950060561299324,
      "learning_rate": 8.255062473071953e-06,
      "loss": 0.0583,
      "step": 9690
    },
    {
      "epoch": 4.179233089185696,
      "grad_norm": 30.770219802856445,
      "learning_rate": 8.211977595863852e-06,
      "loss": 0.1711,
      "step": 9700
    },
    {
      "epoch": 4.183541576906506,
      "grad_norm": 1.814556360244751,
      "learning_rate": 8.168892718655752e-06,
      "loss": 0.0104,
      "step": 9710
    },
    {
      "epoch": 4.187850064627316,
      "grad_norm": 0.04660286381840706,
      "learning_rate": 8.125807841447653e-06,
      "loss": 0.041,
      "step": 9720
    },
    {
      "epoch": 4.1921585523481255,
      "grad_norm": 41.404747009277344,
      "learning_rate": 8.082722964239552e-06,
      "loss": 0.0771,
      "step": 9730
    },
    {
      "epoch": 4.196467040068936,
      "grad_norm": 0.05962873250246048,
      "learning_rate": 8.039638087031452e-06,
      "loss": 0.0733,
      "step": 9740
    },
    {
      "epoch": 4.200775527789745,
      "grad_norm": 0.8719273805618286,
      "learning_rate": 7.996553209823353e-06,
      "loss": 0.0756,
      "step": 9750
    },
    {
      "epoch": 4.205084015510556,
      "grad_norm": 16.942153930664062,
      "learning_rate": 7.953468332615253e-06,
      "loss": 0.0083,
      "step": 9760
    },
    {
      "epoch": 4.209392503231366,
      "grad_norm": 0.021742727607488632,
      "learning_rate": 7.910383455407152e-06,
      "loss": 0.0274,
      "step": 9770
    },
    {
      "epoch": 4.213700990952176,
      "grad_norm": 0.6576065421104431,
      "learning_rate": 7.867298578199052e-06,
      "loss": 0.064,
      "step": 9780
    },
    {
      "epoch": 4.218009478672986,
      "grad_norm": 5.489595890045166,
      "learning_rate": 7.824213700990953e-06,
      "loss": 0.0596,
      "step": 9790
    },
    {
      "epoch": 4.2223179663937955,
      "grad_norm": 0.2667321562767029,
      "learning_rate": 7.781128823782852e-06,
      "loss": 0.0534,
      "step": 9800
    },
    {
      "epoch": 4.226626454114606,
      "grad_norm": 0.10716577619314194,
      "learning_rate": 7.738043946574752e-06,
      "loss": 0.0255,
      "step": 9810
    },
    {
      "epoch": 4.230934941835415,
      "grad_norm": 6.065584182739258,
      "learning_rate": 7.694959069366653e-06,
      "loss": 0.1153,
      "step": 9820
    },
    {
      "epoch": 4.235243429556226,
      "grad_norm": 7.450979232788086,
      "learning_rate": 7.651874192158553e-06,
      "loss": 0.085,
      "step": 9830
    },
    {
      "epoch": 4.239551917277036,
      "grad_norm": 0.044415246695280075,
      "learning_rate": 7.608789314950453e-06,
      "loss": 0.0796,
      "step": 9840
    },
    {
      "epoch": 4.243860404997846,
      "grad_norm": 1.6785674095153809,
      "learning_rate": 7.565704437742353e-06,
      "loss": 0.036,
      "step": 9850
    },
    {
      "epoch": 4.248168892718656,
      "grad_norm": 0.6311917901039124,
      "learning_rate": 7.522619560534253e-06,
      "loss": 0.0748,
      "step": 9860
    },
    {
      "epoch": 4.2524773804394655,
      "grad_norm": 13.800941467285156,
      "learning_rate": 7.479534683326153e-06,
      "loss": 0.0908,
      "step": 9870
    },
    {
      "epoch": 4.256785868160276,
      "grad_norm": 15.321694374084473,
      "learning_rate": 7.436449806118053e-06,
      "loss": 0.0511,
      "step": 9880
    },
    {
      "epoch": 4.261094355881085,
      "grad_norm": 32.425907135009766,
      "learning_rate": 7.393364928909953e-06,
      "loss": 0.1253,
      "step": 9890
    },
    {
      "epoch": 4.265402843601896,
      "grad_norm": 0.14325499534606934,
      "learning_rate": 7.3502800517018535e-06,
      "loss": 0.0818,
      "step": 9900
    },
    {
      "epoch": 4.269711331322705,
      "grad_norm": 18.12657928466797,
      "learning_rate": 7.307195174493753e-06,
      "loss": 0.0698,
      "step": 9910
    },
    {
      "epoch": 4.274019819043516,
      "grad_norm": 25.46823501586914,
      "learning_rate": 7.264110297285653e-06,
      "loss": 0.0199,
      "step": 9920
    },
    {
      "epoch": 4.278328306764326,
      "grad_norm": 1.5565521717071533,
      "learning_rate": 7.221025420077553e-06,
      "loss": 0.0542,
      "step": 9930
    },
    {
      "epoch": 4.282636794485136,
      "grad_norm": 30.314546585083008,
      "learning_rate": 7.177940542869453e-06,
      "loss": 0.1043,
      "step": 9940
    },
    {
      "epoch": 4.286945282205946,
      "grad_norm": 9.403448104858398,
      "learning_rate": 7.134855665661354e-06,
      "loss": 0.0469,
      "step": 9950
    },
    {
      "epoch": 4.2912537699267554,
      "grad_norm": 50.750797271728516,
      "learning_rate": 7.091770788453253e-06,
      "loss": 0.0683,
      "step": 9960
    },
    {
      "epoch": 4.295562257647566,
      "grad_norm": 0.10807830095291138,
      "learning_rate": 7.0486859112451536e-06,
      "loss": 0.1169,
      "step": 9970
    },
    {
      "epoch": 4.299870745368375,
      "grad_norm": 0.016809003427624702,
      "learning_rate": 7.005601034037053e-06,
      "loss": 0.0407,
      "step": 9980
    },
    {
      "epoch": 4.304179233089186,
      "grad_norm": 0.1294095665216446,
      "learning_rate": 6.9625161568289534e-06,
      "loss": 0.0995,
      "step": 9990
    },
    {
      "epoch": 4.308487720809996,
      "grad_norm": 1.452204942703247,
      "learning_rate": 6.919431279620854e-06,
      "loss": 0.0342,
      "step": 10000
    },
    {
      "epoch": 4.312796208530806,
      "grad_norm": 1.9712351560592651,
      "learning_rate": 6.876346402412753e-06,
      "loss": 0.0654,
      "step": 10010
    },
    {
      "epoch": 4.317104696251616,
      "grad_norm": 13.953340530395508,
      "learning_rate": 6.833261525204654e-06,
      "loss": 0.1383,
      "step": 10020
    },
    {
      "epoch": 4.3214131839724255,
      "grad_norm": 4.705362796783447,
      "learning_rate": 6.790176647996553e-06,
      "loss": 0.105,
      "step": 10030
    },
    {
      "epoch": 4.325721671693236,
      "grad_norm": 0.08394303917884827,
      "learning_rate": 6.747091770788454e-06,
      "loss": 0.0614,
      "step": 10040
    },
    {
      "epoch": 4.330030159414045,
      "grad_norm": 1.974996566772461,
      "learning_rate": 6.704006893580353e-06,
      "loss": 0.0762,
      "step": 10050
    },
    {
      "epoch": 4.334338647134856,
      "grad_norm": 2.6086275577545166,
      "learning_rate": 6.6609220163722535e-06,
      "loss": 0.0532,
      "step": 10060
    },
    {
      "epoch": 4.338647134855666,
      "grad_norm": 5.765019416809082,
      "learning_rate": 6.617837139164154e-06,
      "loss": 0.1768,
      "step": 10070
    },
    {
      "epoch": 4.342955622576476,
      "grad_norm": 10.084898948669434,
      "learning_rate": 6.574752261956053e-06,
      "loss": 0.0683,
      "step": 10080
    },
    {
      "epoch": 4.347264110297286,
      "grad_norm": 0.25591596961021423,
      "learning_rate": 6.531667384747954e-06,
      "loss": 0.0394,
      "step": 10090
    },
    {
      "epoch": 4.3515725980180955,
      "grad_norm": 10.628586769104004,
      "learning_rate": 6.488582507539853e-06,
      "loss": 0.1001,
      "step": 10100
    },
    {
      "epoch": 4.355881085738906,
      "grad_norm": 0.38751524686813354,
      "learning_rate": 6.445497630331754e-06,
      "loss": 0.0547,
      "step": 10110
    },
    {
      "epoch": 4.360189573459715,
      "grad_norm": 0.13790038228034973,
      "learning_rate": 6.402412753123654e-06,
      "loss": 0.0519,
      "step": 10120
    },
    {
      "epoch": 4.364498061180526,
      "grad_norm": 0.17157018184661865,
      "learning_rate": 6.3593278759155535e-06,
      "loss": 0.0192,
      "step": 10130
    },
    {
      "epoch": 4.368806548901335,
      "grad_norm": 17.88605308532715,
      "learning_rate": 6.316242998707454e-06,
      "loss": 0.0694,
      "step": 10140
    },
    {
      "epoch": 4.373115036622146,
      "grad_norm": 21.958436965942383,
      "learning_rate": 6.273158121499353e-06,
      "loss": 0.0391,
      "step": 10150
    },
    {
      "epoch": 4.377423524342956,
      "grad_norm": 9.860334396362305,
      "learning_rate": 6.230073244291254e-06,
      "loss": 0.0491,
      "step": 10160
    },
    {
      "epoch": 4.3817320120637655,
      "grad_norm": 0.012375926598906517,
      "learning_rate": 6.186988367083154e-06,
      "loss": 0.0375,
      "step": 10170
    },
    {
      "epoch": 4.386040499784576,
      "grad_norm": 14.910637855529785,
      "learning_rate": 6.143903489875054e-06,
      "loss": 0.0617,
      "step": 10180
    },
    {
      "epoch": 4.390348987505385,
      "grad_norm": 24.69365692138672,
      "learning_rate": 6.100818612666955e-06,
      "loss": 0.0564,
      "step": 10190
    },
    {
      "epoch": 4.394657475226196,
      "grad_norm": 0.9718024730682373,
      "learning_rate": 6.057733735458854e-06,
      "loss": 0.0795,
      "step": 10200
    },
    {
      "epoch": 4.398965962947005,
      "grad_norm": 18.89588165283203,
      "learning_rate": 6.014648858250754e-06,
      "loss": 0.1591,
      "step": 10210
    },
    {
      "epoch": 4.403274450667816,
      "grad_norm": 0.17098917067050934,
      "learning_rate": 5.971563981042654e-06,
      "loss": 0.1073,
      "step": 10220
    },
    {
      "epoch": 4.407582938388625,
      "grad_norm": 0.021724883466959,
      "learning_rate": 5.928479103834554e-06,
      "loss": 0.0793,
      "step": 10230
    },
    {
      "epoch": 4.4118914261094355,
      "grad_norm": 1.730498194694519,
      "learning_rate": 5.885394226626455e-06,
      "loss": 0.0583,
      "step": 10240
    },
    {
      "epoch": 4.416199913830246,
      "grad_norm": 11.024157524108887,
      "learning_rate": 5.8423093494183545e-06,
      "loss": 0.0272,
      "step": 10250
    },
    {
      "epoch": 4.420508401551055,
      "grad_norm": 1.3094443082809448,
      "learning_rate": 5.799224472210255e-06,
      "loss": 0.1468,
      "step": 10260
    },
    {
      "epoch": 4.424816889271866,
      "grad_norm": 0.22784405946731567,
      "learning_rate": 5.756139595002154e-06,
      "loss": 0.0819,
      "step": 10270
    },
    {
      "epoch": 4.429125376992675,
      "grad_norm": 1.1396316289901733,
      "learning_rate": 5.713054717794055e-06,
      "loss": 0.0749,
      "step": 10280
    },
    {
      "epoch": 4.433433864713486,
      "grad_norm": 0.6984053254127502,
      "learning_rate": 5.669969840585954e-06,
      "loss": 0.0621,
      "step": 10290
    },
    {
      "epoch": 4.437742352434295,
      "grad_norm": 8.99067211151123,
      "learning_rate": 5.626884963377855e-06,
      "loss": 0.0309,
      "step": 10300
    },
    {
      "epoch": 4.4420508401551055,
      "grad_norm": 0.03915807977318764,
      "learning_rate": 5.583800086169755e-06,
      "loss": 0.1015,
      "step": 10310
    },
    {
      "epoch": 4.446359327875916,
      "grad_norm": 0.041563138365745544,
      "learning_rate": 5.5407152089616546e-06,
      "loss": 0.0648,
      "step": 10320
    },
    {
      "epoch": 4.450667815596725,
      "grad_norm": 0.06180210039019585,
      "learning_rate": 5.497630331753555e-06,
      "loss": 0.1014,
      "step": 10330
    },
    {
      "epoch": 4.454976303317536,
      "grad_norm": 0.6141263246536255,
      "learning_rate": 5.4545454545454545e-06,
      "loss": 0.0363,
      "step": 10340
    },
    {
      "epoch": 4.459284791038345,
      "grad_norm": 26.283082962036133,
      "learning_rate": 5.411460577337355e-06,
      "loss": 0.0374,
      "step": 10350
    },
    {
      "epoch": 4.463593278759156,
      "grad_norm": 0.901086688041687,
      "learning_rate": 5.368375700129255e-06,
      "loss": 0.0541,
      "step": 10360
    },
    {
      "epoch": 4.467901766479965,
      "grad_norm": 10.968646049499512,
      "learning_rate": 5.325290822921155e-06,
      "loss": 0.0953,
      "step": 10370
    },
    {
      "epoch": 4.472210254200776,
      "grad_norm": 0.1916341483592987,
      "learning_rate": 5.282205945713055e-06,
      "loss": 0.0413,
      "step": 10380
    },
    {
      "epoch": 4.476518741921586,
      "grad_norm": 0.08068129420280457,
      "learning_rate": 5.239121068504955e-06,
      "loss": 0.1451,
      "step": 10390
    },
    {
      "epoch": 4.480827229642395,
      "grad_norm": 30.850725173950195,
      "learning_rate": 5.196036191296856e-06,
      "loss": 0.0411,
      "step": 10400
    },
    {
      "epoch": 4.485135717363206,
      "grad_norm": 0.05118672549724579,
      "learning_rate": 5.152951314088755e-06,
      "loss": 0.043,
      "step": 10410
    },
    {
      "epoch": 4.489444205084015,
      "grad_norm": 0.08406466245651245,
      "learning_rate": 5.109866436880655e-06,
      "loss": 0.0219,
      "step": 10420
    },
    {
      "epoch": 4.493752692804826,
      "grad_norm": 0.5576104521751404,
      "learning_rate": 5.066781559672555e-06,
      "loss": 0.0021,
      "step": 10430
    },
    {
      "epoch": 4.498061180525635,
      "grad_norm": 17.142419815063477,
      "learning_rate": 5.023696682464455e-06,
      "loss": 0.1002,
      "step": 10440
    },
    {
      "epoch": 4.502369668246446,
      "grad_norm": 0.09957804530858994,
      "learning_rate": 4.980611805256355e-06,
      "loss": 0.0323,
      "step": 10450
    },
    {
      "epoch": 4.506678155967256,
      "grad_norm": 23.2116641998291,
      "learning_rate": 4.9375269280482555e-06,
      "loss": 0.0363,
      "step": 10460
    },
    {
      "epoch": 4.5109866436880655,
      "grad_norm": 46.85552215576172,
      "learning_rate": 4.894442050840156e-06,
      "loss": 0.0502,
      "step": 10470
    },
    {
      "epoch": 4.515295131408876,
      "grad_norm": 1.6401593685150146,
      "learning_rate": 4.851357173632055e-06,
      "loss": 0.0346,
      "step": 10480
    },
    {
      "epoch": 4.519603619129685,
      "grad_norm": 1.7340348958969116,
      "learning_rate": 4.808272296423955e-06,
      "loss": 0.0635,
      "step": 10490
    },
    {
      "epoch": 4.523912106850496,
      "grad_norm": 34.792842864990234,
      "learning_rate": 4.765187419215855e-06,
      "loss": 0.132,
      "step": 10500
    },
    {
      "epoch": 4.528220594571305,
      "grad_norm": 26.507450103759766,
      "learning_rate": 4.722102542007756e-06,
      "loss": 0.1305,
      "step": 10510
    },
    {
      "epoch": 4.532529082292116,
      "grad_norm": 2.9038631916046143,
      "learning_rate": 4.679017664799656e-06,
      "loss": 0.0797,
      "step": 10520
    },
    {
      "epoch": 4.536837570012925,
      "grad_norm": 0.18753008544445038,
      "learning_rate": 4.6359327875915555e-06,
      "loss": 0.0399,
      "step": 10530
    },
    {
      "epoch": 4.5411460577337355,
      "grad_norm": 15.961724281311035,
      "learning_rate": 4.592847910383456e-06,
      "loss": 0.0741,
      "step": 10540
    },
    {
      "epoch": 4.545454545454545,
      "grad_norm": 4.9671502113342285,
      "learning_rate": 4.549763033175355e-06,
      "loss": 0.1362,
      "step": 10550
    },
    {
      "epoch": 4.549763033175355,
      "grad_norm": 29.680349349975586,
      "learning_rate": 4.506678155967256e-06,
      "loss": 0.0258,
      "step": 10560
    },
    {
      "epoch": 4.554071520896166,
      "grad_norm": 20.287858963012695,
      "learning_rate": 4.463593278759156e-06,
      "loss": 0.0795,
      "step": 10570
    },
    {
      "epoch": 4.558380008616975,
      "grad_norm": 0.28131288290023804,
      "learning_rate": 4.420508401551056e-06,
      "loss": 0.1093,
      "step": 10580
    },
    {
      "epoch": 4.562688496337786,
      "grad_norm": 4.26814079284668,
      "learning_rate": 4.377423524342956e-06,
      "loss": 0.0249,
      "step": 10590
    },
    {
      "epoch": 4.566996984058595,
      "grad_norm": 0.27115899324417114,
      "learning_rate": 4.3343386471348555e-06,
      "loss": 0.1078,
      "step": 10600
    },
    {
      "epoch": 4.5713054717794055,
      "grad_norm": 0.02132388949394226,
      "learning_rate": 4.291253769926756e-06,
      "loss": 0.0053,
      "step": 10610
    },
    {
      "epoch": 4.575613959500215,
      "grad_norm": 0.012844384647905827,
      "learning_rate": 4.248168892718656e-06,
      "loss": 0.0488,
      "step": 10620
    },
    {
      "epoch": 4.579922447221025,
      "grad_norm": 13.90330696105957,
      "learning_rate": 4.205084015510556e-06,
      "loss": 0.1077,
      "step": 10630
    },
    {
      "epoch": 4.584230934941836,
      "grad_norm": 0.05910325050354004,
      "learning_rate": 4.161999138302456e-06,
      "loss": 0.0486,
      "step": 10640
    },
    {
      "epoch": 4.588539422662645,
      "grad_norm": 0.013971795327961445,
      "learning_rate": 4.118914261094356e-06,
      "loss": 0.1317,
      "step": 10650
    },
    {
      "epoch": 4.592847910383456,
      "grad_norm": 1.018241286277771,
      "learning_rate": 4.075829383886256e-06,
      "loss": 0.0532,
      "step": 10660
    },
    {
      "epoch": 4.597156398104265,
      "grad_norm": 0.6040621995925903,
      "learning_rate": 4.032744506678156e-06,
      "loss": 0.0669,
      "step": 10670
    },
    {
      "epoch": 4.6014648858250755,
      "grad_norm": 2.4833614826202393,
      "learning_rate": 3.989659629470057e-06,
      "loss": 0.1242,
      "step": 10680
    },
    {
      "epoch": 4.605773373545885,
      "grad_norm": 0.056738849729299545,
      "learning_rate": 3.946574752261956e-06,
      "loss": 0.1131,
      "step": 10690
    },
    {
      "epoch": 4.610081861266695,
      "grad_norm": 10.64475154876709,
      "learning_rate": 3.903489875053856e-06,
      "loss": 0.0663,
      "step": 10700
    },
    {
      "epoch": 4.614390348987506,
      "grad_norm": 0.19829274713993073,
      "learning_rate": 3.860404997845756e-06,
      "loss": 0.0676,
      "step": 10710
    },
    {
      "epoch": 4.618698836708315,
      "grad_norm": 53.659873962402344,
      "learning_rate": 3.817320120637656e-06,
      "loss": 0.1565,
      "step": 10720
    },
    {
      "epoch": 4.623007324429126,
      "grad_norm": 29.819700241088867,
      "learning_rate": 3.7742352434295565e-06,
      "loss": 0.1769,
      "step": 10730
    },
    {
      "epoch": 4.627315812149935,
      "grad_norm": 18.987058639526367,
      "learning_rate": 3.7311503662214565e-06,
      "loss": 0.0995,
      "step": 10740
    },
    {
      "epoch": 4.6316242998707455,
      "grad_norm": 3.7480108737945557,
      "learning_rate": 3.6880654890133564e-06,
      "loss": 0.0031,
      "step": 10750
    },
    {
      "epoch": 4.635932787591555,
      "grad_norm": 0.6690366864204407,
      "learning_rate": 3.6449806118052563e-06,
      "loss": 0.0259,
      "step": 10760
    },
    {
      "epoch": 4.640241275312365,
      "grad_norm": 0.15267381072044373,
      "learning_rate": 3.6018957345971563e-06,
      "loss": 0.0391,
      "step": 10770
    },
    {
      "epoch": 4.644549763033176,
      "grad_norm": 7.780599117279053,
      "learning_rate": 3.558810857389057e-06,
      "loss": 0.1729,
      "step": 10780
    },
    {
      "epoch": 4.648858250753985,
      "grad_norm": 1.8688488006591797,
      "learning_rate": 3.5157259801809566e-06,
      "loss": 0.0402,
      "step": 10790
    },
    {
      "epoch": 4.653166738474796,
      "grad_norm": 0.12395849823951721,
      "learning_rate": 3.4726411029728565e-06,
      "loss": 0.06,
      "step": 10800
    },
    {
      "epoch": 4.657475226195605,
      "grad_norm": 0.1615072786808014,
      "learning_rate": 3.4295562257647565e-06,
      "loss": 0.0373,
      "step": 10810
    },
    {
      "epoch": 4.6617837139164156,
      "grad_norm": 1.0954481363296509,
      "learning_rate": 3.3864713485566564e-06,
      "loss": 0.0671,
      "step": 10820
    },
    {
      "epoch": 4.666092201637225,
      "grad_norm": 0.9759745001792908,
      "learning_rate": 3.3433864713485572e-06,
      "loss": 0.0802,
      "step": 10830
    },
    {
      "epoch": 4.670400689358035,
      "grad_norm": 0.17137908935546875,
      "learning_rate": 3.300301594140457e-06,
      "loss": 0.08,
      "step": 10840
    },
    {
      "epoch": 4.674709177078846,
      "grad_norm": 0.880713939666748,
      "learning_rate": 3.257216716932357e-06,
      "loss": 0.0328,
      "step": 10850
    },
    {
      "epoch": 4.679017664799655,
      "grad_norm": 1.7571649551391602,
      "learning_rate": 3.214131839724257e-06,
      "loss": 0.0311,
      "step": 10860
    },
    {
      "epoch": 4.683326152520466,
      "grad_norm": 3.5610594749450684,
      "learning_rate": 3.171046962516157e-06,
      "loss": 0.0818,
      "step": 10870
    },
    {
      "epoch": 4.687634640241275,
      "grad_norm": 32.80054473876953,
      "learning_rate": 3.1279620853080565e-06,
      "loss": 0.0309,
      "step": 10880
    },
    {
      "epoch": 4.691943127962086,
      "grad_norm": 0.20481359958648682,
      "learning_rate": 3.084877208099957e-06,
      "loss": 0.0832,
      "step": 10890
    },
    {
      "epoch": 4.696251615682895,
      "grad_norm": 0.16768395900726318,
      "learning_rate": 3.0417923308918573e-06,
      "loss": 0.096,
      "step": 10900
    },
    {
      "epoch": 4.7005601034037054,
      "grad_norm": 3.1180076599121094,
      "learning_rate": 2.998707453683757e-06,
      "loss": 0.0976,
      "step": 10910
    },
    {
      "epoch": 4.704868591124515,
      "grad_norm": 10.297725677490234,
      "learning_rate": 2.955622576475657e-06,
      "loss": 0.0271,
      "step": 10920
    },
    {
      "epoch": 4.709177078845325,
      "grad_norm": 0.030738478526473045,
      "learning_rate": 2.9125376992675575e-06,
      "loss": 0.0561,
      "step": 10930
    },
    {
      "epoch": 4.713485566566135,
      "grad_norm": 33.11485290527344,
      "learning_rate": 2.869452822059457e-06,
      "loss": 0.0394,
      "step": 10940
    },
    {
      "epoch": 4.717794054286945,
      "grad_norm": 7.642700672149658,
      "learning_rate": 2.8263679448513574e-06,
      "loss": 0.1116,
      "step": 10950
    },
    {
      "epoch": 4.722102542007756,
      "grad_norm": 1.658829927444458,
      "learning_rate": 2.7832830676432573e-06,
      "loss": 0.0435,
      "step": 10960
    },
    {
      "epoch": 4.726411029728565,
      "grad_norm": 11.826859474182129,
      "learning_rate": 2.7401981904351573e-06,
      "loss": 0.1179,
      "step": 10970
    },
    {
      "epoch": 4.7307195174493755,
      "grad_norm": 23.134706497192383,
      "learning_rate": 2.6971133132270577e-06,
      "loss": 0.0737,
      "step": 10980
    },
    {
      "epoch": 4.735028005170185,
      "grad_norm": 0.07678280770778656,
      "learning_rate": 2.6540284360189576e-06,
      "loss": 0.1107,
      "step": 10990
    },
    {
      "epoch": 4.739336492890995,
      "grad_norm": 0.2265174686908722,
      "learning_rate": 2.6109435588108575e-06,
      "loss": 0.0201,
      "step": 11000
    },
    {
      "epoch": 4.743644980611805,
      "grad_norm": 10.894963264465332,
      "learning_rate": 2.5678586816027575e-06,
      "loss": 0.1058,
      "step": 11010
    },
    {
      "epoch": 4.747953468332615,
      "grad_norm": 0.9303012490272522,
      "learning_rate": 2.5247738043946574e-06,
      "loss": 0.0988,
      "step": 11020
    },
    {
      "epoch": 4.752261956053426,
      "grad_norm": 47.68080139160156,
      "learning_rate": 2.481688927186558e-06,
      "loss": 0.0887,
      "step": 11030
    },
    {
      "epoch": 4.756570443774235,
      "grad_norm": 19.591808319091797,
      "learning_rate": 2.4386040499784577e-06,
      "loss": 0.1414,
      "step": 11040
    },
    {
      "epoch": 4.7608789314950455,
      "grad_norm": 6.492151260375977,
      "learning_rate": 2.3955191727703577e-06,
      "loss": 0.083,
      "step": 11050
    },
    {
      "epoch": 4.765187419215855,
      "grad_norm": 2.756181001663208,
      "learning_rate": 2.352434295562258e-06,
      "loss": 0.0946,
      "step": 11060
    },
    {
      "epoch": 4.769495906936665,
      "grad_norm": 0.010542372241616249,
      "learning_rate": 2.309349418354158e-06,
      "loss": 0.007,
      "step": 11070
    },
    {
      "epoch": 4.773804394657475,
      "grad_norm": 0.054695241153240204,
      "learning_rate": 2.2662645411460575e-06,
      "loss": 0.0393,
      "step": 11080
    },
    {
      "epoch": 4.778112882378285,
      "grad_norm": 0.04151805490255356,
      "learning_rate": 2.223179663937958e-06,
      "loss": 0.0171,
      "step": 11090
    },
    {
      "epoch": 4.782421370099096,
      "grad_norm": 0.02816023863852024,
      "learning_rate": 2.180094786729858e-06,
      "loss": 0.095,
      "step": 11100
    },
    {
      "epoch": 4.786729857819905,
      "grad_norm": 0.28405827283859253,
      "learning_rate": 2.1370099095217578e-06,
      "loss": 0.1372,
      "step": 11110
    },
    {
      "epoch": 4.7910383455407155,
      "grad_norm": 16.428495407104492,
      "learning_rate": 2.093925032313658e-06,
      "loss": 0.0718,
      "step": 11120
    },
    {
      "epoch": 4.795346833261525,
      "grad_norm": 2.4833261966705322,
      "learning_rate": 2.050840155105558e-06,
      "loss": 0.0566,
      "step": 11130
    },
    {
      "epoch": 4.799655320982335,
      "grad_norm": 20.90995216369629,
      "learning_rate": 2.007755277897458e-06,
      "loss": 0.0536,
      "step": 11140
    },
    {
      "epoch": 4.803963808703145,
      "grad_norm": 19.258039474487305,
      "learning_rate": 1.964670400689358e-06,
      "loss": 0.0498,
      "step": 11150
    },
    {
      "epoch": 4.808272296423955,
      "grad_norm": 2.7362396717071533,
      "learning_rate": 1.921585523481258e-06,
      "loss": 0.0642,
      "step": 11160
    },
    {
      "epoch": 4.812580784144766,
      "grad_norm": 0.288786917924881,
      "learning_rate": 1.8785006462731583e-06,
      "loss": 0.1694,
      "step": 11170
    },
    {
      "epoch": 4.816889271865575,
      "grad_norm": 0.021894611418247223,
      "learning_rate": 1.8354157690650582e-06,
      "loss": 0.0138,
      "step": 11180
    },
    {
      "epoch": 4.8211977595863855,
      "grad_norm": 0.010150626301765442,
      "learning_rate": 1.7923308918569582e-06,
      "loss": 0.0477,
      "step": 11190
    },
    {
      "epoch": 4.825506247307195,
      "grad_norm": 0.06464305520057678,
      "learning_rate": 1.7492460146488583e-06,
      "loss": 0.0909,
      "step": 11200
    },
    {
      "epoch": 4.829814735028005,
      "grad_norm": 0.06927602738142014,
      "learning_rate": 1.7061611374407583e-06,
      "loss": 0.0628,
      "step": 11210
    },
    {
      "epoch": 4.834123222748815,
      "grad_norm": 10.068192481994629,
      "learning_rate": 1.6630762602326586e-06,
      "loss": 0.0696,
      "step": 11220
    },
    {
      "epoch": 4.838431710469625,
      "grad_norm": 5.236141681671143,
      "learning_rate": 1.6199913830245584e-06,
      "loss": 0.1163,
      "step": 11230
    },
    {
      "epoch": 4.842740198190435,
      "grad_norm": 20.2098388671875,
      "learning_rate": 1.5769065058164583e-06,
      "loss": 0.1723,
      "step": 11240
    },
    {
      "epoch": 4.847048685911245,
      "grad_norm": 2.7072336673736572,
      "learning_rate": 1.5338216286083585e-06,
      "loss": 0.0695,
      "step": 11250
    },
    {
      "epoch": 4.851357173632055,
      "grad_norm": 0.08243591338396072,
      "learning_rate": 1.4907367514002586e-06,
      "loss": 0.1204,
      "step": 11260
    },
    {
      "epoch": 4.855665661352865,
      "grad_norm": 0.07540769875049591,
      "learning_rate": 1.4476518741921586e-06,
      "loss": 0.0191,
      "step": 11270
    },
    {
      "epoch": 4.859974149073675,
      "grad_norm": 0.12276852875947952,
      "learning_rate": 1.4045669969840587e-06,
      "loss": 0.0327,
      "step": 11280
    },
    {
      "epoch": 4.864282636794485,
      "grad_norm": 0.03658616170287132,
      "learning_rate": 1.3614821197759587e-06,
      "loss": 0.0367,
      "step": 11290
    },
    {
      "epoch": 4.868591124515295,
      "grad_norm": 28.767736434936523,
      "learning_rate": 1.3183972425678586e-06,
      "loss": 0.0494,
      "step": 11300
    },
    {
      "epoch": 4.872899612236105,
      "grad_norm": 0.03924178704619408,
      "learning_rate": 1.2753123653597588e-06,
      "loss": 0.1062,
      "step": 11310
    },
    {
      "epoch": 4.877208099956915,
      "grad_norm": 3.4501025676727295,
      "learning_rate": 1.232227488151659e-06,
      "loss": 0.0696,
      "step": 11320
    },
    {
      "epoch": 4.881516587677725,
      "grad_norm": 1.8073457479476929,
      "learning_rate": 1.1891426109435589e-06,
      "loss": 0.0589,
      "step": 11330
    },
    {
      "epoch": 4.885825075398535,
      "grad_norm": 0.012385804206132889,
      "learning_rate": 1.1460577337354588e-06,
      "loss": 0.0678,
      "step": 11340
    },
    {
      "epoch": 4.890133563119345,
      "grad_norm": 0.1517878621816635,
      "learning_rate": 1.102972856527359e-06,
      "loss": 0.0655,
      "step": 11350
    },
    {
      "epoch": 4.894442050840155,
      "grad_norm": 0.488054484128952,
      "learning_rate": 1.0598879793192591e-06,
      "loss": 0.0754,
      "step": 11360
    },
    {
      "epoch": 4.898750538560965,
      "grad_norm": 36.726959228515625,
      "learning_rate": 1.0168031021111589e-06,
      "loss": 0.1535,
      "step": 11370
    },
    {
      "epoch": 4.903059026281775,
      "grad_norm": 0.38086801767349243,
      "learning_rate": 9.73718224903059e-07,
      "loss": 0.1032,
      "step": 11380
    },
    {
      "epoch": 4.907367514002585,
      "grad_norm": 0.3552674353122711,
      "learning_rate": 9.306333476949592e-07,
      "loss": 0.0211,
      "step": 11390
    },
    {
      "epoch": 4.911676001723395,
      "grad_norm": 9.279918670654297,
      "learning_rate": 8.875484704868592e-07,
      "loss": 0.0731,
      "step": 11400
    },
    {
      "epoch": 4.915984489444205,
      "grad_norm": 0.03485533222556114,
      "learning_rate": 8.444635932787592e-07,
      "loss": 0.0681,
      "step": 11410
    },
    {
      "epoch": 4.9202929771650155,
      "grad_norm": 0.03602541983127594,
      "learning_rate": 8.013787160706592e-07,
      "loss": 0.0034,
      "step": 11420
    },
    {
      "epoch": 4.924601464885825,
      "grad_norm": 0.11840075254440308,
      "learning_rate": 7.582938388625593e-07,
      "loss": 0.0244,
      "step": 11430
    },
    {
      "epoch": 4.928909952606635,
      "grad_norm": 35.21296691894531,
      "learning_rate": 7.152089616544593e-07,
      "loss": 0.1187,
      "step": 11440
    },
    {
      "epoch": 4.933218440327445,
      "grad_norm": 12.690277099609375,
      "learning_rate": 6.721240844463594e-07,
      "loss": 0.0201,
      "step": 11450
    },
    {
      "epoch": 4.937526928048255,
      "grad_norm": 8.893542289733887,
      "learning_rate": 6.290392072382594e-07,
      "loss": 0.1251,
      "step": 11460
    },
    {
      "epoch": 4.941835415769065,
      "grad_norm": 26.816051483154297,
      "learning_rate": 5.859543300301595e-07,
      "loss": 0.0651,
      "step": 11470
    },
    {
      "epoch": 4.946143903489875,
      "grad_norm": 1.4549881219863892,
      "learning_rate": 5.428694528220595e-07,
      "loss": 0.1094,
      "step": 11480
    },
    {
      "epoch": 4.9504523912106855,
      "grad_norm": 0.046372026205062866,
      "learning_rate": 4.997845756139596e-07,
      "loss": 0.0896,
      "step": 11490
    },
    {
      "epoch": 4.954760878931495,
      "grad_norm": 0.016170600429177284,
      "learning_rate": 4.5669969840585957e-07,
      "loss": 0.0266,
      "step": 11500
    },
    {
      "epoch": 4.959069366652305,
      "grad_norm": 24.95574378967285,
      "learning_rate": 4.136148211977596e-07,
      "loss": 0.0052,
      "step": 11510
    },
    {
      "epoch": 4.963377854373115,
      "grad_norm": 0.02965020202100277,
      "learning_rate": 3.705299439896596e-07,
      "loss": 0.0016,
      "step": 11520
    },
    {
      "epoch": 4.967686342093925,
      "grad_norm": 0.1528617888689041,
      "learning_rate": 3.2744506678155966e-07,
      "loss": 0.0763,
      "step": 11530
    },
    {
      "epoch": 4.971994829814735,
      "grad_norm": 0.0372953861951828,
      "learning_rate": 2.843601895734597e-07,
      "loss": 0.0734,
      "step": 11540
    },
    {
      "epoch": 4.976303317535545,
      "grad_norm": 0.35027727484703064,
      "learning_rate": 2.4127531236535976e-07,
      "loss": 0.0203,
      "step": 11550
    },
    {
      "epoch": 4.9806118052563555,
      "grad_norm": 0.14799481630325317,
      "learning_rate": 1.981904351572598e-07,
      "loss": 0.0485,
      "step": 11560
    },
    {
      "epoch": 4.984920292977165,
      "grad_norm": 0.04388349503278732,
      "learning_rate": 1.5510555794915986e-07,
      "loss": 0.0369,
      "step": 11570
    },
    {
      "epoch": 4.989228780697975,
      "grad_norm": 0.03670525178313255,
      "learning_rate": 1.1202068074105989e-07,
      "loss": 0.069,
      "step": 11580
    },
    {
      "epoch": 4.993537268418785,
      "grad_norm": 0.6072952151298523,
      "learning_rate": 6.893580353295994e-08,
      "loss": 0.0212,
      "step": 11590
    },
    {
      "epoch": 4.997845756139595,
      "grad_norm": 19.823326110839844,
      "learning_rate": 2.5850926324859976e-08,
      "loss": 0.054,
      "step": 11600
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.8991970419883728,
      "eval_runtime": 26.5229,
      "eval_samples_per_second": 599.973,
      "eval_steps_per_second": 37.515,
      "step": 11605
    }
  ],
  "logging_steps": 10,
  "max_steps": 11605,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.221219007392e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
